{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "daf7369d",
      "metadata": {
        "id": "daf7369d"
      },
      "source": [
        "# Things you might think of implementing  \n",
        "- replay buffer to learn from unconnected experiences\n",
        "- train in batches to make everything more efficient.\n",
        "- implement PPO, instantiating 2 actors. 1 will be the baseline (i.e. the previous update) in order to compute the ratio.\n",
        "- define 2 different actors that will be specific for each agent. overfitting is possible.\n",
        "- try to see whether you can use convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34372fb3",
      "metadata": {},
      "source": [
        "# Code for executing in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "tIzr7I0HcgCX",
      "metadata": {
        "id": "tIzr7I0HcgCX"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/overcooked_ai/src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "tzMXZXDdYOy7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzMXZXDdYOy7",
        "outputId": "23ef3f40-5f4f-43ab-95a9-3d250c86edec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'overcooked_ai'...\n",
            "remote: Enumerating objects: 8079, done.\u001b[K\n",
            "remote: Counting objects: 100% (1180/1180), done.\u001b[K\n",
            "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
            "remote: Total 8079 (delta 1040), reused 980 (delta 976), pack-reused 6899 (from 4)\u001b[K\n",
            "Receiving objects: 100% (8079/8079), 567.43 MiB | 23.15 MiB/s, done.\n",
            "Resolving deltas: 100% (4542/4542), done.\n",
            "Updating files: 100% (448/448), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cico-rial/overcooked_ai.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ByV0JzfNad4o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByV0JzfNad4o",
        "outputId": "4b0ff5d3-cf6b-4d82-d42c-8e64829243f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,721 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,994 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,246 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,736 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,953 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,264 kB]\n",
            "Fetched 22.9 MB in 2s (9,368 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.9).\n",
            "python3.10 set to manually installed.\n",
            "python3.10-dev is already the newest version (3.10.12-1~22.04.9).\n",
            "python3.10-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "--2025-06-01 12:27:37--  https://bootstrap.pypa.io/get-pip.py\n",
            "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
            "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2279307 (2.2M) [text/x-python]\n",
            "Saving to: ‘get-pip.py’\n",
            "\n",
            "get-pip.py          100%[===================>]   2.17M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-06-01 12:27:37 (47.3 MB/s) - ‘get-pip.py’ saved [2279307/2279307]\n",
            "\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pip-25.1.1 setuptools-80.9.0 wheel-0.45.1\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10 python3.10-dev python3.10-distutils -y\n",
        "!wget https://bootstrap.pypa.io/get-pip.py\n",
        "!python3.10 get-pip.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4xz3JNt2airL",
      "metadata": {
        "id": "4xz3JNt2airL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "FyR56qTBYkpn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyR56qTBYkpn",
        "outputId": "6e9b4dbf-2e03-41c6-9e35-df32b262e0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/overcooked_ai\n",
            "Obtaining file:///content/overcooked_ai\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dill (from overcooked_ai==2.0.0)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gymnasium (from overcooked_ai==2.0.0)\n",
            "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting ipykernel>=6.29.5 (from overcooked_ai==2.0.0)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipywidgets (from overcooked_ai==2.0.0)\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting matplotlib>=3.10.1 (from overcooked_ai==2.0.0)\n",
            "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2 (from overcooked_ai==2.0.0)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting opencv-python (from overcooked_ai==2.0.0)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pygame (from overcooked_ai==2.0.0)\n",
            "  Downloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting scipy (from overcooked_ai==2.0.0)\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: setuptools>=77.0.3 in /usr/local/lib/python3.10/dist-packages (from overcooked_ai==2.0.0) (80.9.0)\n",
            "Collecting tqdm (from overcooked_ai==2.0.0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading debugpy-1.8.14-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ipython>=7.23.1 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading ipython-8.37.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting matplotlib-inline>=0.1 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting nest-asyncio (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting packaging (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting psutil (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pyzmq>=24 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading pyzmq-26.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting tornado>=6.1 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading tornado-6.5.1-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting decorator (from ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting exceptiongroup (from ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading prompt_toolkit-3.0.51-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack_data (from ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting typing_extensions>=4.6 (from ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from jupyter-client>=6.1.12->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=3.10.1->overcooked_ai==2.0.0)\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=3.10.1->overcooked_ai==2.0.0)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=3.10.1->overcooked_ai==2.0.0)\n",
            "  Downloading fonttools-4.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.10.1->overcooked_ai==2.0.0)\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pillow>=8 (from matplotlib>=3.10.1->overcooked_ai==2.0.0)\n",
            "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.10.1->overcooked_ai==2.0.0) (2.4.7)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=6.29.5->overcooked_ai==2.0.0) (1.16.0)\n",
            "Collecting cloudpickle>=1.2.0 (from gymnasium->overcooked_ai==2.0.0)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium->overcooked_ai==2.0.0)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->overcooked_ai==2.0.0)\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->overcooked_ai==2.0.0)\n",
            "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting executing>=1.2.0 (from stack_data->ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->ipython>=7.23.1->ipykernel>=6.29.5->overcooked_ai==2.0.0)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m139.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading debugpy-1.8.14-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m128.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.37.0-py3-none-any.whl (831 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.9/831.9 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prompt_toolkit-3.0.51-py3-none-any.whl (387 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "Downloading jupyter_core-5.8.1-py3-none-any.whl (28 kB)\n",
            "Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m167.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m148.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m148.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading platformdirs-4.3.8-py3-none-any.whl (18 kB)\n",
            "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pyzmq-26.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.5/862.5 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.5.1-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\n",
            "Downloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Building wheels for collected packages: overcooked_ai\n",
            "  Building editable for overcooked_ai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overcooked_ai: filename=overcooked_ai-2.0.0-0.editable-py3-none-any.whl size=7665 sha256=7237a49bc09b8bc41ffbc40bb98e5e6c7c32789611a16a3ddfebc1c57f068417\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2d2hn2jy/wheels/3f/4d/cf/9e5e60571baeba78b17a943de0e76becc63f5bafd36c3c3478\n",
            "Successfully built overcooked_ai\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, farama-notifications, widgetsnbextension, typing_extensions, traitlets, tqdm, tornado, pyzmq, python-dateutil, pygments, pygame, psutil, prompt_toolkit, platformdirs, pillow, pexpect, parso, packaging, numpy, nest-asyncio, kiwisolver, jupyterlab_widgets, fonttools, executing, dill, decorator, debugpy, cycler, cloudpickle, asttokens, stack_data, scipy, opencv-python, matplotlib-inline, jupyter-core, jedi, gymnasium, exceptiongroup, contourpy, comm, matplotlib, jupyter-client, ipython, ipywidgets, ipykernel, overcooked_ai\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/48\u001b[0m [overcooked_ai]\n",
            "\u001b[1A\u001b[2KSuccessfully installed asttokens-3.0.0 cloudpickle-3.1.1 comm-0.2.2 contourpy-1.3.2 cycler-0.12.1 debugpy-1.8.14 decorator-5.2.1 dill-0.4.0 exceptiongroup-1.3.0 executing-2.2.0 farama-notifications-0.0.4 fonttools-4.58.1 gymnasium-1.1.1 ipykernel-6.29.5 ipython-8.37.0 ipywidgets-8.1.7 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.8.1 jupyterlab_widgets-3.0.15 kiwisolver-1.4.8 matplotlib-3.10.3 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 numpy-1.26.4 opencv-python-4.11.0.86 overcooked_ai-2.0.0 packaging-25.0 parso-0.8.4 pexpect-4.9.0 pillow-11.2.1 platformdirs-4.3.8 prompt_toolkit-3.0.51 psutil-7.0.0 ptyprocess-0.7.0 pure-eval-0.2.3 pygame-2.6.1 pygments-2.19.1 python-dateutil-2.9.0.post0 pyzmq-26.4.0 scipy-1.15.3 stack_data-0.6.3 tornado-6.5.1 tqdm-4.67.1 traitlets-5.14.3 typing_extensions-4.13.2 wcwidth-0.2.13 widgetsnbextension-4.0.14\n"
          ]
        }
      ],
      "source": [
        "%cd overcooked_ai\n",
        "# !ls\n",
        "!python3.10 -m pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb9e80b0",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fcad74b2",
      "metadata": {
        "id": "fcad74b2"
      },
      "outputs": [],
      "source": [
        "from overcooked_ai_py.mdp.overcooked_env import OvercookedEnv, Overcooked\n",
        "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld, OvercookedState\n",
        "from overcooked_ai_py.visualization.state_visualizer import StateVisualizer\n",
        "from overcooked_ai_py.mdp.actions import Action\n",
        "from overcooked_ai_py.agents.agent import Agent, AgentPair, RandomAgent\n",
        "from overcooked_ai_py.agents.benchmarking import AgentEvaluator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Tuple, List, Dict\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8XZ8gNfBd03A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XZ8gNfBd03A",
        "outputId": "3333b9af-b038-421f-ca2d-893b373bd79b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Num GPUs Available: 0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a4b1239",
      "metadata": {
        "id": "9a4b1239"
      },
      "source": [
        "# Useful classes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c856aba",
      "metadata": {
        "id": "5c856aba"
      },
      "source": [
        "Policy class: NN for computing the probability distribution of the actions to take."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3b64a48c",
      "metadata": {
        "id": "3b64a48c"
      },
      "outputs": [],
      "source": [
        "class Policy(Model):\n",
        "    def __init__(self, input_shape, num_actions, optimizer, epsilon = 0.05):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.optimizer = optimizer\n",
        "        self.epsilon = epsilon\n",
        "        self.input_a = Input(shape=(self.input_shape))\n",
        "        self.input_b = Input(shape=(self.input_shape))\n",
        "        # self.concatenate_inputs = Concatenate()\n",
        "        self.dense_1 = layers.Dense(128, activation='tanh')\n",
        "        self.dense_2 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_3 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_4 = layers.Dense(128, activation='tanh')\n",
        "        self.policy_a = layers.Dense(self.num_actions, activation='softmax', name=\"policy_a\")\n",
        "        self.policy_b = layers.Dense(self.num_actions, activation='softmax', name=\"policy_b\")\n",
        "        self.build_model()\n",
        "\n",
        "    # def preprocess(self, obs):\n",
        "    #     agent_1_obs = obs['both_agent_obs'][0]\n",
        "    #     agent_2_obs = obs['both_agent_obs'][1]\n",
        "    #     return (tf.expand_dims(agent_1_obs, axis=0), tf.expand_dims(agent_2_obs, axis=0))\n",
        "    \n",
        "    def preprocess(self, obs):\n",
        "        if isinstance(obs, Tuple):\n",
        "            obs = [obs] # to handle the case where obs_batch is a single observation\n",
        "\n",
        "        obs_1, obs_2 = zip(*obs)\n",
        "        obs_batch = tf.concat([tf.stack(obs_1), tf.stack(obs_2)], axis=-1)\n",
        "        return obs_batch\n",
        "\n",
        "\n",
        "    def call(self, obs, training=False):\n",
        "        x = self.preprocess(obs)\n",
        "        # x = self.concatenate_inputs(x)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.dense_3(x)\n",
        "        x = self.dense_4(x)\n",
        "        policy_a = self.policy_a(x)\n",
        "        policy_b = self.policy_b(x)\n",
        "        return (policy_a, policy_b)\n",
        "\n",
        "    def build_model(self):\n",
        "        # computing a forward pass in order to automatically build the model\n",
        "        dummy_input = (\n",
        "            tf.zeros((1, 96)),\n",
        "            tf.zeros((1, 96))\n",
        "        )\n",
        "        _ = self(dummy_input)\n",
        "\n",
        "    def train_step(self, delta, obs: Tuple, action: Tuple[int,int]):\n",
        "        # update t with t + alpha_t*delta*grad_pi^(A|S) where A is the action taken before reaching St+1\n",
        "        with tf.GradientTape() as tape:\n",
        "            pi = self.call(obs, training=True)\n",
        "            log_pi = tf.math.log(pi)\n",
        "            pi_a = log_pi[0][..., action[0]] + log_pi[1][..., action[1]] # π(A|S), computing the sum of the probability of the best actions\n",
        "\n",
        "        grad_pi_a = tape.gradient(pi_a, self.trainable_weights)\n",
        "        processed_gradient = [-tf.squeeze(delta)*grad for grad in grad_pi_a]\n",
        "        self.optimizer.apply_gradients(zip(processed_gradient, self.trainable_weights))\n",
        "    \n",
        "    def train_batch(self, deltas_batch: tf.Tensor, obs_batch, actions_batch):\n",
        "        # update t with t + alpha_t*delta*grad_pi^(A|S) where A is the action taken before reaching St+1\n",
        "        with tf.GradientTape() as tape:\n",
        "            pi = self.call(obs_batch, training=True)\n",
        "            log_pi = tf.math.log(pi)\n",
        "            pi_a1 = tf.gather(log_pi[0], actions_batch[:, 0], axis=1, batch_dims=1)\n",
        "            pi_a2 = tf.gather(log_pi[1], actions_batch[:, 1], axis=1, batch_dims=1)\n",
        "            # Now compute the weighted sum over the batch\n",
        "            pi_a = -tf.reduce_sum(tf.squeeze(deltas_batch) * (pi_a1 + pi_a2))\n",
        "\n",
        "        grad_pi_a = tape.gradient(pi_a, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_pi_a, self.trainable_weights))\n",
        "\n",
        "    def train_batch_PPO(self, deltas_batch: tf.Tensor, obs_batch, actions_batch, old_policy):\n",
        "        with tf.GradientTape() as tape:\n",
        "            pi = self.call(obs_batch, training=True)\n",
        "            old_pi = old_policy.call(obs_batch)\n",
        "            pi_ratio_1 = pi[0] / old_pi[0] + 1e-8 # to avoid numerical instability\n",
        "            pi_ratio_2 = pi[1] / old_pi[1] + 1e-8 # to avoid numerical instability\n",
        "            pi_clipped_ratio_1 = tf.clip_by_value(pi_ratio_1, 1 - self.epsilon, 1 + self.epsilon)\n",
        "            pi_clipped_ratio_2 = tf.clip_by_value(pi_ratio_2, 1 - self.epsilon, 1 + self.epsilon)\n",
        "            pi_ratio_advantage_1 = pi_ratio_1*deltas_batch\n",
        "            pi_ratio_advantage_2 = pi_ratio_2*deltas_batch\n",
        "            pi_clipped_ratio_advantage_1 = pi_clipped_ratio_1*deltas_batch\n",
        "            pi_clipped_ratio_advantage_2 = pi_clipped_ratio_2*deltas_batch\n",
        "            L = 0\n",
        "            for i in range(len(actions_batch)):\n",
        "                L += min(pi_ratio_advantage_1[i][actions_batch[i][0]], pi_clipped_ratio_advantage_1[i][actions_batch[i][0]])\n",
        "                L += min(pi_ratio_advantage_2[i][actions_batch[i][1]], pi_clipped_ratio_advantage_2[i][actions_batch[i][1]])\n",
        "            loss = -L\n",
        "\n",
        "        grad_loss = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_loss, self.trainable_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcc3e496",
      "metadata": {
        "id": "dcc3e496"
      },
      "source": [
        "ValueFunctionApproximator class: NN for approximating the value function of a given state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0171d26d",
      "metadata": {
        "id": "0171d26d"
      },
      "outputs": [],
      "source": [
        "class ValueFunctionApproximator(Model):\n",
        "    def __init__(self, input_shape, optimizer):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.optimizer = optimizer\n",
        "        self.input_a = Input(shape=(self.input_shape))\n",
        "        self.input_b = Input(shape=(self.input_shape))\n",
        "        # self.concatenate_inputs = Concatenate()\n",
        "        self.dense_1 = layers.Dense(128, activation='tanh')\n",
        "        self.dense_2 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_3 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_4 = layers.Dense(128, activation='tanh')\n",
        "        # self.value_function = layers.Dense(1, activation='relu', name=\"value_function\")\n",
        "        self.value_function = layers.Dense(1, name=\"value_function\")\n",
        "        self.build_model()\n",
        "\n",
        "    \n",
        "    def preprocess(self, obs):\n",
        "        if isinstance(obs, Tuple):\n",
        "            obs = [obs] # to handle the case where obs_batch is a single observation\n",
        "\n",
        "        obs_1, obs_2 = zip(*obs)\n",
        "        obs_batch = tf.concat([tf.stack(obs_1), tf.stack(obs_2)], axis=-1)\n",
        "        return obs_batch\n",
        "\n",
        "\n",
        "    def call(self, obs: Tuple, training=False):\n",
        "        x = self.preprocess(obs)\n",
        "        # x = self.concatenate_inputs(x)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.dense_3(x)\n",
        "        x = self.dense_4(x)\n",
        "        value_function = self.value_function(x)\n",
        "        return value_function\n",
        "\n",
        "    def build_model(self):\n",
        "        # computing a forward pass in order to automatically build the model\n",
        "        dummy_input = (\n",
        "            tf.zeros((1, 96)),\n",
        "            tf.zeros((1, 96))\n",
        "        )\n",
        "        _ = self(dummy_input)\n",
        "\n",
        "    def train_step(self, delta, obs: Tuple):\n",
        "        # update w with w + alpha_w*delta*grad_v^(St)\n",
        "        with tf.GradientTape() as tape:\n",
        "            state_value = self.call(obs, training=True)\n",
        "\n",
        "        grad_state_value = tape.gradient(state_value, self.trainable_weights)\n",
        "        processed_gradient = [-tf.squeeze(delta)*grad for grad in grad_state_value]\n",
        "        self.optimizer.apply_gradients(zip(processed_gradient, self.trainable_weights))\n",
        "\n",
        "    def train_batch(self, deltas_batch: tf.Tensor, obs_batch): # deltas is a tf.Tensor of shape (batch_size,1)\n",
        "        # update w with w + alpha_w*grad_v^(St)*delta\n",
        "        with tf.GradientTape() as tape:\n",
        "            state_value = self.call(obs_batch, training=True)\n",
        "            processed_state_value = -deltas_batch * state_value\n",
        "\n",
        "        grad_state_value = tape.gradient(processed_state_value, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_state_value, self.trainable_weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a8ccb45",
      "metadata": {
        "id": "7a8ccb45"
      },
      "source": [
        "Agent class: inherits from Agent class found in agent.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "325eb6dd",
      "metadata": {
        "id": "325eb6dd"
      },
      "outputs": [],
      "source": [
        "class MyAgent(Agent):\n",
        "    \"\"\"\n",
        "    This class is more a couple of actors since we use shared networks and the output are 2!!!\n",
        "    For now let's treat it like a single player identified by self.index\n",
        "    \"\"\"\n",
        "    def __init__(self, actor, old_policy, critic, idx, base_env: OvercookedEnv):\n",
        "        super().__init__()\n",
        "        self.actor = actor\n",
        "        self.old_policy = old_policy\n",
        "        self.critic = critic\n",
        "        self.idx = idx\n",
        "        if not self.idx in [0,1]:\n",
        "            raise AssertionError(\"The index of the agent must be either 0 or 1!\")\n",
        "        self.base_env = base_env\n",
        "\n",
        "    def action(self, obs):\n",
        "        \"\"\"\n",
        "        obs: preprocessed observation (or overcookedstate)\n",
        "        We want to output the action given the state. can use a NN!\n",
        "        should return a tuple (Action, Dict)\n",
        "        Dict should contain info about the action ('action_probs': numpy array)\n",
        "        \"\"\"\n",
        "        if isinstance(obs, OvercookedState):\n",
        "            # this is useful for translating the OvercookedState\n",
        "            # into observation that can be fed into the NN.\n",
        "            state = obs\n",
        "            obs_from_state = self.base_env.featurize_state_mdp(state)\n",
        "            # obs = {'both_agent_obs': obs_from_state, 'overcooked_state': state}\n",
        "            obs = (obs_from_state[0],obs_from_state[1])\n",
        "\n",
        "        action_probs = self.actor.call(obs)[self.idx].numpy()\n",
        "        action = Action.sample(np.squeeze(action_probs))\n",
        "        # if np.random.random() > self.epsilon:\n",
        "        #     action = Action.argmax(action_probs) # greedy selection\n",
        "        # else:\n",
        "        #     action_idx = np.random.choice(range(0,6), size=1)[0]\n",
        "        #     action = Action.INDEX_TO_ACTION[action_idx] # random exploration\n",
        "        \n",
        "        # sample = tf.random.categorical(tf.math.log(action_probs), num_samples = 1)\n",
        "        # action_idx = tf.squeeze(sample, axis=-1)[0].numpy()\n",
        "        # action = Action.INDEX_TO_ACTION[action_idx]\n",
        "        return (action, {'action_probs': action_probs})\n",
        "\n",
        "    def actions(self, obss):\n",
        "        \"\"\"\n",
        "        Look at the documentation of the Agent class\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def update(self, obs, reward):\n",
        "        \"\"\"\n",
        "        What do we need to update?\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def update_old_policy(self):\n",
        "        self.old_policy.set_weights(self.actor.get_weights())\n",
        "\n",
        "    # def decay_epsilon(self, decay):\n",
        "    #     if self.epsilon - decay <= 0.05:\n",
        "    #         self.epsilon = 0.05\n",
        "    #     else:\n",
        "    #         self.epsilon -= decay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1728a541",
      "metadata": {
        "id": "1728a541"
      },
      "source": [
        "# Let's start coding!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26d16be5",
      "metadata": {
        "id": "26d16be5"
      },
      "source": [
        "Let's define our environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0d6e5f28",
      "metadata": {
        "id": "0d6e5f28"
      },
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec017db8",
      "metadata": {
        "id": "ec017db8"
      },
      "source": [
        "Let's instantiate our networks and the hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1680f8db",
      "metadata": {
        "id": "1680f8db"
      },
      "outputs": [],
      "source": [
        "alpha_w = 1e-5\n",
        "alpha_t = 1e-6\n",
        "critic_optimizer = Adam(learning_rate=alpha_w)\n",
        "actor_optimizer = Adam(learning_rate=alpha_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "292c6b08",
      "metadata": {
        "id": "292c6b08"
      },
      "outputs": [],
      "source": [
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=actor_optimizer\n",
        "    )\n",
        "\n",
        "shared_critic = ValueFunctionApproximator(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=critic_optimizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f929ba8d",
      "metadata": {
        "id": "f929ba8d"
      },
      "outputs": [],
      "source": [
        "path_critic = \"networks/critic/\"\n",
        "path_actor = \"networks/actor/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0PCfVFtse_Dz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PCfVFtse_Dz",
        "outputId": "9e0fffac-4e1f-45f7-9e05-2c73bb5f9192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created directories: networks/critic/ and networks/actor/\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(path_critic, exist_ok=True)\n",
        "os.makedirs(path_actor, exist_ok=True)\n",
        "print(f\"Created directories: {path_critic} and {path_actor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7097c7a9",
      "metadata": {
        "id": "7097c7a9"
      },
      "outputs": [],
      "source": [
        "# shared_critic.load_weights(path_critic + \"shared_critic.weights.h5\")\n",
        "# shared_actor.load_weights(path_actor + \"shared_actor.weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0226d7fd",
      "metadata": {
        "id": "0226d7fd"
      },
      "source": [
        "Let's instantiate our agents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0a9e27b4",
      "metadata": {
        "id": "0a9e27b4"
      },
      "outputs": [],
      "source": [
        "agent_1 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        ")\n",
        "agent_2 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea337a3",
      "metadata": {
        "id": "7ea337a3"
      },
      "source": [
        "Let's define our training loop! Let's go for now for a bootstrapping method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "85a8c642",
      "metadata": {},
      "outputs": [],
      "source": [
        "# shared_critic.load_weights(path_critic + \"shared_critic_deep_batch.weights.h5\")\n",
        "# shared_actor.load_weights(path_actor + \"shared_actor_deep_batch.weights.h5\")\n",
        "\n",
        "# shared_critic.save_weights(path_critic + \"shared_critic_deep_batch.weights.h5\")\n",
        "# shared_actor.save_weights(path_actor + \"shared_actor_deep_batch.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24ea87a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24ea87a8",
        "outputId": "d67c4b86-586a-4bdd-c30a-f7d99c635678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [  1] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.0\n",
            "Episode [  2] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 4.5\n",
            "Episode [  3] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.0\n",
            "Episode [  4] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 4.5\n",
            "Episode [  5] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 4.8\n",
            "Episode [  6] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.0\n",
            "Episode [  7] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 5.429\n",
            "Episode [  8] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.125\n",
            "Episode [  9] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 4.889\n",
            "Episode [ 10] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 4.4\n",
            "Episode [ 11] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 4.818\n",
            "Episode [ 12] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 5.083\n",
            "Episode [ 13] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 4.923\n",
            "Episode [ 14] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 4.786\n",
            "Episode [ 15] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 5.2\n",
            "Episode [ 16] terminated at timestep 400. cumulative reward:  20. updated: True. avg reward: 6.125\n",
            "Episode [ 17] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.941\n",
            "Episode [ 18] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.778\n",
            "Episode [ 19] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.632\n",
            "Episode [ 20] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.65\n",
            "Episode [ 21] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 6.143\n",
            "Episode [ 22] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.364\n",
            "Episode [ 23] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.565\n",
            "Episode [ 24] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.625\n",
            "Episode [ 25] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.48\n",
            "Episode [ 26] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 6.231\n",
            "Episode [ 27] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.111\n",
            "Episode [ 28] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.286\n",
            "Episode [ 29] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.172\n",
            "Episode [ 30] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.167\n",
            "Episode [ 31] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.226\n",
            "Episode [ 32] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.219\n",
            "Episode [ 33] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.121\n",
            "Episode [ 34] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 6.353\n",
            "Episode [ 35] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.343\n",
            "Episode [ 36] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.25\n",
            "Episode [ 37] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.162\n",
            "Episode [ 38] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 6.237\n",
            "Episode [ 39] terminated at timestep 400. cumulative reward:  22. updated: True. avg reward: 6.641\n",
            "Episode [ 40] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 6.825\n",
            "Episode [ 41] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.805\n",
            "Episode [ 42] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 6.976\n",
            "Episode [ 43] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.884\n",
            "Episode [ 44] terminated at timestep 400. cumulative reward:  25. updated: True. avg reward: 7.295\n",
            "Episode [ 45] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.444\n",
            "Episode [ 46] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.348\n",
            "Episode [ 47] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.489\n",
            "Episode [ 48] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.625\n",
            "Episode [ 49] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.755\n",
            "Episode [ 50] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.72\n",
            "Episode [ 51] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.843\n",
            "Episode [ 52] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.962\n",
            "Episode [ 53] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.075\n",
            "Episode [ 54] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.13\n",
            "Episode [ 55] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.273\n",
            "Episode [ 56] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.179\n",
            "Episode [ 57] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 8.368\n",
            "Episode [ 58] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.466\n",
            "Episode [ 59] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.593\n",
            "Episode [ 60] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.717\n",
            "Episode [ 61] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.672\n",
            "Episode [ 62] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.758\n",
            "Episode [ 63] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.841\n",
            "Episode [ 64] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.75\n",
            "Episode [ 65] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.708\n",
            "Episode [ 66] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.742\n",
            "Episode [ 67] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.776\n",
            "Episode [ 68] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.691\n",
            "Episode [ 69] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.797\n",
            "Episode [ 70] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.871\n",
            "Episode [ 71] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.831\n",
            "Episode [ 72] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.75\n",
            "Episode [ 73] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.822\n",
            "Episode [ 74] terminated at timestep 400. cumulative reward:  36. updated: True. avg reward: 9.189\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 75] terminated at timestep 400. cumulative reward:  28. updated: True. avg reward: 9.44\n",
            "Episode [ 76] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 9.434\n",
            "Episode [ 77] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.416\n",
            "Episode [ 78] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 9.538\n",
            "Episode [ 79] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.557\n",
            "Episode [ 80] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.612\n",
            "Episode [ 81] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 9.691\n",
            "Episode [ 82] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.744\n",
            "Episode [ 83] terminated at timestep 400. cumulative reward:  28. updated: True. avg reward: 9.964\n",
            "Episode [ 84] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.881\n",
            "Episode [ 85] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.859\n",
            "Episode [ 86] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.907\n",
            "Episode [ 87] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.862\n",
            "Episode [ 88] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.909\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 89] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.921\n",
            "Episode [ 90] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 10.022\n",
            "Episode [ 91] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.033\n",
            "Episode [ 92] terminated at timestep 400. cumulative reward:  25. updated: True. avg reward: 10.196\n",
            "Episode [ 93] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.237\n",
            "Episode [ 94] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 10.191\n",
            "Episode [ 95] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.2\n",
            "Episode [ 96] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.125\n",
            "Episode [ 97] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 10.216\n",
            "Episode [ 98] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.143\n",
            "Episode [ 99] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.152\n",
            "Episode [100] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 10.05\n",
            "Episode [101] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 10.03\n",
            "Episode [102] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.961\n",
            "Episode [103] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.893\n",
            "Episode [104] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.875\n",
            "Episode [105] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.81\n",
            "Episode [106] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.745\n",
            "Episode [107] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 9.804\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [108] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.815\n",
            "Episode [109] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.826\n",
            "Episode [110] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 9.882\n",
            "Episode [111] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.892\n",
            "Episode [112] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 9.804\n",
            "Episode [113] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.788\n",
            "Episode [114] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.772\n",
            "Episode [115] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.713\n",
            "Episode [116] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.655\n",
            "Episode [117] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.598\n",
            "Episode [118] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.636\n",
            "Episode [119] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.622\n",
            "Episode [120] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.658\n",
            "Episode [121] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.603\n",
            "Episode [122] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.574\n",
            "Episode [123] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.585\n",
            "Episode [124] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.573\n",
            "Episode [125] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.584\n",
            "Episode [126] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.556\n",
            "Episode [127] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.591\n",
            "Episode [128] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.602\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [129] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.612\n",
            "Episode [130] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.585\n",
            "Episode [131] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.573\n",
            "Episode [132] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.545\n",
            "Episode [133] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.496\n",
            "Episode [134] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.507\n",
            "Episode [135] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.541\n",
            "Episode [136] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 9.471\n",
            "Episode [137] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.423\n",
            "Episode [138] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.435\n",
            "Episode [139] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.388\n",
            "Episode [140] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.364\n",
            "Episode [141] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 9.411\n",
            "Episode [142] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.366\n",
            "Episode [143] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.322\n",
            "Episode [144] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.312\n",
            "Episode [145] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.345\n",
            "Episode [146] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.377\n",
            "Episode [147] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.333\n",
            "Episode [148] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.291\n",
            "Episode [149] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.248\n",
            "Episode [150] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.26\n",
            "Episode [151] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.252\n",
            "Episode [152] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.263\n",
            "Episode [153] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 9.203\n",
            "Episode [154] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 9.143\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [155] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.174\n",
            "Episode [156] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.154\n",
            "Episode [157] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.166\n",
            "Episode [158] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.127\n",
            "Episode [159] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.088\n",
            "Episode [160] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.05\n",
            "Episode [161] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.062\n",
            "Episode [162] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.025\n",
            "Episode [163] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.037\n",
            "Episode [164] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.03\n",
            "Episode [165] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.994\n",
            "Episode [166] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.958\n",
            "Episode [167] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.922\n",
            "Episode [168] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.887\n",
            "Episode [169] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.834\n",
            "Episode [170] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.847\n",
            "Episode [171] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.795\n",
            "Episode [172] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.779\n",
            "Episode [173] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.775\n",
            "Episode [174] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.787\n",
            "Episode [175] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.783\n",
            "Episode [176] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.767\n",
            "Episode [177] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.763\n",
            "Episode [178] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.713\n",
            "Episode [179] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.682\n",
            "Episode [180] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.65\n",
            "Episode [181] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.635\n",
            "Episode [182] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.604\n",
            "Episode [183] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.574\n",
            "Episode [184] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.56\n",
            "Episode [185] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.53\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [186] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.5\n",
            "Episode [187] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.471\n",
            "Episode [188] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.426\n",
            "Episode [189] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.413\n",
            "Episode [190] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.411\n",
            "Episode [191] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.382\n",
            "Episode [192] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.339\n",
            "Episode [193] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.295\n",
            "Episode [194] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.325\n",
            "Episode [195] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.282\n",
            "Episode [196] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.281\n",
            "Episode [197] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.269\n",
            "Episode [198] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.258\n",
            "Episode [199] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.256\n",
            "Episode [200] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.295\n",
            "Episode [201] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.269\n",
            "Episode [202] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.282\n",
            "Episode [203] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.256\n",
            "Episode [204] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.23\n",
            "Episode [205] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.205\n",
            "Episode [206] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.18\n",
            "Episode [207] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.179\n",
            "Episode [208] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.154\n",
            "Episode [209] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.129\n",
            "Episode [210] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.143\n",
            "Episode [211] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.104\n",
            "Episode [212] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.094\n",
            "Episode [213] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.07\n",
            "Episode [214] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.047\n",
            "Episode [215] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.037\n",
            "Episode [216] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.051\n",
            "Episode [217] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.051\n",
            "Episode [218] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.028\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [219] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.041\n",
            "Episode [220] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.018\n",
            "Episode [221] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.995\n",
            "Episode [222] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.973\n",
            "Episode [223] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.0\n",
            "Episode [224] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.991\n",
            "Episode [225] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.969\n",
            "Episode [226] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.934\n",
            "Episode [227] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.925\n",
            "Episode [228] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.925\n",
            "Episode [229] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.926\n",
            "Episode [230] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.904\n",
            "Episode [231] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.883\n",
            "Episode [232] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.884\n",
            "Episode [233] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.863\n",
            "Episode [234] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.842\n",
            "Episode [235] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.809\n",
            "Episode [236] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.809\n",
            "Episode [237] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.823\n",
            "Episode [238] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.803\n",
            "Episode [239] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.77\n",
            "Episode [240] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.75\n",
            "Episode [241] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.73\n",
            "Episode [242] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.711\n",
            "Episode [243] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.691\n",
            "Episode [244] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.693\n",
            "Episode [245] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.673\n",
            "Episode [246] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.654\n",
            "Episode [247] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.68\n",
            "Episode [248] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.661\n",
            "Episode [249] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.663\n",
            "Episode [250] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.644\n",
            "Episode [251] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.625\n",
            "Episode [252] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.627\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [253] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.621\n",
            "Episode [254] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.591\n",
            "Episode [255] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.561\n",
            "Episode [256] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.562\n",
            "Episode [257] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.576\n",
            "Episode [258] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.547\n",
            "Episode [259] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.571\n",
            "Episode [260] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.554\n",
            "Episode [261] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.536\n",
            "Episode [262] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.538\n",
            "Episode [263] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.551\n",
            "Episode [264] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.534\n",
            "Episode [265] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.536\n",
            "Episode [266] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.519\n",
            "Episode [267] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.502\n",
            "Episode [268] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.485\n",
            "Episode [269] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.48\n",
            "User interrupted training. Saving weights\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 1000\n",
        "number_of_epochs = 4\n",
        "batch_size = 10\n",
        "last_actor_call = 0 # debugging\n",
        "stop_calling = False # debugging\n",
        "average_reward = 0\n",
        "gamma = 0.95\n",
        "buffer_replay = {'observations': [],\n",
        "                 'actions': [],\n",
        "                 'deltas': []}\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        t = 0\n",
        "        obs = env.reset()\n",
        "        obs = obs['both_agent_obs'] # BRO I WAS TOO LAZY TO OVERRIDE OBS. DON'T FORGET IT\n",
        "\n",
        "        done = False\n",
        "        shaped_reward_factor = 1 # multiplicative factor for discounting shaped reward.\n",
        "        discount_rate = 1 # will decrease the shaped reward every time\n",
        "        cumulative_reward = 0\n",
        "        updated = False\n",
        "\n",
        "        if stop_calling: # debugging\n",
        "            break # debugging\n",
        "\n",
        "        if (episode) % 50 == 0:\n",
        "            shared_critic.save_weights(path_critic + \"shared_critic_exp_1.weights.h5\")\n",
        "            shared_actor.save_weights(path_actor + \"shared_actor_exp_1.weights.h5\")\n",
        "\n",
        "        while not done:\n",
        "            action1 = agent_1.action(obs)\n",
        "            action2 = agent_2.action(obs)\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            action = (player_1_action, player_2_action)\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            new_obs = new_obs['both_agent_obs']\n",
        "\n",
        "            if shaped_reward != 0:\n",
        "                shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "                shaped_reward_factor *= discount_rate\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            if done:\n",
        "                delta = total_reward - shared_critic.call(obs)\n",
        "            else:\n",
        "                delta = total_reward + gamma*shared_critic.call(new_obs) - shared_critic.call(obs)\n",
        "\n",
        "            if not stop_calling: # debugging\n",
        "                last_actor_call = shared_actor.call(obs) # debugging\n",
        "\n",
        "            # adding experience to the buffer replay if it is a good experience\n",
        "            # let's try to understand what is a good experience (high reward, high delta...)\n",
        "            if total_reward > 0:\n",
        "                buffer_replay['observations'].append(obs)\n",
        "                buffer_replay['deltas'].append(delta)\n",
        "                buffer_replay['actions'].append(action)\n",
        "            \n",
        "            if len(buffer_replay['observations']) > 200:\n",
        "                print(f\"Performing {number_of_epochs} epochs of stocastic gradient descent on the replay buffer.\")\n",
        "                for epoch in range(1, number_of_epochs + 1):\n",
        "                    num_batches = len(buffer_replay['observations']) // batch_size\n",
        "                    shuffled_indices = tf.random.shuffle(tf.range(len(buffer_replay['observations'])))\n",
        "                    for batch in range(num_batches):\n",
        "                        if batch == num_batches: # last batch\n",
        "                            idx = shuffled_indices[batch*batch_size:]\n",
        "                        else:\n",
        "                            idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                        deltas_batch = tf.squeeze(tf.gather(buffer_replay['deltas'], idx), axis=-1)\n",
        "                        actions_batch = tf.gather(buffer_replay['actions'], idx)\n",
        "                        observations_batch = tf.gather(buffer_replay['observations'], idx)\n",
        "\n",
        "                        # shared_critic.train_batch(deltas_batch, observations_batch)\n",
        "                        shared_actor.train_batch(deltas_batch, observations_batch, actions_batch)\n",
        "                    print(f\"Epoch {epoch} terminated.\")\n",
        "                buffer_replay['observations'] = buffer_replay['observations'][50:]\n",
        "                buffer_replay['actions'] = buffer_replay['actions'][50:]\n",
        "                buffer_replay['deltas'] = buffer_replay['deltas'][50:]\n",
        "\n",
        "            if delta != 0:\n",
        "                updated = True\n",
        "                # update w with w + alpha_w*delta*grad_v^(St)\n",
        "                shared_critic.train_step(delta, obs)\n",
        "                # update t with t + alpha_t*delta*grad_pi^(A|S) where A is the action taken before reaching St+1\n",
        "                shared_actor.train_step(delta, obs, action)\n",
        "\n",
        "                # DEBUGGING\n",
        "                if not np.sum(shared_actor.call(obs)[1].numpy()) > 0.9:\n",
        "                    print(delta)\n",
        "                    stop_calling = True\n",
        "                    break\n",
        "                # END DEBUGGING\n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            # think about training the critic by itself for a while\n",
        "            t += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. updated: {updated}. avg reward: {round(average_reward, 3)}\")\n",
        "        # shared_critic.save_weights(path_critic + \"shared_critic.weights.h5\")\n",
        "        # shared_actor.save_weights(path_actor + \"shared_actor.weights.h5\")\n",
        "except KeyboardInterrupt:\n",
        "    shared_critic.save_weights(path_critic + \"shared_critic_exp_1.weights.h5\")\n",
        "    shared_actor.save_weights(path_actor + \"shared_actor_exp_1.weights.h5\")\n",
        "    print(\"User interrupted training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e25868",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7b6aea1e58e14dcca9cf57ca1ee27a32"
          ]
        },
        "id": "d9e25868",
        "outputId": "4f1d760c-915e-4fcf-a5eb-b2d887bcd226"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 4.00 (std: 8.00, se: 2.53); avg len: 400.00; : 100%|██████████| 10/10 [00:58<00:00,  5.86s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54039eb99f594796b4c5c1fc31773483",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "# trajs = ae.evaluate_human_model_pair(1)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffd4221b",
      "metadata": {},
      "source": [
        "# Without experience replay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "49a49265",
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5d985564",
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha_w = 1e-5\n",
        "alpha_t = 1e-6\n",
        "critic_optimizer = Adam(learning_rate=alpha_w)\n",
        "actor_optimizer = Adam(learning_rate=alpha_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "af61f18c",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=actor_optimizer\n",
        "    )\n",
        "\n",
        "shared_critic = ValueFunctionApproximator(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=critic_optimizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "04fe446d",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_1 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        ")\n",
        "agent_2 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "bdef36fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [  1] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 0.0\n",
            "Episode [  2] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 4.5\n",
            "Episode [  3] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 4.0\n",
            "Episode [  4] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 3.75\n",
            "Episode [  5] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 4.2\n",
            "Episode [  6] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 4.5\n",
            "Episode [  7] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 5.429\n",
            "Episode [  8] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 6.5\n",
            "Episode [  9] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.444\n",
            "Episode [ 10] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.4\n",
            "Episode [ 11] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.364\n",
            "Episode [ 12] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.333\n",
            "Episode [ 13] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.308\n",
            "Episode [ 14] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.286\n",
            "Episode [ 15] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.867\n",
            "Episode [ 16] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.0\n",
            "Episode [ 17] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 6.176\n",
            "Episode [ 18] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 6.333\n",
            "Episode [ 19] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.158\n",
            "Episode [ 20] terminated at timestep 400. cumulative reward:  17. updated: True. avg reward: 6.7\n",
            "Episode [ 21] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.048\n",
            "Episode [ 22] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.091\n",
            "Episode [ 23] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.391\n",
            "Episode [ 24] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.417\n",
            "Episode [ 25] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.24\n",
            "Episode [ 26] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.5\n",
            "Episode [ 27] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 7.815\n",
            "Episode [ 28] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.643\n",
            "Episode [ 29] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.483\n",
            "Episode [ 30] terminated at timestep 400. cumulative reward:  17. updated: True. avg reward: 7.8\n",
            "Episode [ 31] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.0\n",
            "Episode [ 32] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.25\n",
            "Episode [ 33] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.182\n",
            "Episode [ 34] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.029\n",
            "Episode [ 35] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.257\n",
            "Episode [ 36] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 8.556\n",
            "Episode [ 37] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.703\n",
            "Episode [ 38] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.763\n",
            "Episode [ 39] terminated at timestep 400. cumulative reward:  17. updated: True. avg reward: 8.974\n",
            "Episode [ 40] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.9\n",
            "Episode [ 41] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.756\n",
            "Episode [ 42] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.81\n",
            "Episode [ 43] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.744\n",
            "Episode [ 44] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.795\n",
            "Episode [ 45] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 9.022\n",
            "Episode [ 46] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.891\n",
            "Episode [ 47] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.936\n",
            "Episode [ 48] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 9.083\n",
            "Episode [ 49] terminated at timestep 400. cumulative reward:  20. updated: True. avg reward: 9.306\n",
            "Episode [ 50] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 9.5\n",
            "Episode [ 51] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 9.686\n",
            "Episode [ 52] terminated at timestep 400. cumulative reward:  25. updated: True. avg reward: 9.981\n",
            "Episode [ 53] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.849\n",
            "Episode [ 54] terminated at timestep 400. cumulative reward:  20. updated: True. avg reward: 10.037\n",
            "Episode [ 55] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 10.0\n",
            "Episode [ 56] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.875\n",
            "Episode [ 57] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 10.035\n",
            "Episode [ 58] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.103\n",
            "Episode [ 59] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.119\n",
            "Episode [ 60] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.133\n",
            "Episode [ 61] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 10.23\n",
            "Episode [ 62] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 10.371\n",
            "Episode [ 63] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 10.302\n",
            "Episode [ 64] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.312\n",
            "Episode [ 65] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.369\n",
            "Episode [ 66] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.258\n",
            "Episode [ 67] terminated at timestep 400. cumulative reward:  22. updated: True. avg reward: 10.433\n",
            "Episode [ 68] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.441\n",
            "Episode [ 69] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.333\n",
            "Episode [ 70] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.386\n",
            "Episode [ 71] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.282\n",
            "Episode [ 72] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.181\n",
            "Episode [ 73] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 10.041\n",
            "Episode [ 74] terminated at timestep 400. cumulative reward:  30. updated: True. avg reward: 10.311\n",
            "Episode [ 75] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.213\n",
            "Episode [ 76] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.118\n",
            "Episode [ 77] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 10.234\n",
            "Episode [ 78] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.244\n",
            "Episode [ 79] terminated at timestep 400. cumulative reward:  25. updated: True. avg reward: 10.43\n",
            "Episode [ 80] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 10.438\n",
            "Episode [ 81] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.481\n",
            "Episode [ 82] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.39\n",
            "Episode [ 83] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.434\n",
            "Episode [ 84] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.345\n",
            "Episode [ 85] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.259\n",
            "Episode [ 86] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.302\n",
            "Episode [ 87] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.218\n",
            "Episode [ 88] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.261\n",
            "Episode [ 89] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.18\n",
            "Episode [ 90] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 10.156\n",
            "Episode [ 91] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 10.132\n",
            "Episode [ 92] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 10.054\n",
            "Episode [ 93] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.978\n",
            "Episode [ 94] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.904\n",
            "Episode [ 95] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.916\n",
            "Episode [ 96] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.896\n",
            "Episode [ 97] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.825\n",
            "Episode [ 98] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.867\n",
            "Episode [ 99] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.879\n",
            "Episode [100] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.89\n",
            "Episode [101] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.822\n",
            "Episode [102] terminated at timestep 400. cumulative reward:  17. updated: True. avg reward: 9.892\n",
            "Episode [103] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.903\n",
            "Episode [104] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 9.962\n",
            "Episode [105] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.924\n",
            "Episode [106] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.858\n",
            "Episode [107] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.841\n",
            "Episode [108] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.852\n",
            "Episode [109] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.789\n",
            "Episode [110] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.727\n",
            "Episode [111] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.694\n",
            "Episode [112] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.705\n",
            "Episode [113] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.646\n",
            "Episode [114] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.684\n",
            "Episode [115] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.626\n",
            "Episode [116] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.595\n",
            "Episode [117] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.538\n",
            "Episode [118] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 9.458\n",
            "Episode [119] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.403\n",
            "Episode [120] terminated at timestep 400. cumulative reward:  17. updated: True. avg reward: 9.467\n",
            "Episode [121] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.455\n",
            "Episode [122] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.426\n",
            "Episode [123] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.374\n",
            "Episode [124] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.411\n",
            "Episode [125] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.36\n",
            "Episode [126] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.373\n",
            "Episode [127] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.323\n",
            "Episode [128] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 9.297\n",
            "Episode [129] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.248\n",
            "Episode [130] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.2\n",
            "Episode [131] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.153\n",
            "Episode [132] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.106\n",
            "Episode [133] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.143\n",
            "Episode [134] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.097\n",
            "Episode [135] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 9.089\n",
            "Episode [136] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.103\n",
            "Episode [137] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.117\n",
            "Episode [138] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.072\n",
            "Episode [139] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 9.108\n",
            "Episode [140] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 9.121\n",
            "Episode [141] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 9.078\n",
            "Episode [142] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 9.014\n",
            "Episode [143] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.972\n",
            "Episode [144] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.931\n",
            "Episode [145] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.89\n",
            "Episode [146] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.904\n",
            "Episode [147] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.898\n",
            "Episode [148] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.858\n",
            "Episode [149] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.852\n",
            "Episode [150] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.867\n",
            "Episode [151] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.861\n",
            "Episode [152] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.822\n",
            "Episode [153] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.837\n",
            "Episode [154] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.799\n",
            "Episode [155] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.794\n",
            "Episode [156] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 8.795\n",
            "Episode [157] terminated at timestep 400. cumulative reward:  22. updated: True. avg reward: 8.879\n",
            "Episode [158] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.873\n",
            "Episode [159] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.836\n",
            "Episode [160] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.85\n",
            "Episode [161] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.832\n",
            "Episode [162] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.827\n",
            "Episode [163] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.84\n",
            "Episode [164] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.835\n",
            "Episode [165] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.8\n",
            "Episode [166] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.831\n",
            "Episode [167] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.844\n",
            "Episode [168] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.839\n",
            "Episode [169] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.805\n",
            "Episode [170] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.847\n",
            "Episode [171] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.813\n",
            "Episode [172] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.779\n",
            "Episode [173] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.728\n",
            "Episode [174] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.695\n",
            "Episode [175] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.691\n",
            "Episode [176] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.733\n",
            "Episode [177] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.701\n",
            "Episode [178] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.652\n",
            "Episode [179] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.665\n",
            "Episode [180] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.633\n",
            "Episode [181] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.63\n",
            "Episode [182] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 8.687\n",
            "Episode [183] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.639\n",
            "Episode [184] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.609\n",
            "Episode [185] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.578\n",
            "Episode [186] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.591\n",
            "Episode [187] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.545\n",
            "Episode [188] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.516\n",
            "Episode [189] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.487\n",
            "Episode [190] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.458\n",
            "Episode [191] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.445\n",
            "Episode [192] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.458\n",
            "Episode [193] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.43\n",
            "Episode [194] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.387\n",
            "Episode [195] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.359\n",
            "Episode [196] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.316\n",
            "Episode [197] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.289\n",
            "Episode [198] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.303\n",
            "Episode [199] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.302\n",
            "Episode [200] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.3\n",
            "Episode [201] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.274\n",
            "Episode [202] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.233\n",
            "Episode [203] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.246\n",
            "Episode [204] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.221\n",
            "Episode [205] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.21\n",
            "Episode [206] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.238\n",
            "Episode [207] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.198\n",
            "Episode [208] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.159\n",
            "Episode [209] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.134\n",
            "Episode [210] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 8.171\n",
            "Episode [211] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.133\n",
            "Episode [212] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.094\n",
            "Episode [213] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.056\n",
            "Episode [214] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.033\n",
            "Episode [215] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.033\n",
            "Episode [216] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 8.032\n",
            "Episode [217] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.009\n",
            "Episode [218] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.972\n",
            "Episode [219] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.936\n",
            "Episode [220] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.914\n",
            "Episode [221] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.878\n",
            "Episode [222] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.856\n",
            "Episode [223] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.834\n",
            "Episode [224] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.812\n",
            "Episode [225] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.791\n",
            "Episode [226] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.77\n",
            "Episode [227] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.749\n",
            "Episode [228] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.728\n",
            "Episode [229] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.707\n",
            "Episode [230] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.687\n",
            "Episode [231] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.667\n",
            "Episode [232] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.647\n",
            "Episode [233] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.648\n",
            "Episode [234] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.628\n",
            "Episode [235] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.609\n",
            "Episode [236] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.623\n",
            "Episode [237] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 7.658\n",
            "Episode [238] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.626\n",
            "Episode [239] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.607\n",
            "Episode [240] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.633\n",
            "Episode [241] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.614\n",
            "Episode [242] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.595\n",
            "Episode [243] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.576\n",
            "Episode [244] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.557\n",
            "Episode [245] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.539\n",
            "Episode [246] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.533\n",
            "Episode [247] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.514\n",
            "Episode [248] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.516\n",
            "Episode [249] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.51\n",
            "Episode [250] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.504\n",
            "Episode [251] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.486\n",
            "Episode [252] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.468\n",
            "Episode [253] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.451\n",
            "Episode [254] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.453\n",
            "Episode [255] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.455\n",
            "Episode [256] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.449\n",
            "Episode [257] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.42\n",
            "Episode [258] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.403\n",
            "Episode [259] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.386\n",
            "Episode [260] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.388\n",
            "Episode [261] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.391\n",
            "Episode [262] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.405\n",
            "Episode [263] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 7.437\n",
            "Episode [264] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.439\n",
            "Episode [265] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.411\n",
            "Episode [266] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.395\n",
            "Episode [267] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.378\n",
            "Episode [268] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.362\n",
            "Episode [269] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.364\n",
            "Episode [270] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.348\n",
            "Episode [271] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.343\n",
            "Episode [272] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.327\n",
            "Episode [273] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.33\n",
            "Episode [274] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.314\n",
            "Episode [275] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.316\n",
            "Episode [276] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.301\n",
            "Episode [277] terminated at timestep 400. cumulative reward:  22. updated: True. avg reward: 7.354\n",
            "Episode [278] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.338\n",
            "Episode [279] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.323\n",
            "Episode [280] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.346\n",
            "Episode [281] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.331\n",
            "Episode [282] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.316\n",
            "Episode [283] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.29\n",
            "Episode [284] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.303\n",
            "Episode [285] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.305\n",
            "Episode [286] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.308\n",
            "Episode [287] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.293\n",
            "Episode [288] terminated at timestep 400. cumulative reward:  17. updated: True. avg reward: 7.326\n",
            "Episode [289] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.311\n",
            "Episode [290] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.297\n",
            "Episode [291] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.299\n",
            "Episode [292] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.284\n",
            "Episode [293] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.307\n",
            "Episode [294] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.31\n",
            "Episode [295] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.312\n",
            "Episode [296] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.297\n",
            "Episode [297] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.31\n",
            "Episode [298] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.295\n",
            "Episode [299] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.281\n",
            "Episode [300] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.267\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 300\n",
        "number_of_epochs = 4\n",
        "batch_size = 10\n",
        "last_actor_call = 0 # debugging\n",
        "stop_calling = False # debugging\n",
        "average_reward = 0\n",
        "gamma = 0.95\n",
        "\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        t = 0\n",
        "        obs = env.reset()\n",
        "        obs = obs['both_agent_obs'] # BRO I WAS TOO LAZY TO OVERRIDE OBS. DON'T FORGET IT\n",
        "\n",
        "        done = False\n",
        "        shaped_reward_factor = 1 # multiplicative factor for discounting shaped reward.\n",
        "        discount_rate = 1 # will decrease the shaped reward every time\n",
        "        cumulative_reward = 0\n",
        "        updated = False\n",
        "\n",
        "        if stop_calling: # debugging\n",
        "            break # debugging\n",
        "\n",
        "        if (episode) % 50 == 0:\n",
        "            shared_critic.save_weights(path_critic + \"shared_critic_exp_1_2.weights.h5\")\n",
        "            shared_actor.save_weights(path_actor + \"shared_actor_exp_1_2.weights.h5\")\n",
        "\n",
        "        while not done:\n",
        "            action1 = agent_1.action(obs)\n",
        "            action2 = agent_2.action(obs)\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            action = (player_1_action, player_2_action)\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            new_obs = new_obs['both_agent_obs']\n",
        "\n",
        "            if shaped_reward != 0:\n",
        "                shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "                shaped_reward_factor *= discount_rate\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            if done:\n",
        "                delta = total_reward - shared_critic.call(obs)\n",
        "            else:\n",
        "                delta = total_reward + gamma*shared_critic.call(new_obs) - shared_critic.call(obs)\n",
        "\n",
        "            if not stop_calling: # debugging\n",
        "                last_actor_call = shared_actor.call(obs) # debugging\n",
        "\n",
        "            # adding experience to the buffer replay if it is a good experience\n",
        "            \n",
        "\n",
        "            if delta != 0:\n",
        "                updated = True\n",
        "                # update w with w + alpha_w*delta*grad_v^(St)\n",
        "                shared_critic.train_step(delta, obs)\n",
        "                # update t with t + alpha_t*delta*grad_pi^(A|S) where A is the action taken before reaching St+1\n",
        "                shared_actor.train_step(delta, obs, action)\n",
        "\n",
        "                # DEBUGGING\n",
        "                if not np.sum(shared_actor.call(obs)[1].numpy()) > 0.9:\n",
        "                    print(delta)\n",
        "                    stop_calling = True\n",
        "                    break\n",
        "                # END DEBUGGING\n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            # think about training the critic by itself for a while\n",
        "            t += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. updated: {updated}. avg reward: {round(average_reward, 3)}\")\n",
        "        # shared_critic.save_weights(path_critic + \"shared_critic.weights.h5\")\n",
        "        # shared_actor.save_weights(path_actor + \"shared_actor.weights.h5\")\n",
        "except KeyboardInterrupt:\n",
        "    shared_critic.save_weights(path_critic + \"shared_critic_exp_1_2.weights.h5\")\n",
        "    shared_actor.save_weights(path_actor + \"shared_actor_exp_1_2.weights.h5\")\n",
        "    print(\"User interrupted training. Saving weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233a2332",
      "metadata": {},
      "source": [
        "# Let's see the RandomAgent average reward to see whether my algorithm is learning something or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522c422a",
      "metadata": {},
      "outputs": [],
      "source": [
        "random_agent_1 = RandomAgent(all_actions=True)\n",
        "random_agent_2 = RandomAgent(all_actions=True)\n",
        "number_of_episodes = 100\n",
        "average_reward = 0\n",
        "for episode in range(1, number_of_episodes + 1):\n",
        "    t = 0\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    cumulative_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action1 = random_agent_1.action(obs)\n",
        "        action2 = random_agent_2.action(obs)\n",
        "        player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "        player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "        action = (player_1_action, player_2_action)\n",
        "\n",
        "        new_obs, reward, done, env_info = env.step(action)\n",
        "        shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "        total_reward = reward + shaped_reward\n",
        "\n",
        "        cumulative_reward += total_reward\n",
        "\n",
        "        obs = new_obs\n",
        "\n",
        "        # think about training the critic by itself for a while\n",
        "        t += 1\n",
        "\n",
        "    average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "    print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. avg reward: {round(average_reward, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f6da1d0",
      "metadata": {},
      "source": [
        "Random baseline: avg reward = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c6674fd",
      "metadata": {},
      "source": [
        "# Trial ordered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f7e7de4",
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "febcee67",
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha_w = 1e-5\n",
        "alpha_t = 1e-6\n",
        "critic_optimizer = Adam(learning_rate=alpha_w)\n",
        "actor_optimizer = Adam(learning_rate=alpha_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7e84c95f",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=actor_optimizer\n",
        "    )\n",
        "\n",
        "shared_critic = ValueFunctionApproximator(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=critic_optimizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3ed6ca25",
      "metadata": {},
      "outputs": [],
      "source": [
        "path_critic = \"networks/critic/\"\n",
        "path_actor = \"networks/actor/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "cc806c13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created directories: networks/critic/ and networks/actor/\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(path_critic, exist_ok=True)\n",
        "os.makedirs(path_actor, exist_ok=True)\n",
        "print(f\"Created directories: {path_critic} and {path_actor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1703bb91",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_1 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        ")\n",
        "agent_2 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0dadb389",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [  1] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.0\n",
            "Episode [  2] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 10.0\n",
            "Episode [  3] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.667\n",
            "Episode [  4] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.5\n",
            "Episode [  5] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.8\n",
            "Episode [  6] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.167\n",
            "Episode [  7] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.714\n",
            "Episode [  8] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.75\n",
            "Episode [  9] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.778\n",
            "Episode [ 10] terminated at timestep 400. cumulative reward:  20. updated: True. avg reward: 7.2\n",
            "Episode [ 11] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.091\n",
            "Episode [ 12] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.667\n",
            "Episode [ 13] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.308\n",
            "Episode [ 14] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.0\n",
            "Episode [ 15] terminated at timestep 400. cumulative reward:  19. updated: True. avg reward: 7.8\n",
            "Episode [ 16] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.188\n",
            "Episode [ 17] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.353\n",
            "Episode [ 18] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.222\n",
            "Episode [ 19] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 8.263\n",
            "Episode [ 20] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.0\n",
            "Episode [ 21] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 8.143\n",
            "Episode [ 22] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.045\n",
            "Episode [ 23] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.826\n",
            "Episode [ 24] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.625\n",
            "Episode [ 25] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 7.68\n",
            "Episode [ 26] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.808\n",
            "Episode [ 27] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.741\n",
            "Episode [ 28] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.679\n",
            "Episode [ 29] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.621\n",
            "Episode [ 30] terminated at timestep 400. cumulative reward:  20. updated: True. avg reward: 8.033\n",
            "Episode [ 31] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.226\n",
            "Episode [ 32] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.156\n",
            "Episode [ 33] terminated at timestep 400. cumulative reward:  17. updated: True. avg reward: 8.424\n",
            "Episode [ 34] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.265\n",
            "Episode [ 35] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.114\n",
            "Episode [ 36] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.278\n",
            "Episode [ 37] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.432\n",
            "Episode [ 38] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.289\n",
            "Episode [ 39] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.231\n",
            "Episode [ 40] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.375\n",
            "Episode [ 41] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 8.171\n",
            "Episode [ 42] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.048\n",
            "Episode [ 43] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 8.07\n",
            "Episode [ 44] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.955\n",
            "Episode [ 45] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.089\n",
            "Episode [ 46] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.978\n",
            "Episode [ 47] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.979\n",
            "Episode [ 48] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.104\n",
            "Episode [ 49] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 8.061\n",
            "Episode [ 50] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 8.18\n",
            "Episode [ 51] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 8.078\n",
            "Episode [ 52] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.981\n",
            "Episode [ 53] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.887\n",
            "Episode [ 54] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.741\n",
            "Episode [ 55] terminated at timestep 400. cumulative reward:  17. updated: True. avg reward: 7.909\n",
            "Episode [ 56] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.875\n",
            "Episode [ 57] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.789\n",
            "Episode [ 58] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.707\n",
            "Episode [ 59] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.576\n",
            "Episode [ 60] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.55\n",
            "Episode [ 61] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.607\n",
            "Episode [ 62] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.581\n",
            "Episode [ 63] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.46\n",
            "Episode [ 64] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.437\n",
            "Episode [ 65] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.369\n",
            "Episode [ 66] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.379\n",
            "Episode [ 67] terminated at timestep 400. cumulative reward:   9. updated: True. avg reward: 7.403\n",
            "Episode [ 68] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.382\n",
            "Episode [ 69] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.391\n",
            "Episode [ 70] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.486\n",
            "Episode [ 71] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.465\n",
            "Episode [ 72] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.444\n",
            "Episode [ 73] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.534\n",
            "Episode [ 74] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.541\n",
            "Episode [ 75] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.587\n",
            "Episode [ 76] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.526\n",
            "Episode [ 77] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.468\n",
            "Episode [ 78] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.41\n",
            "Episode [ 79] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.316\n",
            "Episode [ 80] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.4\n",
            "Episode [ 81] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 7.481\n",
            "Episode [ 82] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.427\n",
            "Episode [ 83] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.337\n",
            "Episode [ 84] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.286\n",
            "Episode [ 85] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 7.2\n",
            "Episode [ 86] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 7.244\n",
            "Episode [ 87] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.195\n",
            "Episode [ 88] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 7.182\n",
            "Episode [ 89] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.135\n",
            "Episode [ 90] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.089\n",
            "Episode [ 91] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.044\n",
            "Episode [ 92] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 7.0\n",
            "Episode [ 93] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 7.011\n",
            "Episode [ 94] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.968\n",
            "Episode [ 95] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.958\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 96] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.948\n",
            "Episode [ 97] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.907\n",
            "Episode [ 98] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.867\n",
            "Episode [ 99] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.828\n",
            "Episode [100] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.79\n",
            "Episode [101] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.832\n",
            "Episode [102] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.873\n",
            "Episode [103] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 6.806\n",
            "Episode [104] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.769\n",
            "Episode [105] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.733\n",
            "Episode [106] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.698\n",
            "Episode [107] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.692\n",
            "Episode [108] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.704\n",
            "Episode [109] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.67\n",
            "Episode [110] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.664\n",
            "Episode [111] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.658\n",
            "Episode [112] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.652\n",
            "Episode [113] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 6.593\n",
            "Episode [114] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.632\n",
            "Episode [115] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.626\n",
            "Episode [116] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.595\n",
            "Episode [117] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.564\n",
            "Episode [118] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.559\n",
            "Episode [119] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.529\n",
            "Episode [120] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.542\n",
            "Episode [121] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.537\n",
            "Episode [122] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.508\n",
            "Episode [123] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.48\n",
            "Episode [124] terminated at timestep 400. cumulative reward:  16. updated: True. avg reward: 6.556\n",
            "Episode [125] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.552\n",
            "Episode [126] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.524\n",
            "Episode [127] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.496\n",
            "Episode [128] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 6.445\n",
            "Episode [129] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.419\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [130] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.392\n",
            "Episode [131] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.427\n",
            "Episode [132] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.424\n",
            "Episode [133] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.421\n",
            "Episode [134] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 6.373\n",
            "Episode [135] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 6.43\n",
            "Episode [136] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.426\n",
            "Episode [137] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.423\n",
            "Episode [138] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.399\n",
            "Episode [139] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.374\n",
            "Episode [140] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.407\n",
            "Episode [141] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.44\n",
            "Episode [142] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.415\n",
            "Episode [143] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.448\n",
            "Episode [144] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.458\n",
            "Episode [145] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.434\n",
            "Episode [146] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.411\n",
            "Episode [147] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.388\n",
            "Episode [148] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.365\n",
            "Episode [149] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.342\n",
            "Episode [150] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.32\n",
            "Episode [151] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.318\n",
            "Episode [152] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.296\n",
            "Episode [153] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.275\n",
            "Episode [154] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.253\n",
            "Episode [155] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.252\n",
            "Episode [156] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.282\n",
            "Episode [157] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.261\n",
            "Episode [158] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.272\n",
            "Episode [159] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.252\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [160] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.231\n",
            "Episode [161] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.261\n",
            "Episode [162] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.241\n",
            "Episode [163] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.221\n",
            "Episode [164] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.201\n",
            "Episode [165] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.2\n",
            "Episode [166] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.199\n",
            "Episode [167] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.21\n",
            "Episode [168] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.19\n",
            "Episode [169] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.172\n",
            "Episode [170] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 6.135\n",
            "Episode [171] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.135\n",
            "Episode [172] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.116\n",
            "Episode [173] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 6.145\n",
            "Episode [174] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.126\n",
            "Episode [175] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 6.091\n",
            "Episode [176] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.074\n",
            "Episode [177] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.056\n",
            "Episode [178] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.039\n",
            "Episode [179] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 6.022\n",
            "Episode [180] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 6.033\n",
            "Episode [181] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 6.033\n",
            "Episode [182] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 6.0\n",
            "Episode [183] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.984\n",
            "Episode [184] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.967\n",
            "Episode [185] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.968\n",
            "Episode [186] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.952\n",
            "Episode [187] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.936\n",
            "Episode [188] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.904\n",
            "Episode [189] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 5.915\n",
            "Episode [190] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.9\n",
            "Episode [191] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.885\n",
            "Episode [192] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.87\n",
            "Episode [193] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 5.896\n",
            "Episode [194] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.881\n",
            "Episode [195] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.882\n",
            "Episode [196] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.852\n",
            "Episode [197] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.838\n",
            "Performing 4 epochs of stocastic gradient descent on the replay buffer.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [198] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 5.864\n",
            "Episode [199] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.849\n",
            "Episode [200] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 5.86\n",
            "Episode [201] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.846\n",
            "Episode [202] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.832\n",
            "Episode [203] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.818\n",
            "Episode [204] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.804\n",
            "Episode [205] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.776\n",
            "Episode [206] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.762\n",
            "Episode [207] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.763\n",
            "Episode [208] terminated at timestep 400. cumulative reward:  14. updated: True. avg reward: 5.803\n",
            "Episode [209] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.789\n",
            "Episode [210] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.776\n",
            "Episode [211] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.763\n",
            "Episode [212] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.75\n",
            "Episode [213] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.737\n",
            "Episode [214] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.724\n",
            "Episode [215] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.712\n",
            "Episode [216] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.699\n",
            "Episode [217] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.673\n",
            "Episode [218] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.661\n",
            "Episode [219] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.648\n",
            "Episode [220] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.636\n",
            "Episode [221] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.611\n",
            "Episode [222] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.599\n",
            "Episode [223] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 5.61\n",
            "Episode [224] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.585\n",
            "Episode [225] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.56\n",
            "Episode [226] terminated at timestep 400. cumulative reward:  11. updated: True. avg reward: 5.584\n",
            "Episode [227] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.559\n",
            "Episode [228] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.561\n",
            "Episode [229] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.537\n",
            "Episode [230] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.526\n",
            "Episode [231] terminated at timestep 400. cumulative reward:   8. updated: True. avg reward: 5.537\n",
            "Episode [232] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.513\n",
            "Episode [233] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.502\n",
            "Episode [234] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.491\n",
            "Episode [235] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.481\n",
            "Episode [236] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.47\n",
            "Episode [237] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.46\n",
            "Episode [238] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.45\n",
            "Episode [239] terminated at timestep 400. cumulative reward:   6. updated: True. avg reward: 5.452\n",
            "Episode [240] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.429\n",
            "Episode [241] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.407\n",
            "Episode [242] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.397\n",
            "Episode [243] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.387\n",
            "Episode [244] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.365\n",
            "Episode [245] terminated at timestep 400. cumulative reward:   0. updated: True. avg reward: 5.343\n",
            "Episode [246] terminated at timestep 400. cumulative reward:   3. updated: True. avg reward: 5.333\n",
            "User interrupted training. Saving weights\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 300\n",
        "number_of_epochs = 4\n",
        "batch_size = 10\n",
        "last_actor_call = 0 # debugging\n",
        "stop_calling = False # debugging\n",
        "average_reward = 0\n",
        "gamma = 0.95\n",
        "buffer_replay = {'observations': [],\n",
        "                 'actions': [],\n",
        "                 'deltas': []}\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        t = 0\n",
        "        obs = env.reset()\n",
        "\n",
        "        done = False\n",
        "        shaped_reward_factor = 1 # multiplicative factor for discounting shaped reward.\n",
        "        discount_rate = 1 # will decrease the shaped reward every time\n",
        "        cumulative_reward = 0\n",
        "        updated = False\n",
        "\n",
        "        if stop_calling: # debugging\n",
        "            break # debugging\n",
        "\n",
        "        if (episode) % 50 == 0:\n",
        "            shared_critic.save_weights(path_critic + \"shared_critic_exp_2.weights.h5\")\n",
        "            shared_actor.save_weights(path_actor + \"shared_actor_exp_2.weights.h5\")\n",
        "\n",
        "        while not done:\n",
        "            action1 = agent_1.action(obs['both_agent_obs'])\n",
        "            action2 = agent_2.action(obs['both_agent_obs'])\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            action = (player_1_action, player_2_action)\n",
        "\n",
        "            if obs['other_agent_env_idx'] == 0:\n",
        "                my_obs = (obs['both_agent_obs'][1],obs['both_agent_obs'][0])\n",
        "                obs['both_agent_obs'] = my_obs # BRO I WAS TOO LAZY TO OVERRIDE OBS. DON'T FORGET IT\n",
        "                action = (player_2_action, player_1_action)\n",
        "            else:\n",
        "                action = (player_1_action, player_2_action)\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            if shaped_reward != 0:\n",
        "                shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "                shaped_reward_factor *= discount_rate\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            if done:\n",
        "                delta = total_reward - shared_critic.call(obs['both_agent_obs'])\n",
        "            else:\n",
        "                delta = total_reward + gamma*shared_critic.call(new_obs['both_agent_obs']) - shared_critic.call(obs['both_agent_obs'])\n",
        "\n",
        "            if not stop_calling: # debugging\n",
        "                last_actor_call = shared_actor.call(obs['both_agent_obs']) # debugging\n",
        "\n",
        "            # adding experience to the buffer replay if it is a good experience\n",
        "            # let's try to understand what is a good experience (high reward, high delta...)\n",
        "            if total_reward > 0:\n",
        "                buffer_replay['observations'].append(obs['both_agent_obs'])\n",
        "                buffer_replay['deltas'].append(delta)\n",
        "                buffer_replay['actions'].append(action)\n",
        "            \n",
        "            if len(buffer_replay['observations']) > 200:\n",
        "                print(f\"Performing {number_of_epochs} epochs of stocastic gradient descent on the replay buffer.\")\n",
        "                for epoch in range(1, number_of_epochs + 1):\n",
        "                    num_batches = len(buffer_replay['observations']) // batch_size\n",
        "                    shuffled_indices = tf.random.shuffle(tf.range(len(buffer_replay['observations'])))\n",
        "                    for batch in range(num_batches):\n",
        "                        if batch == num_batches: # last batch\n",
        "                            idx = shuffled_indices[batch*batch_size:]\n",
        "                        else:\n",
        "                            idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                        deltas_batch = tf.squeeze(tf.gather(buffer_replay['deltas'], idx), axis=-1)\n",
        "                        actions_batch = tf.gather(buffer_replay['actions'], idx)\n",
        "                        observations_batch = tf.gather(buffer_replay['observations'], idx)\n",
        "\n",
        "                        # shared_critic.train_batch(deltas_batch, observations_batch)\n",
        "                        shared_actor.train_batch(deltas_batch, observations_batch, actions_batch)\n",
        "                    print(f\"Epoch {epoch} terminated.\")\n",
        "                buffer_replay['observations'] = buffer_replay['observations'][50:]\n",
        "                buffer_replay['actions'] = buffer_replay['actions'][50:]\n",
        "                buffer_replay['deltas'] = buffer_replay['deltas'][50:]\n",
        "\n",
        "            if delta != 0:\n",
        "                updated = True\n",
        "                # update w with w + alpha_w*delta*grad_v^(St)\n",
        "                shared_critic.train_step(delta, obs['both_agent_obs'])\n",
        "                # update t with t + alpha_t*delta*grad_pi^(A|S) where A is the action taken before reaching St+1\n",
        "                shared_actor.train_step(delta, obs['both_agent_obs'], action)\n",
        "\n",
        "                # DEBUGGING\n",
        "                if not np.sum(shared_actor.call(obs['both_agent_obs'])[1].numpy()) > 0.9:\n",
        "                    print(delta)\n",
        "                    stop_calling = True\n",
        "                    break\n",
        "                # END DEBUGGING\n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            # think about training the critic by itself for a while\n",
        "            t += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. updated: {updated}. avg reward: {round(average_reward, 3)}\")\n",
        "        # shared_critic.save_weights(path_critic + \"shared_critic.weights.h5\")\n",
        "        # shared_actor.save_weights(path_actor + \"shared_actor.weights.h5\")\n",
        "except KeyboardInterrupt:\n",
        "    shared_critic.save_weights(path_critic + \"shared_critic_exp_2.weights.h5\")\n",
        "    shared_actor.save_weights(path_actor + \"shared_actor_exp_2.weights.h5\")\n",
        "    print(\"User interrupted training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e4761f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "# trajs = ae.evaluate_human_model_pair(1)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64519ff3",
      "metadata": {},
      "source": [
        "# Trial with batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8e0f7804",
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "711e15de",
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha_w = 1e-5\n",
        "alpha_t = 1e-6\n",
        "critic_optimizer = Adam(learning_rate=alpha_w)\n",
        "actor_optimizer = Adam(learning_rate=alpha_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e4ce6964",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=actor_optimizer\n",
        "    )\n",
        "\n",
        "shared_critic = ValueFunctionApproximator(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=critic_optimizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "aeeeaf0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_1 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        ")\n",
        "agent_2 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "593e9626",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [  1] terminated at timestep 400. cumulative reward:   3. avg reward: 3.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  2] terminated at timestep 400. cumulative reward:   0. avg reward: 1.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  3] terminated at timestep 400. cumulative reward:   8. avg reward: 3.667\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  4] terminated at timestep 400. cumulative reward:  14. avg reward: 6.25\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  5] terminated at timestep 400. cumulative reward:   6. avg reward: 6.2\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  6] terminated at timestep 400. cumulative reward:  14. avg reward: 7.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  7] terminated at timestep 400. cumulative reward:   3. avg reward: 6.857\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  8] terminated at timestep 400. cumulative reward:   3. avg reward: 6.375\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  9] terminated at timestep 400. cumulative reward:   9. avg reward: 6.667\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 10] terminated at timestep 400. cumulative reward:   9. avg reward: 6.9\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 11] terminated at timestep 400. cumulative reward:   3. avg reward: 6.545\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 12] terminated at timestep 400. cumulative reward:   3. avg reward: 6.25\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 13] terminated at timestep 400. cumulative reward:   0. avg reward: 5.769\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 14] terminated at timestep 400. cumulative reward:   3. avg reward: 5.571\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 15] terminated at timestep 400. cumulative reward:   9. avg reward: 5.8\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 16] terminated at timestep 400. cumulative reward:   6. avg reward: 5.812\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 17] terminated at timestep 400. cumulative reward:   3. avg reward: 5.647\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 18] terminated at timestep 400. cumulative reward:   3. avg reward: 5.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 19] terminated at timestep 400. cumulative reward:  11. avg reward: 5.789\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 20] terminated at timestep 400. cumulative reward:   3. avg reward: 5.65\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 21] terminated at timestep 400. cumulative reward:   3. avg reward: 5.524\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 22] terminated at timestep 400. cumulative reward:   9. avg reward: 5.682\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 23] terminated at timestep 400. cumulative reward:   3. avg reward: 5.565\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 24] terminated at timestep 400. cumulative reward:   9. avg reward: 5.708\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 25] terminated at timestep 400. cumulative reward:  17. avg reward: 6.16\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 26] terminated at timestep 400. cumulative reward:  11. avg reward: 6.346\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 27] terminated at timestep 400. cumulative reward:  20. avg reward: 6.852\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 28] terminated at timestep 400. cumulative reward:   6. avg reward: 6.821\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 29] terminated at timestep 400. cumulative reward:  12. avg reward: 7.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 30] terminated at timestep 400. cumulative reward:   8. avg reward: 7.033\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 31] terminated at timestep 400. cumulative reward:  14. avg reward: 7.258\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 32] terminated at timestep 400. cumulative reward:   3. avg reward: 7.125\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 33] terminated at timestep 400. cumulative reward:   8. avg reward: 7.152\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 34] terminated at timestep 400. cumulative reward:  11. avg reward: 7.265\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 35] terminated at timestep 400. cumulative reward:  17. avg reward: 7.543\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 36] terminated at timestep 400. cumulative reward:   6. avg reward: 7.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 37] terminated at timestep 400. cumulative reward:   3. avg reward: 7.378\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 38] terminated at timestep 400. cumulative reward:   8. avg reward: 7.395\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 39] terminated at timestep 400. cumulative reward:   6. avg reward: 7.359\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 40] terminated at timestep 400. cumulative reward:  14. avg reward: 7.525\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 41] terminated at timestep 400. cumulative reward:   3. avg reward: 7.415\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 42] terminated at timestep 400. cumulative reward:   3. avg reward: 7.31\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 43] terminated at timestep 400. cumulative reward:  14. avg reward: 7.465\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 44] terminated at timestep 400. cumulative reward:   9. avg reward: 7.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 45] terminated at timestep 400. cumulative reward:   6. avg reward: 7.467\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 46] terminated at timestep 400. cumulative reward:   6. avg reward: 7.435\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 47] terminated at timestep 400. cumulative reward:   3. avg reward: 7.34\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 48] terminated at timestep 400. cumulative reward:  14. avg reward: 7.479\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 49] terminated at timestep 400. cumulative reward:  16. avg reward: 7.653\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 50] terminated at timestep 400. cumulative reward:  11. avg reward: 7.72\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 51] terminated at timestep 400. cumulative reward:   3. avg reward: 7.627\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 52] terminated at timestep 400. cumulative reward:   3. avg reward: 7.538\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 53] terminated at timestep 400. cumulative reward:  11. avg reward: 7.604\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 54] terminated at timestep 400. cumulative reward:  20. avg reward: 7.833\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 55] terminated at timestep 400. cumulative reward:   6. avg reward: 7.8\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 56] terminated at timestep 400. cumulative reward:  20. avg reward: 8.018\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 57] terminated at timestep 400. cumulative reward:   6. avg reward: 7.982\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 58] terminated at timestep 400. cumulative reward:   6. avg reward: 7.948\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 59] terminated at timestep 400. cumulative reward:   3. avg reward: 7.864\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 60] terminated at timestep 400. cumulative reward:   3. avg reward: 7.783\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 61] terminated at timestep 400. cumulative reward:   9. avg reward: 7.803\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 62] terminated at timestep 400. cumulative reward:   9. avg reward: 7.823\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 63] terminated at timestep 400. cumulative reward:  14. avg reward: 7.921\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 64] terminated at timestep 400. cumulative reward:   6. avg reward: 7.891\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 65] terminated at timestep 400. cumulative reward:  17. avg reward: 8.031\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 66] terminated at timestep 400. cumulative reward:   3. avg reward: 7.955\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 67] terminated at timestep 400. cumulative reward:   8. avg reward: 7.955\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 68] terminated at timestep 400. cumulative reward:  51. avg reward: 8.588\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 69] terminated at timestep 400. cumulative reward:   3. avg reward: 8.507\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 70] terminated at timestep 400. cumulative reward:   3. avg reward: 8.429\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 71] terminated at timestep 400. cumulative reward:   3. avg reward: 8.352\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 72] terminated at timestep 400. cumulative reward:  14. avg reward: 8.431\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 73] terminated at timestep 400. cumulative reward:  40. avg reward: 8.863\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 74] terminated at timestep 400. cumulative reward:  14. avg reward: 8.932\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 75] terminated at timestep 400. cumulative reward:  11. avg reward: 8.96\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 76] terminated at timestep 400. cumulative reward:   8. avg reward: 8.947\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 77] terminated at timestep 400. cumulative reward:  14. avg reward: 9.013\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 78] terminated at timestep 400. cumulative reward:  17. avg reward: 9.115\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 79] terminated at timestep 400. cumulative reward:   8. avg reward: 9.101\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 80] terminated at timestep 400. cumulative reward:   6. avg reward: 9.062\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 81] terminated at timestep 400. cumulative reward:  14. avg reward: 9.123\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 82] terminated at timestep 400. cumulative reward:   6. avg reward: 9.085\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 83] terminated at timestep 400. cumulative reward:  14. avg reward: 9.145\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 84] terminated at timestep 400. cumulative reward:  31. avg reward: 9.405\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 85] terminated at timestep 400. cumulative reward:   3. avg reward: 9.329\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 86] terminated at timestep 400. cumulative reward:   3. avg reward: 9.256\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 87] terminated at timestep 400. cumulative reward:   6. avg reward: 9.218\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 88] terminated at timestep 400. cumulative reward:   3. avg reward: 9.148\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 89] terminated at timestep 400. cumulative reward:  14. avg reward: 9.202\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 90] terminated at timestep 400. cumulative reward:  17. avg reward: 9.289\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 91] terminated at timestep 400. cumulative reward:   3. avg reward: 9.22\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 92] terminated at timestep 400. cumulative reward:  11. avg reward: 9.239\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 93] terminated at timestep 400. cumulative reward:  24. avg reward: 9.398\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 94] terminated at timestep 400. cumulative reward:  14. avg reward: 9.447\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 95] terminated at timestep 400. cumulative reward:   8. avg reward: 9.432\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 96] terminated at timestep 400. cumulative reward:  17. avg reward: 9.51\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 97] terminated at timestep 400. cumulative reward:   0. avg reward: 9.412\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 98] terminated at timestep 400. cumulative reward:   3. avg reward: 9.347\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 99] terminated at timestep 400. cumulative reward:  19. avg reward: 9.444\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [100] terminated at timestep 400. cumulative reward:   3. avg reward: 9.38\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [101] terminated at timestep 400. cumulative reward:  11. avg reward: 9.396\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [102] terminated at timestep 400. cumulative reward:  11. avg reward: 9.412\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [103] terminated at timestep 400. cumulative reward:  25. avg reward: 9.563\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [104] terminated at timestep 400. cumulative reward:  14. avg reward: 9.606\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [105] terminated at timestep 400. cumulative reward:   3. avg reward: 9.543\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [106] terminated at timestep 400. cumulative reward:  19. avg reward: 9.632\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [107] terminated at timestep 400. cumulative reward:   3. avg reward: 9.57\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [108] terminated at timestep 400. cumulative reward:  16. avg reward: 9.63\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [109] terminated at timestep 400. cumulative reward:   3. avg reward: 9.569\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [110] terminated at timestep 400. cumulative reward:  11. avg reward: 9.582\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [111] terminated at timestep 400. cumulative reward:   3. avg reward: 9.523\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [112] terminated at timestep 400. cumulative reward:  17. avg reward: 9.589\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [113] terminated at timestep 400. cumulative reward:  22. avg reward: 9.699\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [114] terminated at timestep 400. cumulative reward:  14. avg reward: 9.737\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [115] terminated at timestep 400. cumulative reward:   6. avg reward: 9.704\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [116] terminated at timestep 400. cumulative reward:  11. avg reward: 9.716\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [117] terminated at timestep 400. cumulative reward:  11. avg reward: 9.726\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [118] terminated at timestep 400. cumulative reward:   8. avg reward: 9.712\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [119] terminated at timestep 400. cumulative reward:   3. avg reward: 9.655\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [120] terminated at timestep 400. cumulative reward:  19. avg reward: 9.733\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [121] terminated at timestep 400. cumulative reward:   8. avg reward: 9.719\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [122] terminated at timestep 400. cumulative reward:  11. avg reward: 9.73\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [123] terminated at timestep 400. cumulative reward:   6. avg reward: 9.699\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [124] terminated at timestep 400. cumulative reward:   3. avg reward: 9.645\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [125] terminated at timestep 400. cumulative reward:  14. avg reward: 9.68\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [126] terminated at timestep 400. cumulative reward:   8. avg reward: 9.667\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [127] terminated at timestep 400. cumulative reward:   8. avg reward: 9.654\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [128] terminated at timestep 400. cumulative reward:  14. avg reward: 9.688\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [129] terminated at timestep 400. cumulative reward:  11. avg reward: 9.698\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [130] terminated at timestep 400. cumulative reward:  11. avg reward: 9.708\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [131] terminated at timestep 400. cumulative reward:   3. avg reward: 9.656\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [132] terminated at timestep 400. cumulative reward:   3. avg reward: 9.606\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [133] terminated at timestep 400. cumulative reward:  14. avg reward: 9.639\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [134] terminated at timestep 400. cumulative reward:   8. avg reward: 9.627\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [135] terminated at timestep 400. cumulative reward:  14. avg reward: 9.659\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [136] terminated at timestep 400. cumulative reward:   6. avg reward: 9.632\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [137] terminated at timestep 400. cumulative reward:  17. avg reward: 9.686\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [138] terminated at timestep 400. cumulative reward:  28. avg reward: 9.819\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [139] terminated at timestep 400. cumulative reward:   3. avg reward: 9.77\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [140] terminated at timestep 400. cumulative reward:  11. avg reward: 9.779\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [141] terminated at timestep 400. cumulative reward:   3. avg reward: 9.73\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [142] terminated at timestep 400. cumulative reward:   3. avg reward: 9.683\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [143] terminated at timestep 400. cumulative reward:  14. avg reward: 9.713\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [144] terminated at timestep 400. cumulative reward:   3. avg reward: 9.667\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [145] terminated at timestep 400. cumulative reward:   3. avg reward: 9.621\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [146] terminated at timestep 400. cumulative reward:  16. avg reward: 9.664\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [147] terminated at timestep 400. cumulative reward:  14. avg reward: 9.694\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [148] terminated at timestep 400. cumulative reward:   6. avg reward: 9.669\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [149] terminated at timestep 400. cumulative reward:  14. avg reward: 9.698\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [150] terminated at timestep 400. cumulative reward:   3. avg reward: 9.653\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [151] terminated at timestep 400. cumulative reward:  19. avg reward: 9.715\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [152] terminated at timestep 400. cumulative reward:   3. avg reward: 9.671\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [153] terminated at timestep 400. cumulative reward:   3. avg reward: 9.627\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [154] terminated at timestep 400. cumulative reward:  19. avg reward: 9.688\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [155] terminated at timestep 400. cumulative reward:  11. avg reward: 9.697\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [156] terminated at timestep 400. cumulative reward:   3. avg reward: 9.654\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [157] terminated at timestep 400. cumulative reward:   8. avg reward: 9.643\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [158] terminated at timestep 400. cumulative reward:   3. avg reward: 9.601\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [159] terminated at timestep 400. cumulative reward:   9. avg reward: 9.597\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [160] terminated at timestep 400. cumulative reward:   3. avg reward: 9.556\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [161] terminated at timestep 400. cumulative reward:   6. avg reward: 9.534\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [162] terminated at timestep 400. cumulative reward:   8. avg reward: 9.525\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [163] terminated at timestep 400. cumulative reward:  11. avg reward: 9.534\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [164] terminated at timestep 400. cumulative reward:   3. avg reward: 9.494\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [165] terminated at timestep 400. cumulative reward:   3. avg reward: 9.455\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [166] terminated at timestep 400. cumulative reward:   3. avg reward: 9.416\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [167] terminated at timestep 400. cumulative reward:   6. avg reward: 9.395\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [168] terminated at timestep 400. cumulative reward:  14. avg reward: 9.423\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [169] terminated at timestep 400. cumulative reward:  11. avg reward: 9.432\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [170] terminated at timestep 400. cumulative reward:   3. avg reward: 9.394\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [171] terminated at timestep 400. cumulative reward:   8. avg reward: 9.386\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [172] terminated at timestep 400. cumulative reward:  11. avg reward: 9.395\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [173] terminated at timestep 400. cumulative reward:  11. avg reward: 9.405\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [174] terminated at timestep 400. cumulative reward:   6. avg reward: 9.385\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [175] terminated at timestep 400. cumulative reward:  14. avg reward: 9.411\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [176] terminated at timestep 400. cumulative reward:   6. avg reward: 9.392\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [177] terminated at timestep 400. cumulative reward:  11. avg reward: 9.401\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [178] terminated at timestep 400. cumulative reward:   6. avg reward: 9.382\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [179] terminated at timestep 400. cumulative reward:  19. avg reward: 9.436\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [180] terminated at timestep 400. cumulative reward:  22. avg reward: 9.506\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [181] terminated at timestep 400. cumulative reward:   3. avg reward: 9.47\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [182] terminated at timestep 400. cumulative reward:  11. avg reward: 9.478\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [183] terminated at timestep 400. cumulative reward:   8. avg reward: 9.47\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [184] terminated at timestep 400. cumulative reward:   3. avg reward: 9.435\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [185] terminated at timestep 400. cumulative reward:   8. avg reward: 9.427\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [186] terminated at timestep 400. cumulative reward:   3. avg reward: 9.392\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [187] terminated at timestep 400. cumulative reward:  11. avg reward: 9.401\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [188] terminated at timestep 400. cumulative reward:  11. avg reward: 9.41\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [189] terminated at timestep 400. cumulative reward:   3. avg reward: 9.376\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [190] terminated at timestep 400. cumulative reward:   3. avg reward: 9.342\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [191] terminated at timestep 400. cumulative reward:  11. avg reward: 9.351\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [192] terminated at timestep 400. cumulative reward:  11. avg reward: 9.359\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [193] terminated at timestep 400. cumulative reward:   3. avg reward: 9.326\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [194] terminated at timestep 400. cumulative reward:   6. avg reward: 9.309\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [195] terminated at timestep 400. cumulative reward:  11. avg reward: 9.318\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [196] terminated at timestep 400. cumulative reward:   3. avg reward: 9.286\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [197] terminated at timestep 400. cumulative reward:  14. avg reward: 9.31\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [198] terminated at timestep 400. cumulative reward:  14. avg reward: 9.333\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [199] terminated at timestep 400. cumulative reward:   3. avg reward: 9.302\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [200] terminated at timestep 400. cumulative reward:  16. avg reward: 9.335\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [201] terminated at timestep 400. cumulative reward:  11. avg reward: 9.343\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [202] terminated at timestep 400. cumulative reward:   6. avg reward: 9.327\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [203] terminated at timestep 400. cumulative reward:   3. avg reward: 9.296\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [204] terminated at timestep 400. cumulative reward:  11. avg reward: 9.304\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [205] terminated at timestep 400. cumulative reward:   3. avg reward: 9.273\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [206] terminated at timestep 400. cumulative reward:   3. avg reward: 9.243\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [207] terminated at timestep 400. cumulative reward:  11. avg reward: 9.251\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [208] terminated at timestep 400. cumulative reward:   3. avg reward: 9.221\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [209] terminated at timestep 400. cumulative reward:   3. avg reward: 9.191\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [210] terminated at timestep 400. cumulative reward:  11. avg reward: 9.2\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [211] terminated at timestep 400. cumulative reward:  14. avg reward: 9.223\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [212] terminated at timestep 400. cumulative reward:  11. avg reward: 9.231\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [213] terminated at timestep 400. cumulative reward:   3. avg reward: 9.202\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [214] terminated at timestep 400. cumulative reward:   6. avg reward: 9.187\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [215] terminated at timestep 400. cumulative reward:   3. avg reward: 9.158\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [216] terminated at timestep 400. cumulative reward:  19. avg reward: 9.204\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [217] terminated at timestep 400. cumulative reward:   6. avg reward: 9.189\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [218] terminated at timestep 400. cumulative reward:   3. avg reward: 9.161\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [219] terminated at timestep 400. cumulative reward:   6. avg reward: 9.146\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [220] terminated at timestep 400. cumulative reward:  22. avg reward: 9.205\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [221] terminated at timestep 400. cumulative reward:   8. avg reward: 9.199\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [222] terminated at timestep 400. cumulative reward:  11. avg reward: 9.207\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [223] terminated at timestep 400. cumulative reward:   3. avg reward: 9.179\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [224] terminated at timestep 400. cumulative reward:  22. avg reward: 9.237\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [225] terminated at timestep 400. cumulative reward:   3. avg reward: 9.209\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [226] terminated at timestep 400. cumulative reward:   6. avg reward: 9.195\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [227] terminated at timestep 400. cumulative reward:  24. avg reward: 9.26\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [228] terminated at timestep 400. cumulative reward:   3. avg reward: 9.232\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [229] terminated at timestep 400. cumulative reward:  11. avg reward: 9.24\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [230] terminated at timestep 400. cumulative reward:   6. avg reward: 9.226\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [231] terminated at timestep 400. cumulative reward:   8. avg reward: 9.221\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [232] terminated at timestep 400. cumulative reward:  25. avg reward: 9.289\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [233] terminated at timestep 400. cumulative reward:  11. avg reward: 9.296\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [234] terminated at timestep 400. cumulative reward:  11. avg reward: 9.303\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [235] terminated at timestep 400. cumulative reward:  11. avg reward: 9.311\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [236] terminated at timestep 400. cumulative reward:   3. avg reward: 9.284\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [237] terminated at timestep 400. cumulative reward:   8. avg reward: 9.278\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [238] terminated at timestep 400. cumulative reward:   6. avg reward: 9.265\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [239] terminated at timestep 400. cumulative reward:  14. avg reward: 9.285\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [240] terminated at timestep 400. cumulative reward:   3. avg reward: 9.258\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [241] terminated at timestep 400. cumulative reward:   3. avg reward: 9.232\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [242] terminated at timestep 400. cumulative reward:  14. avg reward: 9.252\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [243] terminated at timestep 400. cumulative reward:  11. avg reward: 9.259\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [244] terminated at timestep 400. cumulative reward:   3. avg reward: 9.234\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [245] terminated at timestep 400. cumulative reward:   3. avg reward: 9.208\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [246] terminated at timestep 400. cumulative reward:   8. avg reward: 9.203\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [247] terminated at timestep 400. cumulative reward:   3. avg reward: 9.178\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [248] terminated at timestep 400. cumulative reward:   6. avg reward: 9.165\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [249] terminated at timestep 400. cumulative reward:   6. avg reward: 9.153\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [250] terminated at timestep 400. cumulative reward:   0. avg reward: 9.116\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [251] terminated at timestep 400. cumulative reward:   6. avg reward: 9.104\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [252] terminated at timestep 400. cumulative reward:  11. avg reward: 9.111\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [253] terminated at timestep 400. cumulative reward:  14. avg reward: 9.13\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [254] terminated at timestep 400. cumulative reward:   3. avg reward: 9.106\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [255] terminated at timestep 400. cumulative reward:  11. avg reward: 9.114\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [256] terminated at timestep 400. cumulative reward:  14. avg reward: 9.133\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [257] terminated at timestep 400. cumulative reward:   3. avg reward: 9.109\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [258] terminated at timestep 400. cumulative reward:  11. avg reward: 9.116\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [259] terminated at timestep 400. cumulative reward:   8. avg reward: 9.112\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [260] terminated at timestep 400. cumulative reward:   6. avg reward: 9.1\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [261] terminated at timestep 400. cumulative reward:  19. avg reward: 9.138\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [262] terminated at timestep 400. cumulative reward:   3. avg reward: 9.115\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [263] terminated at timestep 400. cumulative reward:   3. avg reward: 9.091\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [264] terminated at timestep 400. cumulative reward:   3. avg reward: 9.068\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [265] terminated at timestep 400. cumulative reward:   6. avg reward: 9.057\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [266] terminated at timestep 400. cumulative reward:   3. avg reward: 9.034\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "User interrupted training. Saving weights\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 500\n",
        "number_of_epochs = 4\n",
        "batch_size = 20\n",
        "average_reward = 0\n",
        "gamma = 0.95\n",
        "\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        actions = []\n",
        "        deltas = []\n",
        "        observations = []\n",
        "\n",
        "        t = 0\n",
        "        obs = env.reset()\n",
        "        obs = obs['both_agent_obs'] \n",
        "        \n",
        "        done = False\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        if (episode) % 50 == 0:\n",
        "            shared_critic.save_weights(path_critic + \"shared_critic_exp_3.weights.h5\")\n",
        "            shared_actor.save_weights(path_actor + \"shared_actor_exp_3.weights.h5\")\n",
        "\n",
        "        while not done:\n",
        "            action1 = agent_1.action(obs)\n",
        "            action2 = agent_2.action(obs)\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            action = (player_1_action, player_2_action)\n",
        "\n",
        "            actions.append(action)\n",
        "            observations.append(obs)\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            new_obs = new_obs['both_agent_obs']\n",
        "\n",
        "            if shaped_reward != 0:\n",
        "                shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "                shaped_reward_factor *= discount_rate\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            if done:\n",
        "                delta = total_reward - shared_critic.call(obs)\n",
        "            else:\n",
        "                delta = total_reward + gamma*shared_critic.call(new_obs) - shared_critic.call(obs)\n",
        "\n",
        "            deltas.append(delta)\n",
        "            \n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            # think about training the critic by itself for a while\n",
        "            t += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. avg reward: {round(average_reward, 3)}\")\n",
        "        print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "        for epoch in range(1, number_of_epochs + 1):\n",
        "            num_batches = len(actions) // batch_size\n",
        "            shuffled_indices = tf.random.shuffle(tf.range(len(actions)))\n",
        "            for batch in range(num_batches):\n",
        "                if batch == num_batches: # last batch\n",
        "                    idx = shuffled_indices[batch*batch_size:]\n",
        "                else:\n",
        "                    idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                deltas_batch = tf.squeeze(tf.gather(deltas, idx), axis=-1)\n",
        "                actions_batch = tf.gather(actions, idx)\n",
        "                observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "                shared_critic.train_batch(deltas_batch, observations_batch)\n",
        "                shared_actor.train_batch(deltas_batch, observations_batch, actions_batch)\n",
        "            print(f\"Epoch {epoch} terminated.\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    shared_critic.save_weights(path_critic + \"shared_critic_exp_3.weights.h5\")\n",
        "    shared_actor.save_weights(path_actor + \"shared_actor_exp_3.weights.h5\")\n",
        "    print(\"User interrupted training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f0dc0dca",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|██████████| 10/10 [00:57<00:00,  5.74s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c876b89aaa14be0a15b1c8aa535ac71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "# trajs = ae.evaluate_human_model_pair(1)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02b85687",
      "metadata": {},
      "source": [
        "# Trial with batches and past reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "41db51fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "73387606",
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha_w = 1e-5\n",
        "alpha_t = 1e-6\n",
        "critic_optimizer = Adam(learning_rate=alpha_w)\n",
        "actor_optimizer = Adam(learning_rate=alpha_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "d2a0b847",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=actor_optimizer\n",
        "    )\n",
        "\n",
        "shared_critic = ValueFunctionApproximator(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=critic_optimizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "75e0c310",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_1 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    old_policy=None,\n",
        "    critic=shared_critic,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        ")\n",
        "agent_2 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    old_policy=None,\n",
        "    critic=shared_critic,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0043032",
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_actor.load_weights(path_actor + \"shared_actor_exp_7.weights.h5\")\n",
        "shared_critic.load_weights(path_critic + \"shared_critic_exp_7.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a4710cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [  1] terminated at timestep 400. cumulative reward:  59. avg reward: 59.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  2] terminated at timestep 400. cumulative reward:  23. avg reward: 41.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  3] terminated at timestep 400. cumulative reward:  39. avg reward: 40.333\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  4] terminated at timestep 400. cumulative reward:  12. avg reward: 33.25\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  5] terminated at timestep 400. cumulative reward:  48. avg reward: 36.2\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  6] terminated at timestep 400. cumulative reward:  25. avg reward: 34.333\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  7] terminated at timestep 400. cumulative reward:  23. avg reward: 32.714\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  8] terminated at timestep 400. cumulative reward:  33. avg reward: 32.75\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  9] terminated at timestep 400. cumulative reward:  33. avg reward: 32.778\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 10] terminated at timestep 400. cumulative reward:   0. avg reward: 29.5\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 11] terminated at timestep 400. cumulative reward:  68. avg reward: 33.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 12] terminated at timestep 400. cumulative reward:  31. avg reward: 32.833\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 13] terminated at timestep 400. cumulative reward:  20. avg reward: 31.846\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 14] terminated at timestep 400. cumulative reward:  12. avg reward: 30.429\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 15] terminated at timestep 400. cumulative reward:  20. avg reward: 29.733\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 16] terminated at timestep 400. cumulative reward:  82. avg reward: 33.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 17] terminated at timestep 400. cumulative reward:  42. avg reward: 33.529\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 18] terminated at timestep 400. cumulative reward:  11. avg reward: 32.278\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 19] terminated at timestep 400. cumulative reward:  26. avg reward: 31.947\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 20] terminated at timestep 400. cumulative reward:  39. avg reward: 32.3\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 21] terminated at timestep 400. cumulative reward:  12. avg reward: 31.333\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 22] terminated at timestep 400. cumulative reward:  33. avg reward: 31.409\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 23] terminated at timestep 400. cumulative reward:  28. avg reward: 31.261\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 24] terminated at timestep 400. cumulative reward:  43. avg reward: 31.75\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 25] terminated at timestep 400. cumulative reward:  33. avg reward: 31.8\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 26] terminated at timestep 400. cumulative reward:  32. avg reward: 31.808\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 27] terminated at timestep 400. cumulative reward:   9. avg reward: 30.963\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 28] terminated at timestep 400. cumulative reward:   9. avg reward: 30.179\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 29] terminated at timestep 400. cumulative reward:  74. avg reward: 31.69\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 30] terminated at timestep 400. cumulative reward:  20. avg reward: 31.3\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 31] terminated at timestep 400. cumulative reward:  34. avg reward: 31.387\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 32] terminated at timestep 400. cumulative reward:  12. avg reward: 30.781\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 33] terminated at timestep 400. cumulative reward:  20. avg reward: 30.455\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 34] terminated at timestep 400. cumulative reward:  22. avg reward: 30.206\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 35] terminated at timestep 400. cumulative reward:  20. avg reward: 29.914\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 36] terminated at timestep 400. cumulative reward:  11. avg reward: 29.389\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 37] terminated at timestep 400. cumulative reward:  57. avg reward: 30.135\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 38] terminated at timestep 400. cumulative reward:   9. avg reward: 29.579\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 39] terminated at timestep 400. cumulative reward:  12. avg reward: 29.128\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 40] terminated at timestep 400. cumulative reward:   9. avg reward: 28.625\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 41] terminated at timestep 400. cumulative reward:  20. avg reward: 28.415\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 42] terminated at timestep 400. cumulative reward:  36. avg reward: 28.595\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 43] terminated at timestep 400. cumulative reward:  80. avg reward: 29.791\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 44] terminated at timestep 400. cumulative reward:  22. avg reward: 29.614\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 45] terminated at timestep 400. cumulative reward:  46. avg reward: 29.978\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 46] terminated at timestep 400. cumulative reward:  14. avg reward: 29.63\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 47] terminated at timestep 400. cumulative reward:  31. avg reward: 29.66\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 48] terminated at timestep 400. cumulative reward:   9. avg reward: 29.229\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 49] terminated at timestep 400. cumulative reward:  22. avg reward: 29.082\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 50] terminated at timestep 400. cumulative reward:  50. avg reward: 29.5\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 51] terminated at timestep 400. cumulative reward:  23. avg reward: 29.373\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 52] terminated at timestep 400. cumulative reward:  12. avg reward: 29.038\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 53] terminated at timestep 400. cumulative reward:  46. avg reward: 29.358\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 54] terminated at timestep 400. cumulative reward:  48. avg reward: 29.704\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 55] terminated at timestep 400. cumulative reward:  19. avg reward: 29.509\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 56] terminated at timestep 400. cumulative reward:  12. avg reward: 29.196\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 57] terminated at timestep 400. cumulative reward:  31. avg reward: 29.228\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 58] terminated at timestep 400. cumulative reward:  43. avg reward: 29.466\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 59] terminated at timestep 400. cumulative reward:  22. avg reward: 29.339\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 60] terminated at timestep 400. cumulative reward:  25. avg reward: 29.267\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 61] terminated at timestep 400. cumulative reward:  28. avg reward: 29.246\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 62] terminated at timestep 400. cumulative reward:  56. avg reward: 29.677\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 63] terminated at timestep 400. cumulative reward:  26. avg reward: 29.619\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 64] terminated at timestep 400. cumulative reward:  20. avg reward: 29.469\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 65] terminated at timestep 400. cumulative reward:  20. avg reward: 29.323\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 66] terminated at timestep 400. cumulative reward:  36. avg reward: 29.424\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 67] terminated at timestep 400. cumulative reward:  57. avg reward: 29.836\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 68] terminated at timestep 400. cumulative reward:  40. avg reward: 29.985\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 69] terminated at timestep 400. cumulative reward:  23. avg reward: 29.884\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 70] terminated at timestep 400. cumulative reward:  25. avg reward: 29.814\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 71] terminated at timestep 400. cumulative reward:   9. avg reward: 29.521\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 72] terminated at timestep 400. cumulative reward:  54. avg reward: 29.861\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 73] terminated at timestep 400. cumulative reward:  45. avg reward: 30.068\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 74] terminated at timestep 400. cumulative reward:  51. avg reward: 30.351\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 75] terminated at timestep 400. cumulative reward:  12. avg reward: 30.107\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 76] terminated at timestep 400. cumulative reward:   9. avg reward: 29.829\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 77] terminated at timestep 400. cumulative reward:  43. avg reward: 30.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 78] terminated at timestep 400. cumulative reward:  28. avg reward: 29.974\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 79] terminated at timestep 400. cumulative reward:  17. avg reward: 29.81\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 80] terminated at timestep 400. cumulative reward:  12. avg reward: 29.588\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 81] terminated at timestep 400. cumulative reward:  17. avg reward: 29.432\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 82] terminated at timestep 400. cumulative reward:   9. avg reward: 29.183\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 83] terminated at timestep 400. cumulative reward:  17. avg reward: 29.036\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 84] terminated at timestep 400. cumulative reward:  28. avg reward: 29.024\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 85] terminated at timestep 400. cumulative reward:  48. avg reward: 29.247\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 86] terminated at timestep 400. cumulative reward:  12. avg reward: 29.047\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 87] terminated at timestep 400. cumulative reward:  26. avg reward: 29.011\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 88] terminated at timestep 400. cumulative reward:  37. avg reward: 29.102\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 89] terminated at timestep 400. cumulative reward:  48. avg reward: 29.315\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 90] terminated at timestep 400. cumulative reward:  57. avg reward: 29.622\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 91] terminated at timestep 400. cumulative reward:  20. avg reward: 29.516\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 92] terminated at timestep 400. cumulative reward:  46. avg reward: 29.696\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 93] terminated at timestep 400. cumulative reward:  23. avg reward: 29.624\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 94] terminated at timestep 400. cumulative reward:  12. avg reward: 29.436\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 95] terminated at timestep 400. cumulative reward:  82. avg reward: 29.989\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 96] terminated at timestep 400. cumulative reward:  50. avg reward: 30.198\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 97] terminated at timestep 400. cumulative reward:  23. avg reward: 30.124\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 98] terminated at timestep 400. cumulative reward:   9. avg reward: 29.908\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 99] terminated at timestep 400. cumulative reward:  12. avg reward: 29.727\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [100] terminated at timestep 400. cumulative reward:  25. avg reward: 29.68\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [101] terminated at timestep 400. cumulative reward:  28. avg reward: 29.663\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [102] terminated at timestep 400. cumulative reward:  12. avg reward: 29.49\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [103] terminated at timestep 400. cumulative reward:  28. avg reward: 29.476\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [104] terminated at timestep 400. cumulative reward:  23. avg reward: 29.413\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [105] terminated at timestep 400. cumulative reward:  37. avg reward: 29.486\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [106] terminated at timestep 400. cumulative reward:  48. avg reward: 29.66\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [107] terminated at timestep 400. cumulative reward:  12. avg reward: 29.495\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [108] terminated at timestep 400. cumulative reward:  12. avg reward: 29.333\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [109] terminated at timestep 400. cumulative reward:  23. avg reward: 29.275\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [110] terminated at timestep 400. cumulative reward:  28. avg reward: 29.264\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [111] terminated at timestep 400. cumulative reward:  31. avg reward: 29.279\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [112] terminated at timestep 400. cumulative reward:  46. avg reward: 29.429\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [113] terminated at timestep 400. cumulative reward:  17. avg reward: 29.319\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [114] terminated at timestep 400. cumulative reward:  12. avg reward: 29.167\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [115] terminated at timestep 400. cumulative reward:  28. avg reward: 29.157\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [116] terminated at timestep 400. cumulative reward:   9. avg reward: 28.983\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [117] terminated at timestep 400. cumulative reward:   9. avg reward: 28.812\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [118] terminated at timestep 400. cumulative reward:  22. avg reward: 28.754\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [119] terminated at timestep 400. cumulative reward:  12. avg reward: 28.613\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [120] terminated at timestep 400. cumulative reward:  12. avg reward: 28.475\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [121] terminated at timestep 400. cumulative reward:  45. avg reward: 28.612\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [122] terminated at timestep 400. cumulative reward:  25. avg reward: 28.582\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [123] terminated at timestep 400. cumulative reward:  30. avg reward: 28.593\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [124] terminated at timestep 400. cumulative reward:   9. avg reward: 28.435\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [125] terminated at timestep 400. cumulative reward:  25. avg reward: 28.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [126] terminated at timestep 400. cumulative reward:   9. avg reward: 28.254\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [127] terminated at timestep 400. cumulative reward:  63. avg reward: 28.528\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [128] terminated at timestep 400. cumulative reward:  45. avg reward: 28.656\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [129] terminated at timestep 400. cumulative reward:  42. avg reward: 28.76\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [130] terminated at timestep 400. cumulative reward:  34. avg reward: 28.8\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [131] terminated at timestep 400. cumulative reward:  45. avg reward: 28.924\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [132] terminated at timestep 400. cumulative reward:  40. avg reward: 29.008\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [133] terminated at timestep 400. cumulative reward:  36. avg reward: 29.06\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [134] terminated at timestep 400. cumulative reward:  53. avg reward: 29.239\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [135] terminated at timestep 400. cumulative reward:  28. avg reward: 29.23\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [136] terminated at timestep 400. cumulative reward:  12. avg reward: 29.103\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [137] terminated at timestep 400. cumulative reward:   9. avg reward: 28.956\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [138] terminated at timestep 400. cumulative reward:   9. avg reward: 28.812\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [139] terminated at timestep 400. cumulative reward:  54. avg reward: 28.993\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [140] terminated at timestep 400. cumulative reward:  20. avg reward: 28.929\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [141] terminated at timestep 400. cumulative reward:  31. avg reward: 28.943\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [142] terminated at timestep 400. cumulative reward:  39. avg reward: 29.014\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [143] terminated at timestep 400. cumulative reward:   9. avg reward: 28.874\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [144] terminated at timestep 400. cumulative reward:  39. avg reward: 28.944\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [145] terminated at timestep 400. cumulative reward:   9. avg reward: 28.807\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [146] terminated at timestep 400. cumulative reward:  12. avg reward: 28.692\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [147] terminated at timestep 400. cumulative reward:   9. avg reward: 28.558\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [148] terminated at timestep 400. cumulative reward:  17. avg reward: 28.48\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [149] terminated at timestep 400. cumulative reward:  39. avg reward: 28.55\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [150] terminated at timestep 400. cumulative reward:  51. avg reward: 28.7\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [151] terminated at timestep 400. cumulative reward:  20. avg reward: 28.642\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [152] terminated at timestep 400. cumulative reward:  12. avg reward: 28.533\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [153] terminated at timestep 400. cumulative reward:  23. avg reward: 28.497\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [154] terminated at timestep 400. cumulative reward:  31. avg reward: 28.513\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [155] terminated at timestep 400. cumulative reward:  12. avg reward: 28.406\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [156] terminated at timestep 400. cumulative reward:  34. avg reward: 28.442\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [157] terminated at timestep 400. cumulative reward:  22. avg reward: 28.401\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [158] terminated at timestep 400. cumulative reward:  12. avg reward: 28.297\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [159] terminated at timestep 400. cumulative reward:  20. avg reward: 28.245\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [160] terminated at timestep 400. cumulative reward:  12. avg reward: 28.144\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [161] terminated at timestep 400. cumulative reward:  45. avg reward: 28.248\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [162] terminated at timestep 400. cumulative reward:  37. avg reward: 28.302\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [163] terminated at timestep 400. cumulative reward:  17. avg reward: 28.233\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [164] terminated at timestep 400. cumulative reward:  23. avg reward: 28.201\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [165] terminated at timestep 400. cumulative reward:  12. avg reward: 28.103\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [166] terminated at timestep 400. cumulative reward:  36. avg reward: 28.151\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [167] terminated at timestep 400. cumulative reward:  28. avg reward: 28.15\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [168] terminated at timestep 400. cumulative reward:  34. avg reward: 28.185\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [169] terminated at timestep 400. cumulative reward:  12. avg reward: 28.089\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [170] terminated at timestep 400. cumulative reward:  28. avg reward: 28.088\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [171] terminated at timestep 400. cumulative reward:  26. avg reward: 28.076\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [172] terminated at timestep 400. cumulative reward:  11. avg reward: 27.977\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [173] terminated at timestep 400. cumulative reward:  17. avg reward: 27.913\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [174] terminated at timestep 400. cumulative reward:  45. avg reward: 28.011\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [175] terminated at timestep 400. cumulative reward:  25. avg reward: 27.994\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [176] terminated at timestep 400. cumulative reward:  31. avg reward: 28.011\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [177] terminated at timestep 400. cumulative reward:  19. avg reward: 27.96\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [178] terminated at timestep 400. cumulative reward:  26. avg reward: 27.949\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [179] terminated at timestep 400. cumulative reward:  12. avg reward: 27.86\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [180] terminated at timestep 400. cumulative reward:  28. avg reward: 27.861\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [181] terminated at timestep 400. cumulative reward:  20. avg reward: 27.818\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [182] terminated at timestep 400. cumulative reward:  54. avg reward: 27.962\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [183] terminated at timestep 400. cumulative reward:  12. avg reward: 27.874\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [184] terminated at timestep 400. cumulative reward:   9. avg reward: 27.772\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [185] terminated at timestep 400. cumulative reward:  31. avg reward: 27.789\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [186] terminated at timestep 400. cumulative reward:  12. avg reward: 27.704\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [187] terminated at timestep 400. cumulative reward:  23. avg reward: 27.679\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [188] terminated at timestep 400. cumulative reward:  28. avg reward: 27.681\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [189] terminated at timestep 400. cumulative reward:  20. avg reward: 27.64\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [190] terminated at timestep 400. cumulative reward:  12. avg reward: 27.558\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [191] terminated at timestep 400. cumulative reward:  28. avg reward: 27.56\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [192] terminated at timestep 400. cumulative reward:  26. avg reward: 27.552\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [193] terminated at timestep 400. cumulative reward:  31. avg reward: 27.57\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [194] terminated at timestep 400. cumulative reward:  33. avg reward: 27.598\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [195] terminated at timestep 400. cumulative reward:   9. avg reward: 27.503\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [196] terminated at timestep 400. cumulative reward:  28. avg reward: 27.505\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [197] terminated at timestep 400. cumulative reward:  17. avg reward: 27.452\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [198] terminated at timestep 400. cumulative reward:  25. avg reward: 27.439\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [199] terminated at timestep 400. cumulative reward:   6. avg reward: 27.332\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [200] terminated at timestep 400. cumulative reward:   9. avg reward: 27.24\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [201] terminated at timestep 400. cumulative reward:  51. avg reward: 27.358\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [202] terminated at timestep 400. cumulative reward:  23. avg reward: 27.337\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [203] terminated at timestep 400. cumulative reward:  17. avg reward: 27.286\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [204] terminated at timestep 400. cumulative reward:  23. avg reward: 27.265\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [205] terminated at timestep 400. cumulative reward:  31. avg reward: 27.283\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [206] terminated at timestep 400. cumulative reward:  12. avg reward: 27.209\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [207] terminated at timestep 400. cumulative reward:  28. avg reward: 27.213\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [208] terminated at timestep 400. cumulative reward:   9. avg reward: 27.125\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [209] terminated at timestep 400. cumulative reward:   3. avg reward: 27.01\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [210] terminated at timestep 400. cumulative reward:  31. avg reward: 27.029\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [211] terminated at timestep 400. cumulative reward:  28. avg reward: 27.033\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [212] terminated at timestep 400. cumulative reward:  31. avg reward: 27.052\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [213] terminated at timestep 400. cumulative reward:  25. avg reward: 27.042\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [214] terminated at timestep 400. cumulative reward:  28. avg reward: 27.047\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [215] terminated at timestep 400. cumulative reward:  14. avg reward: 26.986\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [216] terminated at timestep 400. cumulative reward:  53. avg reward: 27.106\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [217] terminated at timestep 400. cumulative reward:  42. avg reward: 27.175\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [218] terminated at timestep 400. cumulative reward:  23. avg reward: 27.156\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [219] terminated at timestep 400. cumulative reward:  31. avg reward: 27.174\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [220] terminated at timestep 400. cumulative reward:  20. avg reward: 27.141\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [221] terminated at timestep 400. cumulative reward:  31. avg reward: 27.158\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [222] terminated at timestep 400. cumulative reward:  11. avg reward: 27.086\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [223] terminated at timestep 400. cumulative reward:  19. avg reward: 27.049\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [224] terminated at timestep 400. cumulative reward:  33. avg reward: 27.076\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [225] terminated at timestep 400. cumulative reward:  14. avg reward: 27.018\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [226] terminated at timestep 400. cumulative reward:   9. avg reward: 26.938\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [227] terminated at timestep 400. cumulative reward:  14. avg reward: 26.881\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [228] terminated at timestep 400. cumulative reward:  31. avg reward: 26.899\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [229] terminated at timestep 400. cumulative reward:  37. avg reward: 26.943\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [230] terminated at timestep 400. cumulative reward:  31. avg reward: 26.961\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [231] terminated at timestep 400. cumulative reward:  22. avg reward: 26.939\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [232] terminated at timestep 400. cumulative reward:  28. avg reward: 26.944\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [233] terminated at timestep 400. cumulative reward:  43. avg reward: 27.013\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [234] terminated at timestep 400. cumulative reward:  59. avg reward: 27.15\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [235] terminated at timestep 400. cumulative reward:  54. avg reward: 27.264\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [236] terminated at timestep 400. cumulative reward:   9. avg reward: 27.186\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [237] terminated at timestep 400. cumulative reward:  42. avg reward: 27.249\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [238] terminated at timestep 400. cumulative reward:  23. avg reward: 27.231\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [239] terminated at timestep 400. cumulative reward:  20. avg reward: 27.201\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [240] terminated at timestep 400. cumulative reward:  50. avg reward: 27.296\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [241] terminated at timestep 400. cumulative reward:   9. avg reward: 27.22\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [242] terminated at timestep 400. cumulative reward:  46. avg reward: 27.298\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [243] terminated at timestep 400. cumulative reward:  54. avg reward: 27.407\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [244] terminated at timestep 400. cumulative reward:  31. avg reward: 27.422\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [245] terminated at timestep 400. cumulative reward:  25. avg reward: 27.412\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [246] terminated at timestep 400. cumulative reward:  28. avg reward: 27.415\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [247] terminated at timestep 400. cumulative reward:   6. avg reward: 27.328\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [248] terminated at timestep 400. cumulative reward:   9. avg reward: 27.254\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [249] terminated at timestep 400. cumulative reward:  45. avg reward: 27.325\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [250] terminated at timestep 400. cumulative reward:  12. avg reward: 27.264\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [251] terminated at timestep 400. cumulative reward:  39. avg reward: 27.311\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [252] terminated at timestep 400. cumulative reward:  42. avg reward: 27.369\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [253] terminated at timestep 400. cumulative reward:  28. avg reward: 27.372\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [254] terminated at timestep 400. cumulative reward:  33. avg reward: 27.394\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [255] terminated at timestep 400. cumulative reward:  45. avg reward: 27.463\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [256] terminated at timestep 400. cumulative reward:   9. avg reward: 27.391\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [257] terminated at timestep 400. cumulative reward:  46. avg reward: 27.463\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [258] terminated at timestep 400. cumulative reward:  28. avg reward: 27.465\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [259] terminated at timestep 400. cumulative reward:  36. avg reward: 27.498\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [260] terminated at timestep 400. cumulative reward:  71. avg reward: 27.665\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [261] terminated at timestep 400. cumulative reward:  53. avg reward: 27.762\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [262] terminated at timestep 400. cumulative reward:  34. avg reward: 27.786\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [263] terminated at timestep 400. cumulative reward:  36. avg reward: 27.817\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [264] terminated at timestep 400. cumulative reward:  34. avg reward: 27.841\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [265] terminated at timestep 400. cumulative reward:  99. avg reward: 28.109\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [266] terminated at timestep 400. cumulative reward:  59. avg reward: 28.226\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [267] terminated at timestep 400. cumulative reward:  80. avg reward: 28.419\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [268] terminated at timestep 400. cumulative reward:  23. avg reward: 28.399\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [269] terminated at timestep 400. cumulative reward:  17. avg reward: 28.357\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [270] terminated at timestep 400. cumulative reward:  12. avg reward: 28.296\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [271] terminated at timestep 400. cumulative reward:  42. avg reward: 28.347\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [272] terminated at timestep 400. cumulative reward:  45. avg reward: 28.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [273] terminated at timestep 400. cumulative reward:  12. avg reward: 28.348\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [274] terminated at timestep 400. cumulative reward:   9. avg reward: 28.277\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [275] terminated at timestep 400. cumulative reward:  12. avg reward: 28.218\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [276] terminated at timestep 400. cumulative reward:  64. avg reward: 28.348\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [277] terminated at timestep 400. cumulative reward:  23. avg reward: 28.329\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [278] terminated at timestep 400. cumulative reward:  37. avg reward: 28.36\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [279] terminated at timestep 400. cumulative reward:  20. avg reward: 28.33\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [280] terminated at timestep 400. cumulative reward:  23. avg reward: 28.311\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [281] terminated at timestep 400. cumulative reward:  31. avg reward: 28.32\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [282] terminated at timestep 400. cumulative reward:  44. avg reward: 28.376\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [283] terminated at timestep 400. cumulative reward:  71. avg reward: 28.527\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [284] terminated at timestep 400. cumulative reward:  46. avg reward: 28.588\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [285] terminated at timestep 400. cumulative reward:   9. avg reward: 28.519\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [286] terminated at timestep 400. cumulative reward:  46. avg reward: 28.58\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [287] terminated at timestep 400. cumulative reward:  12. avg reward: 28.523\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [288] terminated at timestep 400. cumulative reward:  17. avg reward: 28.483\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [289] terminated at timestep 400. cumulative reward:  20. avg reward: 28.453\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [290] terminated at timestep 400. cumulative reward:  22. avg reward: 28.431\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [291] terminated at timestep 400. cumulative reward:  14. avg reward: 28.381\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [292] terminated at timestep 400. cumulative reward:   9. avg reward: 28.315\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [293] terminated at timestep 400. cumulative reward:  56. avg reward: 28.41\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [294] terminated at timestep 400. cumulative reward:  26. avg reward: 28.401\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [295] terminated at timestep 400. cumulative reward:  28. avg reward: 28.4\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [296] terminated at timestep 400. cumulative reward:   9. avg reward: 28.334\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [297] terminated at timestep 400. cumulative reward:  62. avg reward: 28.448\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [298] terminated at timestep 400. cumulative reward:  25. avg reward: 28.436\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [299] terminated at timestep 400. cumulative reward:  39. avg reward: 28.472\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [300] terminated at timestep 400. cumulative reward:  40. avg reward: 28.51\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [301] terminated at timestep 400. cumulative reward:   9. avg reward: 28.445\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [302] terminated at timestep 400. cumulative reward:   9. avg reward: 28.381\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [303] terminated at timestep 400. cumulative reward:  23. avg reward: 28.363\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [304] terminated at timestep 400. cumulative reward:  17. avg reward: 28.326\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [305] terminated at timestep 400. cumulative reward:  51. avg reward: 28.4\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [306] terminated at timestep 400. cumulative reward:  57. avg reward: 28.493\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [307] terminated at timestep 400. cumulative reward:  20. avg reward: 28.466\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [308] terminated at timestep 400. cumulative reward:  51. avg reward: 28.539\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [309] terminated at timestep 400. cumulative reward:   9. avg reward: 28.476\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [310] terminated at timestep 400. cumulative reward:  80. avg reward: 28.642\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [311] terminated at timestep 400. cumulative reward:  12. avg reward: 28.588\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [312] terminated at timestep 400. cumulative reward:  40. avg reward: 28.625\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [313] terminated at timestep 400. cumulative reward:  28. avg reward: 28.623\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [314] terminated at timestep 400. cumulative reward:  51. avg reward: 28.694\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [315] terminated at timestep 400. cumulative reward:  31. avg reward: 28.702\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [316] terminated at timestep 400. cumulative reward:  34. avg reward: 28.718\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [317] terminated at timestep 400. cumulative reward:  12. avg reward: 28.666\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [318] terminated at timestep 400. cumulative reward:  22. avg reward: 28.645\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [319] terminated at timestep 400. cumulative reward:  39. avg reward: 28.677\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [320] terminated at timestep 400. cumulative reward:  31. avg reward: 28.684\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [321] terminated at timestep 400. cumulative reward:  32. avg reward: 28.695\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [322] terminated at timestep 400. cumulative reward:   9. avg reward: 28.634\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [323] terminated at timestep 400. cumulative reward:  39. avg reward: 28.666\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [324] terminated at timestep 400. cumulative reward:  51. avg reward: 28.735\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [325] terminated at timestep 400. cumulative reward:  25. avg reward: 28.723\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [326] terminated at timestep 400. cumulative reward:  12. avg reward: 28.672\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [327] terminated at timestep 400. cumulative reward:  40. avg reward: 28.706\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [328] terminated at timestep 400. cumulative reward:  28. avg reward: 28.704\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [329] terminated at timestep 400. cumulative reward:  23. avg reward: 28.687\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [330] terminated at timestep 400. cumulative reward:  22. avg reward: 28.667\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [331] terminated at timestep 400. cumulative reward:  43. avg reward: 28.71\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [332] terminated at timestep 400. cumulative reward:  23. avg reward: 28.693\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [333] terminated at timestep 400. cumulative reward:  14. avg reward: 28.649\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [334] terminated at timestep 400. cumulative reward:  61. avg reward: 28.746\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [335] terminated at timestep 400. cumulative reward:  33. avg reward: 28.758\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [336] terminated at timestep 400. cumulative reward:  51. avg reward: 28.824\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [337] terminated at timestep 400. cumulative reward:  12. avg reward: 28.774\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [338] terminated at timestep 400. cumulative reward:  37. avg reward: 28.799\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [339] terminated at timestep 400. cumulative reward:  40. avg reward: 28.832\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [340] terminated at timestep 400. cumulative reward:  42. avg reward: 28.871\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [341] terminated at timestep 400. cumulative reward:  31. avg reward: 28.877\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [342] terminated at timestep 400. cumulative reward:  22. avg reward: 28.857\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [343] terminated at timestep 400. cumulative reward:  31. avg reward: 28.863\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [344] terminated at timestep 400. cumulative reward:   9. avg reward: 28.805\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [345] terminated at timestep 400. cumulative reward:  20. avg reward: 28.78\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [346] terminated at timestep 400. cumulative reward:   9. avg reward: 28.723\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [347] terminated at timestep 400. cumulative reward:  50. avg reward: 28.784\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [348] terminated at timestep 400. cumulative reward:  39. avg reward: 28.813\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [349] terminated at timestep 400. cumulative reward:  51. avg reward: 28.877\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [350] terminated at timestep 400. cumulative reward:  20. avg reward: 28.851\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [351] terminated at timestep 400. cumulative reward:  20. avg reward: 28.826\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [352] terminated at timestep 400. cumulative reward:  23. avg reward: 28.81\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [353] terminated at timestep 400. cumulative reward:  25. avg reward: 28.799\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [354] terminated at timestep 400. cumulative reward:  22. avg reward: 28.78\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [355] terminated at timestep 400. cumulative reward:  22. avg reward: 28.761\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [356] terminated at timestep 400. cumulative reward:  54. avg reward: 28.831\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [357] terminated at timestep 400. cumulative reward:  28. avg reward: 28.829\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [358] terminated at timestep 400. cumulative reward:  25. avg reward: 28.818\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [359] terminated at timestep 400. cumulative reward:  20. avg reward: 28.794\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [360] terminated at timestep 400. cumulative reward:  28. avg reward: 28.792\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [361] terminated at timestep 400. cumulative reward:  46. avg reward: 28.839\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [362] terminated at timestep 400. cumulative reward:  17. avg reward: 28.807\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [363] terminated at timestep 400. cumulative reward:  48. avg reward: 28.86\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [364] terminated at timestep 400. cumulative reward:  23. avg reward: 28.843\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [365] terminated at timestep 400. cumulative reward:  28. avg reward: 28.841\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [366] terminated at timestep 400. cumulative reward:  31. avg reward: 28.847\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [367] terminated at timestep 400. cumulative reward:  25. avg reward: 28.837\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [368] terminated at timestep 400. cumulative reward:  56. avg reward: 28.91\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [369] terminated at timestep 400. cumulative reward:  23. avg reward: 28.894\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [370] terminated at timestep 400. cumulative reward:  25. avg reward: 28.884\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [371] terminated at timestep 400. cumulative reward:  31. avg reward: 28.889\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [372] terminated at timestep 400. cumulative reward:  33. avg reward: 28.901\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [373] terminated at timestep 400. cumulative reward:  37. avg reward: 28.922\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [374] terminated at timestep 400. cumulative reward:  23. avg reward: 28.906\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [375] terminated at timestep 400. cumulative reward:  17. avg reward: 28.875\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [376] terminated at timestep 400. cumulative reward:  31. avg reward: 28.88\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [377] terminated at timestep 400. cumulative reward:  37. avg reward: 28.902\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [378] terminated at timestep 400. cumulative reward:  17. avg reward: 28.87\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [379] terminated at timestep 400. cumulative reward:  46. avg reward: 28.916\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [380] terminated at timestep 400. cumulative reward:  25. avg reward: 28.905\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [381] terminated at timestep 400. cumulative reward:  28. avg reward: 28.903\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [382] terminated at timestep 400. cumulative reward:  48. avg reward: 28.953\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [383] terminated at timestep 400. cumulative reward:  28. avg reward: 28.95\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [384] terminated at timestep 400. cumulative reward:   9. avg reward: 28.898\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [385] terminated at timestep 400. cumulative reward:  23. avg reward: 28.883\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [386] terminated at timestep 400. cumulative reward:  51. avg reward: 28.94\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [387] terminated at timestep 400. cumulative reward:  17. avg reward: 28.91\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [388] terminated at timestep 400. cumulative reward:  27. avg reward: 28.905\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [389] terminated at timestep 400. cumulative reward:  40. avg reward: 28.933\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [390] terminated at timestep 400. cumulative reward:  28. avg reward: 28.931\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [391] terminated at timestep 400. cumulative reward:  20. avg reward: 28.908\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [392] terminated at timestep 400. cumulative reward:  25. avg reward: 28.898\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [393] terminated at timestep 400. cumulative reward:  36. avg reward: 28.916\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [394] terminated at timestep 400. cumulative reward:  43. avg reward: 28.952\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [395] terminated at timestep 400. cumulative reward:  22. avg reward: 28.934\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [396] terminated at timestep 400. cumulative reward:  59. avg reward: 29.01\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [397] terminated at timestep 400. cumulative reward:  50. avg reward: 29.063\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [398] terminated at timestep 400. cumulative reward:  31. avg reward: 29.068\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [399] terminated at timestep 400. cumulative reward:  12. avg reward: 29.025\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [400] terminated at timestep 400. cumulative reward:  36. avg reward: 29.043\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [401] terminated at timestep 400. cumulative reward:  12. avg reward: 29.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [402] terminated at timestep 400. cumulative reward:  56. avg reward: 29.067\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [403] terminated at timestep 400. cumulative reward:  59. avg reward: 29.141\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [404] terminated at timestep 400. cumulative reward:  37. avg reward: 29.161\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [405] terminated at timestep 400. cumulative reward:  36. avg reward: 29.178\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [406] terminated at timestep 400. cumulative reward:  37. avg reward: 29.197\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [407] terminated at timestep 400. cumulative reward:  31. avg reward: 29.201\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [408] terminated at timestep 400. cumulative reward:  42. avg reward: 29.233\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [409] terminated at timestep 400. cumulative reward:   9. avg reward: 29.183\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [410] terminated at timestep 400. cumulative reward:  43. avg reward: 29.217\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [411] terminated at timestep 400. cumulative reward:  23. avg reward: 29.202\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [412] terminated at timestep 400. cumulative reward:  17. avg reward: 29.172\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [413] terminated at timestep 400. cumulative reward:  22. avg reward: 29.155\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [414] terminated at timestep 400. cumulative reward:   9. avg reward: 29.106\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [415] terminated at timestep 400. cumulative reward:  42. avg reward: 29.137\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [416] terminated at timestep 400. cumulative reward:  30. avg reward: 29.139\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [417] terminated at timestep 400. cumulative reward:  19. avg reward: 29.115\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [418] terminated at timestep 400. cumulative reward:  34. avg reward: 29.127\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [419] terminated at timestep 400. cumulative reward:  17. avg reward: 29.098\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [420] terminated at timestep 400. cumulative reward:  17. avg reward: 29.069\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [421] terminated at timestep 400. cumulative reward:  20. avg reward: 29.048\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [422] terminated at timestep 400. cumulative reward:  23. avg reward: 29.033\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [423] terminated at timestep 400. cumulative reward:  39. avg reward: 29.057\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [424] terminated at timestep 400. cumulative reward:  34. avg reward: 29.068\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [425] terminated at timestep 400. cumulative reward:  39. avg reward: 29.092\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [426] terminated at timestep 400. cumulative reward:   9. avg reward: 29.045\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [427] terminated at timestep 400. cumulative reward:  57. avg reward: 29.11\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [428] terminated at timestep 400. cumulative reward:  28. avg reward: 29.107\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [429] terminated at timestep 400. cumulative reward:  28. avg reward: 29.105\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [430] terminated at timestep 400. cumulative reward:  20. avg reward: 29.084\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [431] terminated at timestep 400. cumulative reward:  43. avg reward: 29.116\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [432] terminated at timestep 400. cumulative reward:  17. avg reward: 29.088\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [433] terminated at timestep 400. cumulative reward:  48. avg reward: 29.132\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [434] terminated at timestep 400. cumulative reward:  68. avg reward: 29.221\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [435] terminated at timestep 400. cumulative reward:  34. avg reward: 29.232\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [436] terminated at timestep 400. cumulative reward:  28. avg reward: 29.229\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [437] terminated at timestep 400. cumulative reward:  25. avg reward: 29.22\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [438] terminated at timestep 400. cumulative reward:  12. avg reward: 29.18\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [439] terminated at timestep 400. cumulative reward:  37. avg reward: 29.198\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [440] terminated at timestep 400. cumulative reward:  31. avg reward: 29.202\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [441] terminated at timestep 400. cumulative reward:  34. avg reward: 29.213\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [442] terminated at timestep 400. cumulative reward:  28. avg reward: 29.21\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [443] terminated at timestep 400. cumulative reward:  54. avg reward: 29.266\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [444] terminated at timestep 400. cumulative reward:  12. avg reward: 29.227\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [445] terminated at timestep 400. cumulative reward:  26. avg reward: 29.22\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [446] terminated at timestep 400. cumulative reward:  45. avg reward: 29.256\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [447] terminated at timestep 400. cumulative reward:   9. avg reward: 29.21\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [448] terminated at timestep 400. cumulative reward:  12. avg reward: 29.172\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [449] terminated at timestep 400. cumulative reward:  85. avg reward: 29.296\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [450] terminated at timestep 400. cumulative reward:  30. avg reward: 29.298\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [451] terminated at timestep 400. cumulative reward:  28. avg reward: 29.295\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [452] terminated at timestep 400. cumulative reward:   9. avg reward: 29.25\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [453] terminated at timestep 400. cumulative reward:   9. avg reward: 29.205\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [454] terminated at timestep 400. cumulative reward:  51. avg reward: 29.253\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [455] terminated at timestep 400. cumulative reward:  20. avg reward: 29.233\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [456] terminated at timestep 400. cumulative reward:  20. avg reward: 29.213\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [457] terminated at timestep 400. cumulative reward:  31. avg reward: 29.217\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [458] terminated at timestep 400. cumulative reward:   9. avg reward: 29.172\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [459] terminated at timestep 400. cumulative reward:  25. avg reward: 29.163\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [460] terminated at timestep 400. cumulative reward:  45. avg reward: 29.198\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [461] terminated at timestep 400. cumulative reward:  17. avg reward: 29.171\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [462] terminated at timestep 400. cumulative reward:  59. avg reward: 29.236\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [463] terminated at timestep 400. cumulative reward:  42. avg reward: 29.263\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [464] terminated at timestep 400. cumulative reward:  20. avg reward: 29.244\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [465] terminated at timestep 400. cumulative reward:  12. avg reward: 29.206\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [466] terminated at timestep 400. cumulative reward:  28. avg reward: 29.204\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [467] terminated at timestep 400. cumulative reward:  20. avg reward: 29.184\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [468] terminated at timestep 400. cumulative reward:  12. avg reward: 29.147\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [469] terminated at timestep 400. cumulative reward:  62. avg reward: 29.217\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [470] terminated at timestep 400. cumulative reward:  31. avg reward: 29.221\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [471] terminated at timestep 400. cumulative reward:  12. avg reward: 29.185\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [472] terminated at timestep 400. cumulative reward:  22. avg reward: 29.169\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [473] terminated at timestep 400. cumulative reward:  57. avg reward: 29.228\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [474] terminated at timestep 400. cumulative reward:  26. avg reward: 29.222\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [475] terminated at timestep 400. cumulative reward:  71. avg reward: 29.309\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [476] terminated at timestep 400. cumulative reward:  25. avg reward: 29.3\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [477] terminated at timestep 400. cumulative reward:  31. avg reward: 29.304\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [478] terminated at timestep 400. cumulative reward:  28. avg reward: 29.301\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [479] terminated at timestep 400. cumulative reward:   6. avg reward: 29.253\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [480] terminated at timestep 400. cumulative reward:  57. avg reward: 29.31\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [481] terminated at timestep 400. cumulative reward:  12. avg reward: 29.274\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [482] terminated at timestep 400. cumulative reward:  12. avg reward: 29.239\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [483] terminated at timestep 400. cumulative reward:  28. avg reward: 29.236\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [484] terminated at timestep 400. cumulative reward:  23. avg reward: 29.223\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [485] terminated at timestep 400. cumulative reward:  51. avg reward: 29.268\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [486] terminated at timestep 400. cumulative reward:  28. avg reward: 29.265\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [487] terminated at timestep 400. cumulative reward:  25. avg reward: 29.257\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [488] terminated at timestep 400. cumulative reward:  36. avg reward: 29.27\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [489] terminated at timestep 400. cumulative reward:  23. avg reward: 29.258\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [490] terminated at timestep 400. cumulative reward:  12. avg reward: 29.222\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [491] terminated at timestep 400. cumulative reward:  34. avg reward: 29.232\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [492] terminated at timestep 400. cumulative reward:  73. avg reward: 29.321\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [493] terminated at timestep 400. cumulative reward:  20. avg reward: 29.302\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [494] terminated at timestep 400. cumulative reward:  34. avg reward: 29.312\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [495] terminated at timestep 400. cumulative reward:  23. avg reward: 29.299\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [496] terminated at timestep 400. cumulative reward:   9. avg reward: 29.258\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [497] terminated at timestep 400. cumulative reward:  23. avg reward: 29.245\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [498] terminated at timestep 400. cumulative reward:  43. avg reward: 29.273\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [499] terminated at timestep 400. cumulative reward:  12. avg reward: 29.238\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [500] terminated at timestep 400. cumulative reward:  57. avg reward: 29.294\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [501] terminated at timestep 400. cumulative reward:  39. avg reward: 29.313\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [502] terminated at timestep 400. cumulative reward:  45. avg reward: 29.345\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [503] terminated at timestep 400. cumulative reward:  23. avg reward: 29.332\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [504] terminated at timestep 400. cumulative reward:  12. avg reward: 29.298\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [505] terminated at timestep 400. cumulative reward:  34. avg reward: 29.307\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [506] terminated at timestep 400. cumulative reward:  48. avg reward: 29.344\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [507] terminated at timestep 400. cumulative reward:  48. avg reward: 29.381\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [508] terminated at timestep 400. cumulative reward:  14. avg reward: 29.35\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [509] terminated at timestep 400. cumulative reward:  46. avg reward: 29.383\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [510] terminated at timestep 400. cumulative reward:  48. avg reward: 29.42\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [511] terminated at timestep 400. cumulative reward:  48. avg reward: 29.456\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [512] terminated at timestep 400. cumulative reward:  12. avg reward: 29.422\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [513] terminated at timestep 400. cumulative reward:  51. avg reward: 29.464\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [514] terminated at timestep 400. cumulative reward:  46. avg reward: 29.496\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [515] terminated at timestep 400. cumulative reward:  46. avg reward: 29.528\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [516] terminated at timestep 400. cumulative reward:  42. avg reward: 29.552\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [517] terminated at timestep 400. cumulative reward:  51. avg reward: 29.594\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [518] terminated at timestep 400. cumulative reward:  12. avg reward: 29.56\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [519] terminated at timestep 400. cumulative reward:  20. avg reward: 29.541\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [520] terminated at timestep 400. cumulative reward:  20. avg reward: 29.523\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [521] terminated at timestep 400. cumulative reward:  31. avg reward: 29.526\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [522] terminated at timestep 400. cumulative reward:   6. avg reward: 29.481\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [523] terminated at timestep 400. cumulative reward:  12. avg reward: 29.447\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [524] terminated at timestep 400. cumulative reward:  12. avg reward: 29.414\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [525] terminated at timestep 400. cumulative reward:  23. avg reward: 29.402\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [526] terminated at timestep 400. cumulative reward:  22. avg reward: 29.388\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [527] terminated at timestep 400. cumulative reward:  19. avg reward: 29.368\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [528] terminated at timestep 400. cumulative reward:  28. avg reward: 29.366\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [529] terminated at timestep 400. cumulative reward:  48. avg reward: 29.401\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [530] terminated at timestep 400. cumulative reward:  28. avg reward: 29.398\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [531] terminated at timestep 400. cumulative reward:  51. avg reward: 29.439\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [532] terminated at timestep 400. cumulative reward:  26. avg reward: 29.432\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [533] terminated at timestep 400. cumulative reward:  25. avg reward: 29.424\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [534] terminated at timestep 400. cumulative reward:  23. avg reward: 29.412\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [535] terminated at timestep 400. cumulative reward:  12. avg reward: 29.379\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [536] terminated at timestep 400. cumulative reward:  37. avg reward: 29.394\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [537] terminated at timestep 400. cumulative reward:  33. avg reward: 29.4\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [538] terminated at timestep 400. cumulative reward:  22. avg reward: 29.387\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [539] terminated at timestep 400. cumulative reward:  12. avg reward: 29.354\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [540] terminated at timestep 400. cumulative reward:  51. avg reward: 29.394\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [541] terminated at timestep 400. cumulative reward:  31. avg reward: 29.397\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [542] terminated at timestep 400. cumulative reward:  54. avg reward: 29.443\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [543] terminated at timestep 400. cumulative reward:  20. avg reward: 29.425\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [544] terminated at timestep 400. cumulative reward:  20. avg reward: 29.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [545] terminated at timestep 400. cumulative reward:  46. avg reward: 29.439\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [546] terminated at timestep 400. cumulative reward:  20. avg reward: 29.421\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [547] terminated at timestep 400. cumulative reward:  31. avg reward: 29.424\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [548] terminated at timestep 400. cumulative reward:  36. avg reward: 29.436\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [549] terminated at timestep 400. cumulative reward:  14. avg reward: 29.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [550] terminated at timestep 400. cumulative reward:  31. avg reward: 29.411\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [551] terminated at timestep 400. cumulative reward:  30. avg reward: 29.412\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [552] terminated at timestep 400. cumulative reward:  34. avg reward: 29.42\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [553] terminated at timestep 400. cumulative reward:  28. avg reward: 29.418\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [554] terminated at timestep 400. cumulative reward:  31. avg reward: 29.421\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [555] terminated at timestep 400. cumulative reward:  45. avg reward: 29.449\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [556] terminated at timestep 400. cumulative reward:  42. avg reward: 29.471\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [557] terminated at timestep 400. cumulative reward:  37. avg reward: 29.485\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [558] terminated at timestep 400. cumulative reward:  62. avg reward: 29.543\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [559] terminated at timestep 400. cumulative reward:  31. avg reward: 29.546\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [560] terminated at timestep 400. cumulative reward:  53. avg reward: 29.588\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [561] terminated at timestep 400. cumulative reward:  39. avg reward: 29.604\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [562] terminated at timestep 400. cumulative reward:  39. avg reward: 29.621\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [563] terminated at timestep 400. cumulative reward:  12. avg reward: 29.59\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [564] terminated at timestep 400. cumulative reward:  25. avg reward: 29.582\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [565] terminated at timestep 400. cumulative reward:  54. avg reward: 29.625\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [566] terminated at timestep 400. cumulative reward:  51. avg reward: 29.663\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [567] terminated at timestep 400. cumulative reward:  59. avg reward: 29.714\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [568] terminated at timestep 400. cumulative reward:  45. avg reward: 29.741\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [569] terminated at timestep 400. cumulative reward:  23. avg reward: 29.729\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [570] terminated at timestep 400. cumulative reward:  62. avg reward: 29.786\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [571] terminated at timestep 400. cumulative reward:  33. avg reward: 29.792\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [572] terminated at timestep 400. cumulative reward:  57. avg reward: 29.839\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [573] terminated at timestep 400. cumulative reward:  36. avg reward: 29.85\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [574] terminated at timestep 400. cumulative reward:  14. avg reward: 29.822\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [575] terminated at timestep 400. cumulative reward:  17. avg reward: 29.8\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [576] terminated at timestep 400. cumulative reward:  36. avg reward: 29.811\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [577] terminated at timestep 400. cumulative reward:   9. avg reward: 29.775\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [578] terminated at timestep 400. cumulative reward:  23. avg reward: 29.763\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [579] terminated at timestep 400. cumulative reward:   9. avg reward: 29.727\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [580] terminated at timestep 400. cumulative reward:  36. avg reward: 29.738\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [581] terminated at timestep 400. cumulative reward:  40. avg reward: 29.756\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [582] terminated at timestep 400. cumulative reward:  12. avg reward: 29.725\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [583] terminated at timestep 400. cumulative reward:  36. avg reward: 29.736\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [584] terminated at timestep 400. cumulative reward:  20. avg reward: 29.719\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [585] terminated at timestep 400. cumulative reward:  23. avg reward: 29.708\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [586] terminated at timestep 400. cumulative reward:  12. avg reward: 29.677\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [587] terminated at timestep 400. cumulative reward:  31. avg reward: 29.68\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [588] terminated at timestep 400. cumulative reward:  12. avg reward: 29.65\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [589] terminated at timestep 400. cumulative reward:  25. avg reward: 29.642\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [590] terminated at timestep 400. cumulative reward:  59. avg reward: 29.692\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [591] terminated at timestep 400. cumulative reward:  65. avg reward: 29.751\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [592] terminated at timestep 400. cumulative reward:  25. avg reward: 29.743\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [593] terminated at timestep 400. cumulative reward:  17. avg reward: 29.722\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [594] terminated at timestep 400. cumulative reward:  51. avg reward: 29.758\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [595] terminated at timestep 400. cumulative reward:  48. avg reward: 29.788\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [596] terminated at timestep 400. cumulative reward:   9. avg reward: 29.753\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [597] terminated at timestep 400. cumulative reward:  25. avg reward: 29.745\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [598] terminated at timestep 400. cumulative reward:  56. avg reward: 29.789\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [599] terminated at timestep 400. cumulative reward:  28. avg reward: 29.786\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [600] terminated at timestep 400. cumulative reward:  36. avg reward: 29.797\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [601] terminated at timestep 400. cumulative reward:  20. avg reward: 29.78\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [602] terminated at timestep 400. cumulative reward:  23. avg reward: 29.769\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [603] terminated at timestep 400. cumulative reward:  19. avg reward: 29.751\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [604] terminated at timestep 400. cumulative reward:  28. avg reward: 29.748\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [605] terminated at timestep 400. cumulative reward:  23. avg reward: 29.737\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [606] terminated at timestep 400. cumulative reward:  20. avg reward: 29.721\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [607] terminated at timestep 400. cumulative reward:  36. avg reward: 29.731\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [608] terminated at timestep 400. cumulative reward:  46. avg reward: 29.758\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [609] terminated at timestep 400. cumulative reward:  12. avg reward: 29.729\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [610] terminated at timestep 400. cumulative reward:  51. avg reward: 29.764\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [611] terminated at timestep 400. cumulative reward:  30. avg reward: 29.764\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [612] terminated at timestep 400. cumulative reward:  51. avg reward: 29.799\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [613] terminated at timestep 400. cumulative reward:  26. avg reward: 29.793\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [614] terminated at timestep 400. cumulative reward:  25. avg reward: 29.785\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [615] terminated at timestep 400. cumulative reward:  25. avg reward: 29.777\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [616] terminated at timestep 400. cumulative reward:  22. avg reward: 29.765\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [617] terminated at timestep 400. cumulative reward:  17. avg reward: 29.744\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [618] terminated at timestep 400. cumulative reward:  12. avg reward: 29.715\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [619] terminated at timestep 400. cumulative reward:  28. avg reward: 29.712\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [620] terminated at timestep 400. cumulative reward:  54. avg reward: 29.752\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [621] terminated at timestep 400. cumulative reward:  43. avg reward: 29.773\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [622] terminated at timestep 400. cumulative reward:  25. avg reward: 29.765\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [623] terminated at timestep 400. cumulative reward:  51. avg reward: 29.799\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [624] terminated at timestep 400. cumulative reward:  12. avg reward: 29.771\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [625] terminated at timestep 400. cumulative reward:  17. avg reward: 29.75\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [626] terminated at timestep 400. cumulative reward:  57. avg reward: 29.794\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [627] terminated at timestep 400. cumulative reward:   9. avg reward: 29.761\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [628] terminated at timestep 400. cumulative reward:  42. avg reward: 29.78\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [629] terminated at timestep 400. cumulative reward:  20. avg reward: 29.765\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [630] terminated at timestep 400. cumulative reward:  31. avg reward: 29.767\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [631] terminated at timestep 400. cumulative reward:  57. avg reward: 29.81\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [632] terminated at timestep 400. cumulative reward:  28. avg reward: 29.807\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [633] terminated at timestep 400. cumulative reward:  20. avg reward: 29.791\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [634] terminated at timestep 400. cumulative reward:  17. avg reward: 29.771\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [635] terminated at timestep 400. cumulative reward:   9. avg reward: 29.739\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [636] terminated at timestep 400. cumulative reward:  31. avg reward: 29.741\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [637] terminated at timestep 400. cumulative reward:  26. avg reward: 29.735\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [638] terminated at timestep 400. cumulative reward:  28. avg reward: 29.732\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [639] terminated at timestep 400. cumulative reward:  23. avg reward: 29.721\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [640] terminated at timestep 400. cumulative reward:  47. avg reward: 29.748\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [641] terminated at timestep 400. cumulative reward:  17. avg reward: 29.729\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [642] terminated at timestep 400. cumulative reward:  36. avg reward: 29.738\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [643] terminated at timestep 400. cumulative reward:  39. avg reward: 29.753\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [644] terminated at timestep 400. cumulative reward:   9. avg reward: 29.72\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [645] terminated at timestep 400. cumulative reward:  42. avg reward: 29.74\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [646] terminated at timestep 400. cumulative reward:  20. avg reward: 29.724\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [647] terminated at timestep 400. cumulative reward:  20. avg reward: 29.709\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [648] terminated at timestep 400. cumulative reward:  31. avg reward: 29.711\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [649] terminated at timestep 400. cumulative reward:  39. avg reward: 29.726\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [650] terminated at timestep 400. cumulative reward:  23. avg reward: 29.715\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [651] terminated at timestep 400. cumulative reward:  25. avg reward: 29.708\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [652] terminated at timestep 400. cumulative reward:  20. avg reward: 29.693\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [653] terminated at timestep 400. cumulative reward:  20. avg reward: 29.678\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [654] terminated at timestep 400. cumulative reward:  54. avg reward: 29.716\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [655] terminated at timestep 400. cumulative reward:  42. avg reward: 29.734\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [656] terminated at timestep 400. cumulative reward:  17. avg reward: 29.715\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [657] terminated at timestep 400. cumulative reward:  42. avg reward: 29.734\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [658] terminated at timestep 400. cumulative reward:  57. avg reward: 29.775\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [659] terminated at timestep 400. cumulative reward:  65. avg reward: 29.829\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [660] terminated at timestep 400. cumulative reward:   9. avg reward: 29.797\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [661] terminated at timestep 400. cumulative reward:  20. avg reward: 29.782\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [662] terminated at timestep 400. cumulative reward:  36. avg reward: 29.792\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [663] terminated at timestep 400. cumulative reward:  22. avg reward: 29.78\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [664] terminated at timestep 400. cumulative reward:  31. avg reward: 29.782\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [665] terminated at timestep 400. cumulative reward:  25. avg reward: 29.774\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [666] terminated at timestep 400. cumulative reward:  12. avg reward: 29.748\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [667] terminated at timestep 400. cumulative reward:  28. avg reward: 29.745\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [668] terminated at timestep 400. cumulative reward:  12. avg reward: 29.719\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [669] terminated at timestep 400. cumulative reward:   9. avg reward: 29.688\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [670] terminated at timestep 400. cumulative reward:   9. avg reward: 29.657\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [671] terminated at timestep 400. cumulative reward:  28. avg reward: 29.654\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [672] terminated at timestep 400. cumulative reward:  31. avg reward: 29.656\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [673] terminated at timestep 400. cumulative reward:  64. avg reward: 29.707\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [674] terminated at timestep 400. cumulative reward:  54. avg reward: 29.743\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [675] terminated at timestep 400. cumulative reward:  42. avg reward: 29.761\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [676] terminated at timestep 400. cumulative reward:   9. avg reward: 29.731\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [677] terminated at timestep 400. cumulative reward:  39. avg reward: 29.744\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [678] terminated at timestep 400. cumulative reward:   9. avg reward: 29.714\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [679] terminated at timestep 400. cumulative reward:  51. avg reward: 29.745\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [680] terminated at timestep 400. cumulative reward:  34. avg reward: 29.751\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [681] terminated at timestep 400. cumulative reward:  31. avg reward: 29.753\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [682] terminated at timestep 400. cumulative reward:  43. avg reward: 29.773\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [683] terminated at timestep 400. cumulative reward:   9. avg reward: 29.742\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [684] terminated at timestep 400. cumulative reward:  26. avg reward: 29.737\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [685] terminated at timestep 400. cumulative reward:  20. avg reward: 29.723\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [686] terminated at timestep 400. cumulative reward:  40. avg reward: 29.738\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [687] terminated at timestep 400. cumulative reward:  54. avg reward: 29.773\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [688] terminated at timestep 400. cumulative reward:  23. avg reward: 29.763\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [689] terminated at timestep 400. cumulative reward:  48. avg reward: 29.79\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [690] terminated at timestep 400. cumulative reward:  43. avg reward: 29.809\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [691] terminated at timestep 400. cumulative reward:  34. avg reward: 29.815\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [692] terminated at timestep 400. cumulative reward:  51. avg reward: 29.845\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [693] terminated at timestep 400. cumulative reward:  40. avg reward: 29.86\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [694] terminated at timestep 400. cumulative reward:  12. avg reward: 29.834\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [695] terminated at timestep 400. cumulative reward:  76. avg reward: 29.901\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [696] terminated at timestep 400. cumulative reward:  54. avg reward: 29.935\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [697] terminated at timestep 400. cumulative reward:  31. avg reward: 29.937\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [698] terminated at timestep 400. cumulative reward:  34. avg reward: 29.943\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [699] terminated at timestep 400. cumulative reward:  65. avg reward: 29.993\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [700] terminated at timestep 400. cumulative reward:  51. avg reward: 30.023\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [701] terminated at timestep 400. cumulative reward:  36. avg reward: 30.031\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [702] terminated at timestep 400. cumulative reward:  31. avg reward: 30.033\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [703] terminated at timestep 400. cumulative reward:  59. avg reward: 30.074\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [704] terminated at timestep 400. cumulative reward:  26. avg reward: 30.068\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [705] terminated at timestep 400. cumulative reward:  60. avg reward: 30.111\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [706] terminated at timestep 400. cumulative reward:  76. avg reward: 30.176\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [707] terminated at timestep 400. cumulative reward:  23. avg reward: 30.165\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [708] terminated at timestep 400. cumulative reward:  65. avg reward: 30.215\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [709] terminated at timestep 400. cumulative reward:  20. avg reward: 30.2\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [710] terminated at timestep 400. cumulative reward:  31. avg reward: 30.201\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [711] terminated at timestep 400. cumulative reward:  53. avg reward: 30.233\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [712] terminated at timestep 400. cumulative reward:  20. avg reward: 30.219\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [713] terminated at timestep 400. cumulative reward:  46. avg reward: 30.241\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [714] terminated at timestep 400. cumulative reward:  51. avg reward: 30.27\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [715] terminated at timestep 400. cumulative reward:  51. avg reward: 30.299\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [716] terminated at timestep 400. cumulative reward:  31. avg reward: 30.3\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [717] terminated at timestep 400. cumulative reward:  17. avg reward: 30.282\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [718] terminated at timestep 400. cumulative reward:  39. avg reward: 30.294\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [719] terminated at timestep 400. cumulative reward:  26. avg reward: 30.288\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [720] terminated at timestep 400. cumulative reward:  62. avg reward: 30.332\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [721] terminated at timestep 400. cumulative reward:  28. avg reward: 30.329\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [722] terminated at timestep 400. cumulative reward:  57. avg reward: 30.366\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [723] terminated at timestep 400. cumulative reward:  25. avg reward: 30.358\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [724] terminated at timestep 400. cumulative reward:  12. avg reward: 30.333\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [725] terminated at timestep 400. cumulative reward:  64. avg reward: 30.379\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [726] terminated at timestep 400. cumulative reward:  31. avg reward: 30.38\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [727] terminated at timestep 400. cumulative reward:  22. avg reward: 30.369\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [728] terminated at timestep 400. cumulative reward:  47. avg reward: 30.391\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [729] terminated at timestep 400. cumulative reward:  48. avg reward: 30.416\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [730] terminated at timestep 400. cumulative reward:  12. avg reward: 30.39\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [731] terminated at timestep 400. cumulative reward:  12. avg reward: 30.365\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [732] terminated at timestep 400. cumulative reward:  65. avg reward: 30.413\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [733] terminated at timestep 400. cumulative reward:   9. avg reward: 30.383\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [734] terminated at timestep 400. cumulative reward:  23. avg reward: 30.373\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [735] terminated at timestep 400. cumulative reward:  22. avg reward: 30.362\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [736] terminated at timestep 400. cumulative reward:  20. avg reward: 30.348\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [737] terminated at timestep 400. cumulative reward:  47. avg reward: 30.37\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [738] terminated at timestep 400. cumulative reward:  37. avg reward: 30.379\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [739] terminated at timestep 400. cumulative reward:  20. avg reward: 30.365\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [740] terminated at timestep 400. cumulative reward:  62. avg reward: 30.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [741] terminated at timestep 400. cumulative reward:  17. avg reward: 30.39\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [742] terminated at timestep 400. cumulative reward:  20. avg reward: 30.376\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [743] terminated at timestep 400. cumulative reward:  54. avg reward: 30.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [744] terminated at timestep 400. cumulative reward:  65. avg reward: 30.454\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [745] terminated at timestep 400. cumulative reward:  12. avg reward: 30.43\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [746] terminated at timestep 400. cumulative reward:  39. avg reward: 30.441\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [747] terminated at timestep 400. cumulative reward:  12. avg reward: 30.416\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [748] terminated at timestep 400. cumulative reward:  68. avg reward: 30.467\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [749] terminated at timestep 400. cumulative reward:  45. avg reward: 30.486\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [750] terminated at timestep 400. cumulative reward:  31. avg reward: 30.487\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [751] terminated at timestep 400. cumulative reward:  42. avg reward: 30.502\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [752] terminated at timestep 400. cumulative reward:  60. avg reward: 30.541\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [753] terminated at timestep 400. cumulative reward:  25. avg reward: 30.534\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [754] terminated at timestep 400. cumulative reward:  20. avg reward: 30.52\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [755] terminated at timestep 400. cumulative reward:  33. avg reward: 30.523\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [756] terminated at timestep 400. cumulative reward:  25. avg reward: 30.516\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [757] terminated at timestep 400. cumulative reward:  25. avg reward: 30.509\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [758] terminated at timestep 400. cumulative reward:  68. avg reward: 30.558\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [759] terminated at timestep 400. cumulative reward:  25. avg reward: 30.551\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [760] terminated at timestep 400. cumulative reward:  25. avg reward: 30.543\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [761] terminated at timestep 400. cumulative reward:  28. avg reward: 30.54\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [762] terminated at timestep 400. cumulative reward:  34. avg reward: 30.545\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [763] terminated at timestep 400. cumulative reward:  51. avg reward: 30.571\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [764] terminated at timestep 400. cumulative reward:  28. avg reward: 30.568\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [765] terminated at timestep 400. cumulative reward:  25. avg reward: 30.561\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [766] terminated at timestep 400. cumulative reward:  12. avg reward: 30.537\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [767] terminated at timestep 400. cumulative reward:  62. avg reward: 30.578\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [768] terminated at timestep 400. cumulative reward:  12. avg reward: 30.553\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [769] terminated at timestep 400. cumulative reward:  31. avg reward: 30.554\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [770] terminated at timestep 400. cumulative reward:  22. avg reward: 30.543\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [771] terminated at timestep 400. cumulative reward:  23. avg reward: 30.533\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [772] terminated at timestep 400. cumulative reward:  26. avg reward: 30.527\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [773] terminated at timestep 400. cumulative reward:  56. avg reward: 30.56\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [774] terminated at timestep 400. cumulative reward:  59. avg reward: 30.597\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [775] terminated at timestep 400. cumulative reward:  20. avg reward: 30.583\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [776] terminated at timestep 400. cumulative reward:  43. avg reward: 30.599\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [777] terminated at timestep 400. cumulative reward:  51. avg reward: 30.625\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [778] terminated at timestep 400. cumulative reward:  54. avg reward: 30.656\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [779] terminated at timestep 400. cumulative reward:  39. avg reward: 30.666\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [780] terminated at timestep 400. cumulative reward:  62. avg reward: 30.706\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [781] terminated at timestep 400. cumulative reward:   9. avg reward: 30.679\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [782] terminated at timestep 400. cumulative reward:  59. avg reward: 30.715\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [783] terminated at timestep 400. cumulative reward:  17. avg reward: 30.697\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [784] terminated at timestep 400. cumulative reward:  51. avg reward: 30.723\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [785] terminated at timestep 400. cumulative reward:  17. avg reward: 30.706\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [786] terminated at timestep 400. cumulative reward:   9. avg reward: 30.678\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [787] terminated at timestep 400. cumulative reward:  37. avg reward: 30.686\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [788] terminated at timestep 400. cumulative reward:  46. avg reward: 30.706\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [789] terminated at timestep 400. cumulative reward:  42. avg reward: 30.72\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [790] terminated at timestep 400. cumulative reward:   9. avg reward: 30.692\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [791] terminated at timestep 400. cumulative reward:  23. avg reward: 30.683\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [792] terminated at timestep 400. cumulative reward:  20. avg reward: 30.669\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [793] terminated at timestep 400. cumulative reward:  51. avg reward: 30.695\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [794] terminated at timestep 400. cumulative reward:  53. avg reward: 30.723\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [795] terminated at timestep 400. cumulative reward:  53. avg reward: 30.751\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [796] terminated at timestep 400. cumulative reward:  56. avg reward: 30.783\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [797] terminated at timestep 400. cumulative reward:  40. avg reward: 30.794\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [798] terminated at timestep 400. cumulative reward:  34. avg reward: 30.798\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [799] terminated at timestep 400. cumulative reward:  28. avg reward: 30.795\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [800] terminated at timestep 400. cumulative reward:  12. avg reward: 30.771\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [801] terminated at timestep 400. cumulative reward:  97. avg reward: 30.854\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [802] terminated at timestep 400. cumulative reward:  22. avg reward: 30.843\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [803] terminated at timestep 400. cumulative reward:  12. avg reward: 30.819\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [804] terminated at timestep 400. cumulative reward:  43. avg reward: 30.835\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [805] terminated at timestep 400. cumulative reward:  39. avg reward: 30.845\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [806] terminated at timestep 400. cumulative reward:  36. avg reward: 30.851\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [807] terminated at timestep 400. cumulative reward:  33. avg reward: 30.854\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [808] terminated at timestep 400. cumulative reward:  33. avg reward: 30.856\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [809] terminated at timestep 400. cumulative reward:  20. avg reward: 30.843\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [810] terminated at timestep 400. cumulative reward:  48. avg reward: 30.864\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [811] terminated at timestep 400. cumulative reward:   9. avg reward: 30.837\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [812] terminated at timestep 400. cumulative reward:  31. avg reward: 30.837\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [813] terminated at timestep 400. cumulative reward:   9. avg reward: 30.811\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [814] terminated at timestep 400. cumulative reward:  63. avg reward: 30.85\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [815] terminated at timestep 400. cumulative reward:  33. avg reward: 30.853\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [816] terminated at timestep 400. cumulative reward:  46. avg reward: 30.871\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [817] terminated at timestep 400. cumulative reward:  47. avg reward: 30.891\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [818] terminated at timestep 400. cumulative reward:  43. avg reward: 30.906\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [819] terminated at timestep 400. cumulative reward:  42. avg reward: 30.919\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [820] terminated at timestep 400. cumulative reward:  56. avg reward: 30.95\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [821] terminated at timestep 400. cumulative reward:  17. avg reward: 30.933\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [822] terminated at timestep 400. cumulative reward:  42. avg reward: 30.946\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [823] terminated at timestep 400. cumulative reward:   9. avg reward: 30.92\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [824] terminated at timestep 400. cumulative reward:  16. avg reward: 30.902\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [825] terminated at timestep 400. cumulative reward:  31. avg reward: 30.902\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [826] terminated at timestep 400. cumulative reward:  33. avg reward: 30.904\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [827] terminated at timestep 400. cumulative reward:  23. avg reward: 30.895\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [828] terminated at timestep 400. cumulative reward:  17. avg reward: 30.878\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [829] terminated at timestep 400. cumulative reward:  34. avg reward: 30.882\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [830] terminated at timestep 400. cumulative reward:  12. avg reward: 30.859\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [831] terminated at timestep 400. cumulative reward:  22. avg reward: 30.848\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [832] terminated at timestep 400. cumulative reward:  12. avg reward: 30.826\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [833] terminated at timestep 400. cumulative reward:  54. avg reward: 30.854\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [834] terminated at timestep 400. cumulative reward:  36. avg reward: 30.86\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [835] terminated at timestep 400. cumulative reward:  23. avg reward: 30.85\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [836] terminated at timestep 400. cumulative reward:   9. avg reward: 30.824\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [837] terminated at timestep 400. cumulative reward:  51. avg reward: 30.848\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [838] terminated at timestep 400. cumulative reward:  51. avg reward: 30.872\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [839] terminated at timestep 400. cumulative reward:  40. avg reward: 30.883\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [840] terminated at timestep 400. cumulative reward:  57. avg reward: 30.914\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [841] terminated at timestep 400. cumulative reward:  42. avg reward: 30.927\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [842] terminated at timestep 400. cumulative reward:  59. avg reward: 30.961\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [843] terminated at timestep 400. cumulative reward:  22. avg reward: 30.95\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [844] terminated at timestep 400. cumulative reward:  26. avg reward: 30.944\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [845] terminated at timestep 400. cumulative reward:  20. avg reward: 30.931\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [846] terminated at timestep 400. cumulative reward:  62. avg reward: 30.968\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [847] terminated at timestep 400. cumulative reward:  43. avg reward: 30.982\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [848] terminated at timestep 400. cumulative reward:  42. avg reward: 30.995\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [849] terminated at timestep 400. cumulative reward:  45. avg reward: 31.012\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [850] terminated at timestep 400. cumulative reward:  48. avg reward: 31.032\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [851] terminated at timestep 400. cumulative reward:  48. avg reward: 31.052\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [852] terminated at timestep 400. cumulative reward:  48. avg reward: 31.072\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [853] terminated at timestep 400. cumulative reward:  51. avg reward: 31.095\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [854] terminated at timestep 400. cumulative reward:  20. avg reward: 31.082\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [855] terminated at timestep 400. cumulative reward:  34. avg reward: 31.085\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [856] terminated at timestep 400. cumulative reward:  25. avg reward: 31.078\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [857] terminated at timestep 400. cumulative reward:  22. avg reward: 31.068\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [858] terminated at timestep 400. cumulative reward:  28. avg reward: 31.064\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [859] terminated at timestep 400. cumulative reward:  31. avg reward: 31.064\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [860] terminated at timestep 400. cumulative reward:  51. avg reward: 31.087\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [861] terminated at timestep 400. cumulative reward:  48. avg reward: 31.107\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [862] terminated at timestep 400. cumulative reward:  31. avg reward: 31.107\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [863] terminated at timestep 400. cumulative reward:   9. avg reward: 31.081\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [864] terminated at timestep 400. cumulative reward:  57. avg reward: 31.111\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [865] terminated at timestep 400. cumulative reward:  14. avg reward: 31.091\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [866] terminated at timestep 400. cumulative reward:  20. avg reward: 31.079\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [867] terminated at timestep 400. cumulative reward:  37. avg reward: 31.085\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [868] terminated at timestep 400. cumulative reward:  40. avg reward: 31.096\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [869] terminated at timestep 400. cumulative reward:  46. avg reward: 31.113\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [870] terminated at timestep 400. cumulative reward:   9. avg reward: 31.087\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [871] terminated at timestep 400. cumulative reward:  42. avg reward: 31.1\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [872] terminated at timestep 400. cumulative reward:  51. avg reward: 31.123\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [873] terminated at timestep 400. cumulative reward:  22. avg reward: 31.112\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [874] terminated at timestep 400. cumulative reward:  54. avg reward: 31.138\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [875] terminated at timestep 400. cumulative reward:  42. avg reward: 31.151\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [876] terminated at timestep 400. cumulative reward:  31. avg reward: 31.151\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [877] terminated at timestep 400. cumulative reward:  20. avg reward: 31.138\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [878] terminated at timestep 400. cumulative reward:  42. avg reward: 31.15\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [879] terminated at timestep 400. cumulative reward:  25. avg reward: 31.143\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [880] terminated at timestep 400. cumulative reward:  20. avg reward: 31.131\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [881] terminated at timestep 400. cumulative reward:  12. avg reward: 31.109\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [882] terminated at timestep 400. cumulative reward:  57. avg reward: 31.138\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [883] terminated at timestep 400. cumulative reward:  42. avg reward: 31.151\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [884] terminated at timestep 400. cumulative reward:  12. avg reward: 31.129\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [885] terminated at timestep 400. cumulative reward:  12. avg reward: 31.107\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [886] terminated at timestep 400. cumulative reward:  12. avg reward: 31.086\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [887] terminated at timestep 400. cumulative reward:  74. avg reward: 31.134\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [888] terminated at timestep 400. cumulative reward:  54. avg reward: 31.16\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [889] terminated at timestep 400. cumulative reward:  34. avg reward: 31.163\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [890] terminated at timestep 400. cumulative reward:  22. avg reward: 31.153\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [891] terminated at timestep 400. cumulative reward:  25. avg reward: 31.146\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [892] terminated at timestep 400. cumulative reward:  19. avg reward: 31.132\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [893] terminated at timestep 400. cumulative reward:  59. avg reward: 31.163\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [894] terminated at timestep 400. cumulative reward:  39. avg reward: 31.172\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [895] terminated at timestep 400. cumulative reward:  71. avg reward: 31.217\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [896] terminated at timestep 400. cumulative reward:  60. avg reward: 31.249\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [897] terminated at timestep 400. cumulative reward:  22. avg reward: 31.239\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [898] terminated at timestep 400. cumulative reward:  34. avg reward: 31.242\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [899] terminated at timestep 400. cumulative reward: 119. avg reward: 31.339\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [900] terminated at timestep 400. cumulative reward:  51. avg reward: 31.361\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [901] terminated at timestep 400. cumulative reward:  36. avg reward: 31.366\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [902] terminated at timestep 400. cumulative reward:  42. avg reward: 31.378\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [903] terminated at timestep 400. cumulative reward:  31. avg reward: 31.378\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [904] terminated at timestep 400. cumulative reward:   9. avg reward: 31.353\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [905] terminated at timestep 400. cumulative reward:  48. avg reward: 31.371\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [906] terminated at timestep 400. cumulative reward:  65. avg reward: 31.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [907] terminated at timestep 400. cumulative reward:  36. avg reward: 31.413\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [908] terminated at timestep 400. cumulative reward:  65. avg reward: 31.45\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [909] terminated at timestep 400. cumulative reward:  39. avg reward: 31.459\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [910] terminated at timestep 400. cumulative reward:  31. avg reward: 31.458\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [911] terminated at timestep 400. cumulative reward:  54. avg reward: 31.483\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [912] terminated at timestep 400. cumulative reward:  37. avg reward: 31.489\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [913] terminated at timestep 400. cumulative reward:  30. avg reward: 31.487\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [914] terminated at timestep 400. cumulative reward:  12. avg reward: 31.466\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [915] terminated at timestep 400. cumulative reward:  14. avg reward: 31.447\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [916] terminated at timestep 400. cumulative reward:  77. avg reward: 31.497\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [917] terminated at timestep 400. cumulative reward:  30. avg reward: 31.495\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [918] terminated at timestep 400. cumulative reward:  46. avg reward: 31.511\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [919] terminated at timestep 400. cumulative reward:  31. avg reward: 31.51\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [920] terminated at timestep 400. cumulative reward:  62. avg reward: 31.543\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [921] terminated at timestep 400. cumulative reward:  12. avg reward: 31.522\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [922] terminated at timestep 400. cumulative reward:  23. avg reward: 31.513\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [923] terminated at timestep 400. cumulative reward:  46. avg reward: 31.529\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [924] terminated at timestep 400. cumulative reward:  86. avg reward: 31.588\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [925] terminated at timestep 400. cumulative reward:  43. avg reward: 31.6\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [926] terminated at timestep 400. cumulative reward:  45. avg reward: 31.614\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [927] terminated at timestep 400. cumulative reward:  45. avg reward: 31.629\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [928] terminated at timestep 400. cumulative reward:  51. avg reward: 31.65\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [929] terminated at timestep 400. cumulative reward:  40. avg reward: 31.659\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [930] terminated at timestep 400. cumulative reward:  54. avg reward: 31.683\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [931] terminated at timestep 400. cumulative reward:  20. avg reward: 31.67\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [932] terminated at timestep 400. cumulative reward:  51. avg reward: 31.691\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [933] terminated at timestep 400. cumulative reward:  79. avg reward: 31.742\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [934] terminated at timestep 400. cumulative reward:  31. avg reward: 31.741\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [935] terminated at timestep 400. cumulative reward:  39. avg reward: 31.749\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [936] terminated at timestep 400. cumulative reward:  28. avg reward: 31.745\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [937] terminated at timestep 400. cumulative reward:  80. avg reward: 31.796\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [938] terminated at timestep 400. cumulative reward:  82. avg reward: 31.85\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [939] terminated at timestep 400. cumulative reward:  57. avg reward: 31.876\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [940] terminated at timestep 400. cumulative reward:  62. avg reward: 31.909\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [941] terminated at timestep 400. cumulative reward:  82. avg reward: 31.962\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [942] terminated at timestep 400. cumulative reward:  51. avg reward: 31.982\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [943] terminated at timestep 400. cumulative reward:  53. avg reward: 32.004\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [944] terminated at timestep 400. cumulative reward:  37. avg reward: 32.01\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [945] terminated at timestep 400. cumulative reward:  39. avg reward: 32.017\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [946] terminated at timestep 400. cumulative reward:   9. avg reward: 31.993\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [947] terminated at timestep 400. cumulative reward:  20. avg reward: 31.98\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [948] terminated at timestep 400. cumulative reward:  59. avg reward: 32.008\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [949] terminated at timestep 400. cumulative reward:  34. avg reward: 32.011\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [950] terminated at timestep 400. cumulative reward:  34. avg reward: 32.013\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [951] terminated at timestep 400. cumulative reward:  34. avg reward: 32.015\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [952] terminated at timestep 400. cumulative reward:  31. avg reward: 32.014\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [953] terminated at timestep 400. cumulative reward:  12. avg reward: 31.993\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [954] terminated at timestep 400. cumulative reward:  22. avg reward: 31.982\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [955] terminated at timestep 400. cumulative reward:  59. avg reward: 32.01\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [956] terminated at timestep 400. cumulative reward:  68. avg reward: 32.048\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [957] terminated at timestep 400. cumulative reward:  65. avg reward: 32.083\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [958] terminated at timestep 400. cumulative reward:  14. avg reward: 32.064\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [959] terminated at timestep 400. cumulative reward:  54. avg reward: 32.087\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [960] terminated at timestep 400. cumulative reward:  42. avg reward: 32.097\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [961] terminated at timestep 400. cumulative reward:  51. avg reward: 32.117\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [962] terminated at timestep 400. cumulative reward:  65. avg reward: 32.151\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [963] terminated at timestep 400. cumulative reward:  19. avg reward: 32.137\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [964] terminated at timestep 400. cumulative reward:  22. avg reward: 32.127\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [965] terminated at timestep 400. cumulative reward:  33. avg reward: 32.127\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [966] terminated at timestep 400. cumulative reward:  25. avg reward: 32.12\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [967] terminated at timestep 400. cumulative reward:  28. avg reward: 32.116\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [968] terminated at timestep 400. cumulative reward:  57. avg reward: 32.142\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [969] terminated at timestep 400. cumulative reward:  31. avg reward: 32.14\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [970] terminated at timestep 400. cumulative reward:  39. avg reward: 32.147\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [971] terminated at timestep 400. cumulative reward:  37. avg reward: 32.152\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [972] terminated at timestep 400. cumulative reward:  36. avg reward: 32.156\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [973] terminated at timestep 400. cumulative reward:   9. avg reward: 32.133\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [974] terminated at timestep 400. cumulative reward:  31. avg reward: 32.131\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [975] terminated at timestep 400. cumulative reward:  28. avg reward: 32.127\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [976] terminated at timestep 400. cumulative reward:  43. avg reward: 32.138\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [977] terminated at timestep 400. cumulative reward:  65. avg reward: 32.172\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [978] terminated at timestep 400. cumulative reward:  25. avg reward: 32.165\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [979] terminated at timestep 400. cumulative reward:  20. avg reward: 32.152\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [980] terminated at timestep 400. cumulative reward:  56. avg reward: 32.177\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [981] terminated at timestep 400. cumulative reward:  33. avg reward: 32.177\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [982] terminated at timestep 400. cumulative reward:  34. avg reward: 32.179\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [983] terminated at timestep 400. cumulative reward:  59. avg reward: 32.207\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [984] terminated at timestep 400. cumulative reward:  39. avg reward: 32.213\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [985] terminated at timestep 400. cumulative reward:  34. avg reward: 32.215\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [986] terminated at timestep 400. cumulative reward:  28. avg reward: 32.211\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [987] terminated at timestep 400. cumulative reward:  28. avg reward: 32.207\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [988] terminated at timestep 400. cumulative reward:  31. avg reward: 32.205\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [989] terminated at timestep 400. cumulative reward:  42. avg reward: 32.215\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [990] terminated at timestep 400. cumulative reward:  12. avg reward: 32.195\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [991] terminated at timestep 400. cumulative reward:  28. avg reward: 32.191\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [992] terminated at timestep 400. cumulative reward:  60. avg reward: 32.219\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [993] terminated at timestep 400. cumulative reward:  23. avg reward: 32.209\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [994] terminated at timestep 400. cumulative reward:  48. avg reward: 32.225\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [995] terminated at timestep 400. cumulative reward:  28. avg reward: 32.221\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [996] terminated at timestep 400. cumulative reward:  31. avg reward: 32.22\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [997] terminated at timestep 400. cumulative reward:  57. avg reward: 32.245\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [998] terminated at timestep 400. cumulative reward:  85. avg reward: 32.298\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [999] terminated at timestep 400. cumulative reward:  45. avg reward: 32.31\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [1000] terminated at timestep 400. cumulative reward:  30. avg reward: 32.308\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 1000\n",
        "number_of_epochs = 2 # prima era 4\n",
        "batch_size = 20\n",
        "average_reward = 0\n",
        "best_avg = 0\n",
        "previous_action_to_reward = 5\n",
        "gamma = 0.95\n",
        "gae_lambda = 0.95\n",
        "avg_reward_list = []\n",
        "\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        actions = []\n",
        "        deltas = []\n",
        "        observations = []\n",
        "\n",
        "        t = 0\n",
        "        obs = env.reset()\n",
        "        obs = obs['both_agent_obs'] \n",
        "        \n",
        "        done = False\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        # if (episode) % 50 == 0:\n",
        "        #     shared_critic.save_weights(path_critic + \"shared_critic_exp_6.weights.h5\")\n",
        "        #     shared_actor.save_weights(path_actor + \"shared_actor_exp_6.weights.h5\")\n",
        "\n",
        "        while not done:\n",
        "            action1 = agent_1.action(obs)\n",
        "            action2 = agent_2.action(obs)\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            action = (player_1_action, player_2_action)\n",
        "\n",
        "            actions.append(action)\n",
        "            observations.append(obs)\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            new_obs = new_obs['both_agent_obs']\n",
        "\n",
        "            # if shaped_reward != 0:\n",
        "            #     shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "            #     shaped_reward_factor *= discount_rate\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            if total_reward > 0:\n",
        "                if t > previous_action_to_reward:\n",
        "                    for i in range(t-1, t-previous_action_to_reward-1, -1):\n",
        "                        deltas[i] += total_reward\n",
        "                else:\n",
        "                    for i in range(t-1,-1,-1):\n",
        "                        deltas[i] += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            if done:\n",
        "                delta = total_reward - shared_critic.call(obs)\n",
        "            else:\n",
        "                delta = total_reward + gamma*shared_critic.call(new_obs) - shared_critic.call(obs)\n",
        "\n",
        "            deltas.append(delta)\n",
        "            \n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            # think about training the critic by itself for a while\n",
        "            t += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        avg_reward_list.append(average_reward)\n",
        "\n",
        "        if average_reward > best_avg and episode > 20:\n",
        "            best_avg = average_reward\n",
        "            shared_critic.save_weights(path_critic + \"shared_critic_exp_9.weights.h5\")\n",
        "            shared_actor.save_weights(path_actor + \"shared_actor_exp_9.weights.h5\")\n",
        "\n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. avg reward: {round(average_reward, 3)}\")\n",
        "        print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "        for epoch in range(1, number_of_epochs + 1):\n",
        "            num_batches = len(actions) // batch_size\n",
        "            shuffled_indices = tf.random.shuffle(tf.range(len(actions)))\n",
        "            for batch in range(num_batches):\n",
        "                if batch == num_batches: # last batch\n",
        "                    idx = shuffled_indices[batch*batch_size:]\n",
        "                else:\n",
        "                    idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                deltas_batch = tf.squeeze(tf.gather(deltas, idx), axis=-1)\n",
        "                actions_batch = tf.gather(actions, idx)\n",
        "                observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "                shared_critic.train_batch(deltas_batch, observations_batch)\n",
        "                shared_actor.train_batch(deltas_batch, observations_batch, actions_batch)\n",
        "            print(f\"Epoch {epoch} terminated.\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    shared_critic.save_weights(path_critic + \"shared_critic_exp_9.weights.h5\")\n",
        "    shared_actor.save_weights(path_actor + \"shared_actor_exp_9.weights.h5\")\n",
        "    print(\"User interrupted training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "98ea3453",
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_critic.load_weights(path_critic + \"shared_critic_exp_9.weights.h5\")\n",
        "shared_actor.load_weights(path_actor + \"shared_actor_exp_9.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6090ebe",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 34.00 (std: 12.81, se: 4.05); avg len: 400.00; : 100%|██████████| 10/10 [01:02<00:00,  6.28s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e03ec9cac4d8468fb63862ddc559f318",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "# trajs = ae.evaluate_human_model_pair(1)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "79e4ee71",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the average reward over the episodes\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, number_of_episodes + 1), avg_reward_list)\n",
        "# plt.plot(range(1, number_of_episodes + 1), avg_reward_list_PPO)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Average Reward')\n",
        "plt.title('Average Reward over Episodes')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c8deb954",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{(0, -1): '↑',\n",
              " (0, 1): '↓',\n",
              " (1, 0): '→',\n",
              " (-1, 0): '←',\n",
              " (0, 0): 'stay',\n",
              " 'interact': 'interact'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Action.ACTION_TO_CHAR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66bf159e",
      "metadata": {},
      "source": [
        "# Trial with batches, past reward and GAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "a4b460c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "3b2e5488",
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha_w = 1e-5\n",
        "alpha_t = 1e-6\n",
        "critic_optimizer = Adam(learning_rate=alpha_w)\n",
        "actor_optimizer = Adam(learning_rate=alpha_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "6d9f59e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=actor_optimizer\n",
        "    )\n",
        "\n",
        "shared_critic = ValueFunctionApproximator(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=critic_optimizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "35b0d7c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_1 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    old_policy=None,\n",
        "    critic=shared_critic,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        ")\n",
        "agent_2 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    old_policy=None,\n",
        "    critic=shared_critic,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "8421c88b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leonardo Chiarioni\\Documents\\GitHub\\overcooked_ai\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "c:\\Users\\Leonardo Chiarioni\\Documents\\GitHub\\overcooked_ai\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "shared_critic.load_weights(path_critic + \"shared_critic_exp_9.weights.h5\")\n",
        "shared_actor.load_weights(path_actor + \"shared_actor_exp_9.weights.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd48ca7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the advantages using GAE.\n",
            "Episode [  1] terminated at timestep 400. cumulative reward:   3. avg reward: 3.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [  2] terminated at timestep 400. cumulative reward:   3. avg reward: 3.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [  3] terminated at timestep 400. cumulative reward:   3. avg reward: 3.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [  4] terminated at timestep 400. cumulative reward:  17. avg reward: 6.5\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [  5] terminated at timestep 400. cumulative reward:   6. avg reward: 6.4\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [  6] terminated at timestep 400. cumulative reward:  17. avg reward: 8.167\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [  7] terminated at timestep 400. cumulative reward:   3. avg reward: 7.429\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [  8] terminated at timestep 400. cumulative reward:   3. avg reward: 6.875\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [  9] terminated at timestep 400. cumulative reward:  14. avg reward: 7.667\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 10] terminated at timestep 400. cumulative reward:  14. avg reward: 8.3\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 11] terminated at timestep 400. cumulative reward:  17. avg reward: 9.091\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 12] terminated at timestep 400. cumulative reward:  17. avg reward: 9.75\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 13] terminated at timestep 400. cumulative reward:   3. avg reward: 9.231\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 14] terminated at timestep 400. cumulative reward:   3. avg reward: 8.786\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 15] terminated at timestep 400. cumulative reward:  14. avg reward: 9.133\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 16] terminated at timestep 400. cumulative reward:  11. avg reward: 9.25\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 17] terminated at timestep 400. cumulative reward:   8. avg reward: 9.176\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 18] terminated at timestep 400. cumulative reward:  14. avg reward: 9.444\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 19] terminated at timestep 400. cumulative reward:  19. avg reward: 9.947\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 20] terminated at timestep 400. cumulative reward:  42. avg reward: 11.55\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 21] terminated at timestep 400. cumulative reward:  28. avg reward: 12.333\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 22] terminated at timestep 400. cumulative reward:  14. avg reward: 12.409\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 23] terminated at timestep 400. cumulative reward:  14. avg reward: 12.478\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 24] terminated at timestep 400. cumulative reward:  17. avg reward: 12.667\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 25] terminated at timestep 400. cumulative reward:   3. avg reward: 12.28\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 26] terminated at timestep 400. cumulative reward:  19. avg reward: 12.538\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 27] terminated at timestep 400. cumulative reward:   6. avg reward: 12.296\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 28] terminated at timestep 400. cumulative reward:  14. avg reward: 12.357\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 29] terminated at timestep 400. cumulative reward:  17. avg reward: 12.517\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 30] terminated at timestep 400. cumulative reward:  17. avg reward: 12.667\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 31] terminated at timestep 400. cumulative reward:  11. avg reward: 12.613\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 32] terminated at timestep 400. cumulative reward:   3. avg reward: 12.312\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 33] terminated at timestep 400. cumulative reward:  11. avg reward: 12.273\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 34] terminated at timestep 400. cumulative reward:  37. avg reward: 13.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 35] terminated at timestep 400. cumulative reward:  11. avg reward: 12.943\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 36] terminated at timestep 400. cumulative reward:   6. avg reward: 12.75\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 37] terminated at timestep 400. cumulative reward:   6. avg reward: 12.568\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 38] terminated at timestep 400. cumulative reward:  17. avg reward: 12.684\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 39] terminated at timestep 400. cumulative reward:  37. avg reward: 13.308\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 40] terminated at timestep 400. cumulative reward:  11. avg reward: 13.25\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 41] terminated at timestep 400. cumulative reward:  22. avg reward: 13.463\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 42] terminated at timestep 400. cumulative reward:  17. avg reward: 13.548\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 43] terminated at timestep 400. cumulative reward:  11. avg reward: 13.488\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 44] terminated at timestep 400. cumulative reward:  11. avg reward: 13.432\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 45] terminated at timestep 400. cumulative reward:  14. avg reward: 13.444\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 46] terminated at timestep 400. cumulative reward:   3. avg reward: 13.217\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 47] terminated at timestep 400. cumulative reward:   6. avg reward: 13.064\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 48] terminated at timestep 400. cumulative reward:  14. avg reward: 13.083\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 49] terminated at timestep 400. cumulative reward:  17. avg reward: 13.163\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 50] terminated at timestep 400. cumulative reward:   3. avg reward: 12.96\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 51] terminated at timestep 400. cumulative reward:   6. avg reward: 12.824\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 52] terminated at timestep 400. cumulative reward:  14. avg reward: 12.846\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 53] terminated at timestep 400. cumulative reward:   3. avg reward: 12.66\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 54] terminated at timestep 400. cumulative reward:  25. avg reward: 12.889\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 55] terminated at timestep 400. cumulative reward:  11. avg reward: 12.855\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 56] terminated at timestep 400. cumulative reward:   3. avg reward: 12.679\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 57] terminated at timestep 400. cumulative reward:  14. avg reward: 12.702\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 58] terminated at timestep 400. cumulative reward:   3. avg reward: 12.534\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 59] terminated at timestep 400. cumulative reward:   6. avg reward: 12.424\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 60] terminated at timestep 400. cumulative reward:  31. avg reward: 12.733\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 61] terminated at timestep 400. cumulative reward:  17. avg reward: 12.803\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 62] terminated at timestep 400. cumulative reward:  17. avg reward: 12.871\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 63] terminated at timestep 400. cumulative reward:  22. avg reward: 13.016\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 64] terminated at timestep 400. cumulative reward:  17. avg reward: 13.078\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 65] terminated at timestep 400. cumulative reward:  17. avg reward: 13.138\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 66] terminated at timestep 400. cumulative reward:   3. avg reward: 12.985\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 67] terminated at timestep 400. cumulative reward:   6. avg reward: 12.881\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 68] terminated at timestep 400. cumulative reward:  11. avg reward: 12.853\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 69] terminated at timestep 400. cumulative reward:  20. avg reward: 12.957\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 70] terminated at timestep 400. cumulative reward:   3. avg reward: 12.814\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 71] terminated at timestep 400. cumulative reward:   6. avg reward: 12.718\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 72] terminated at timestep 400. cumulative reward:  14. avg reward: 12.736\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 73] terminated at timestep 400. cumulative reward:  17. avg reward: 12.795\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 74] terminated at timestep 400. cumulative reward:   9. avg reward: 12.743\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 75] terminated at timestep 400. cumulative reward:  25. avg reward: 12.907\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 76] terminated at timestep 400. cumulative reward:   9. avg reward: 12.855\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 77] terminated at timestep 400. cumulative reward:   3. avg reward: 12.727\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 78] terminated at timestep 400. cumulative reward:   3. avg reward: 12.603\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 79] terminated at timestep 400. cumulative reward:   3. avg reward: 12.481\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 80] terminated at timestep 400. cumulative reward:  19. avg reward: 12.562\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 81] terminated at timestep 400. cumulative reward:   8. avg reward: 12.506\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 82] terminated at timestep 400. cumulative reward:   6. avg reward: 12.427\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 83] terminated at timestep 400. cumulative reward:   8. avg reward: 12.373\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 84] terminated at timestep 400. cumulative reward:  16. avg reward: 12.417\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 85] terminated at timestep 400. cumulative reward:   3. avg reward: 12.306\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 86] terminated at timestep 400. cumulative reward:   3. avg reward: 12.198\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 87] terminated at timestep 400. cumulative reward:  22. avg reward: 12.31\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 88] terminated at timestep 400. cumulative reward:  19. avg reward: 12.386\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 89] terminated at timestep 400. cumulative reward:   3. avg reward: 12.281\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 90] terminated at timestep 400. cumulative reward:  11. avg reward: 12.267\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 91] terminated at timestep 400. cumulative reward:  17. avg reward: 12.319\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 92] terminated at timestep 400. cumulative reward:   6. avg reward: 12.25\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 93] terminated at timestep 400. cumulative reward:  14. avg reward: 12.269\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 94] terminated at timestep 400. cumulative reward:  25. avg reward: 12.404\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 95] terminated at timestep 400. cumulative reward:  17. avg reward: 12.453\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 96] terminated at timestep 400. cumulative reward:   3. avg reward: 12.354\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 97] terminated at timestep 400. cumulative reward:   6. avg reward: 12.289\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 98] terminated at timestep 400. cumulative reward:  17. avg reward: 12.337\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [ 99] terminated at timestep 400. cumulative reward:  14. avg reward: 12.354\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [100] terminated at timestep 400. cumulative reward:   3. avg reward: 12.26\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [101] terminated at timestep 400. cumulative reward:   3. avg reward: 12.168\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [102] terminated at timestep 400. cumulative reward:  11. avg reward: 12.157\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [103] terminated at timestep 400. cumulative reward:  25. avg reward: 12.282\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [104] terminated at timestep 400. cumulative reward:  17. avg reward: 12.327\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [105] terminated at timestep 400. cumulative reward:  12. avg reward: 12.324\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [106] terminated at timestep 400. cumulative reward:   6. avg reward: 12.264\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [107] terminated at timestep 400. cumulative reward:  14. avg reward: 12.28\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [108] terminated at timestep 400. cumulative reward:  25. avg reward: 12.398\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [109] terminated at timestep 400. cumulative reward:  11. avg reward: 12.385\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [110] terminated at timestep 400. cumulative reward:   6. avg reward: 12.327\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [111] terminated at timestep 400. cumulative reward:  12. avg reward: 12.324\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [112] terminated at timestep 400. cumulative reward:   6. avg reward: 12.268\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [113] terminated at timestep 400. cumulative reward:   3. avg reward: 12.186\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [114] terminated at timestep 400. cumulative reward:  14. avg reward: 12.202\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [115] terminated at timestep 400. cumulative reward:  14. avg reward: 12.217\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [116] terminated at timestep 400. cumulative reward:   6. avg reward: 12.164\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [117] terminated at timestep 400. cumulative reward:  14. avg reward: 12.179\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [118] terminated at timestep 400. cumulative reward:   9. avg reward: 12.153\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [119] terminated at timestep 400. cumulative reward:   6. avg reward: 12.101\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [120] terminated at timestep 400. cumulative reward:   3. avg reward: 12.025\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [121] terminated at timestep 400. cumulative reward:  14. avg reward: 12.041\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [122] terminated at timestep 400. cumulative reward:  14. avg reward: 12.057\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [123] terminated at timestep 400. cumulative reward:  11. avg reward: 12.049\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [124] terminated at timestep 400. cumulative reward:  11. avg reward: 12.04\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [125] terminated at timestep 400. cumulative reward:   3. avg reward: 11.968\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [126] terminated at timestep 400. cumulative reward:  17. avg reward: 12.008\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [127] terminated at timestep 400. cumulative reward:   6. avg reward: 11.961\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [128] terminated at timestep 400. cumulative reward:   3. avg reward: 11.891\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [129] terminated at timestep 400. cumulative reward:  11. avg reward: 11.884\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [130] terminated at timestep 400. cumulative reward:   3. avg reward: 11.815\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [131] terminated at timestep 400. cumulative reward:   3. avg reward: 11.748\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [132] terminated at timestep 400. cumulative reward:  19. avg reward: 11.803\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [133] terminated at timestep 400. cumulative reward:  14. avg reward: 11.82\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [134] terminated at timestep 400. cumulative reward:  14. avg reward: 11.836\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [135] terminated at timestep 400. cumulative reward:  22. avg reward: 11.911\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [136] terminated at timestep 400. cumulative reward:   3. avg reward: 11.846\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [137] terminated at timestep 400. cumulative reward:  19. avg reward: 11.898\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [138] terminated at timestep 400. cumulative reward:  16. avg reward: 11.928\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [139] terminated at timestep 400. cumulative reward:  11. avg reward: 11.921\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [140] terminated at timestep 400. cumulative reward:  16. avg reward: 11.95\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [141] terminated at timestep 400. cumulative reward:  11. avg reward: 11.943\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [142] terminated at timestep 400. cumulative reward:  14. avg reward: 11.958\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [143] terminated at timestep 400. cumulative reward:   9. avg reward: 11.937\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [144] terminated at timestep 400. cumulative reward:  16. avg reward: 11.965\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [145] terminated at timestep 400. cumulative reward:  14. avg reward: 11.979\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [146] terminated at timestep 400. cumulative reward:  14. avg reward: 11.993\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [147] terminated at timestep 400. cumulative reward:  22. avg reward: 12.061\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [148] terminated at timestep 400. cumulative reward:   3. avg reward: 12.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [149] terminated at timestep 400. cumulative reward:  25. avg reward: 12.087\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [150] terminated at timestep 400. cumulative reward:   6. avg reward: 12.047\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [151] terminated at timestep 400. cumulative reward:  16. avg reward: 12.073\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [152] terminated at timestep 400. cumulative reward:  22. avg reward: 12.138\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [153] terminated at timestep 400. cumulative reward:  11. avg reward: 12.131\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [154] terminated at timestep 400. cumulative reward:  14. avg reward: 12.143\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [155] terminated at timestep 400. cumulative reward:   3. avg reward: 12.084\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [156] terminated at timestep 400. cumulative reward:   3. avg reward: 12.026\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [157] terminated at timestep 400. cumulative reward:   3. avg reward: 11.968\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [158] terminated at timestep 400. cumulative reward:   6. avg reward: 11.93\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [159] terminated at timestep 400. cumulative reward:   6. avg reward: 11.893\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [160] terminated at timestep 400. cumulative reward:  19. avg reward: 11.938\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [161] terminated at timestep 400. cumulative reward:   3. avg reward: 11.882\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [162] terminated at timestep 400. cumulative reward:  19. avg reward: 11.926\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [163] terminated at timestep 400. cumulative reward:  11. avg reward: 11.92\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [164] terminated at timestep 400. cumulative reward:   6. avg reward: 11.884\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [165] terminated at timestep 400. cumulative reward:  17. avg reward: 11.915\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [166] terminated at timestep 400. cumulative reward:  22. avg reward: 11.976\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [167] terminated at timestep 400. cumulative reward:   3. avg reward: 11.922\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [168] terminated at timestep 400. cumulative reward:  17. avg reward: 11.952\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [169] terminated at timestep 400. cumulative reward:   3. avg reward: 11.899\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [170] terminated at timestep 400. cumulative reward:   6. avg reward: 11.865\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [171] terminated at timestep 400. cumulative reward:   3. avg reward: 11.813\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [172] terminated at timestep 400. cumulative reward:  11. avg reward: 11.808\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [173] terminated at timestep 400. cumulative reward:  11. avg reward: 11.803\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [174] terminated at timestep 400. cumulative reward:  14. avg reward: 11.816\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [175] terminated at timestep 400. cumulative reward:  11. avg reward: 11.811\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [176] terminated at timestep 400. cumulative reward:  19. avg reward: 11.852\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [177] terminated at timestep 400. cumulative reward:  11. avg reward: 11.847\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [178] terminated at timestep 400. cumulative reward:  17. avg reward: 11.876\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [179] terminated at timestep 400. cumulative reward:   3. avg reward: 11.827\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [180] terminated at timestep 400. cumulative reward:  20. avg reward: 11.872\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [181] terminated at timestep 400. cumulative reward:  16. avg reward: 11.895\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [182] terminated at timestep 400. cumulative reward:  14. avg reward: 11.907\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [183] terminated at timestep 400. cumulative reward:  12. avg reward: 11.907\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [184] terminated at timestep 400. cumulative reward:  11. avg reward: 11.902\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [185] terminated at timestep 400. cumulative reward:   3. avg reward: 11.854\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [186] terminated at timestep 400. cumulative reward:   6. avg reward: 11.823\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [187] terminated at timestep 400. cumulative reward:  20. avg reward: 11.866\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [188] terminated at timestep 400. cumulative reward:  16. avg reward: 11.888\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [189] terminated at timestep 400. cumulative reward:   9. avg reward: 11.873\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [190] terminated at timestep 400. cumulative reward:  14. avg reward: 11.884\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [191] terminated at timestep 400. cumulative reward:  17. avg reward: 11.911\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [192] terminated at timestep 400. cumulative reward:  16. avg reward: 11.932\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [193] terminated at timestep 400. cumulative reward:  11. avg reward: 11.927\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [194] terminated at timestep 400. cumulative reward:  28. avg reward: 12.01\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [195] terminated at timestep 400. cumulative reward:  11. avg reward: 12.005\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [196] terminated at timestep 400. cumulative reward:  11. avg reward: 12.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [197] terminated at timestep 400. cumulative reward:  14. avg reward: 12.01\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [198] terminated at timestep 400. cumulative reward:   6. avg reward: 11.98\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [199] terminated at timestep 400. cumulative reward:  14. avg reward: 11.99\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [200] terminated at timestep 400. cumulative reward:   8. avg reward: 11.97\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [201] terminated at timestep 400. cumulative reward:  17. avg reward: 11.995\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [202] terminated at timestep 400. cumulative reward:   3. avg reward: 11.95\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [203] terminated at timestep 400. cumulative reward:   3. avg reward: 11.906\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [204] terminated at timestep 400. cumulative reward:  19. avg reward: 11.941\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [205] terminated at timestep 400. cumulative reward:   9. avg reward: 11.927\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [206] terminated at timestep 400. cumulative reward:   3. avg reward: 11.883\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [207] terminated at timestep 400. cumulative reward:   3. avg reward: 11.841\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [208] terminated at timestep 400. cumulative reward:   8. avg reward: 11.822\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [209] terminated at timestep 400. cumulative reward:   3. avg reward: 11.78\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [210] terminated at timestep 400. cumulative reward:   3. avg reward: 11.738\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [211] terminated at timestep 400. cumulative reward:  11. avg reward: 11.735\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [212] terminated at timestep 400. cumulative reward:   6. avg reward: 11.708\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [213] terminated at timestep 400. cumulative reward:   6. avg reward: 11.681\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [214] terminated at timestep 400. cumulative reward:  17. avg reward: 11.706\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [215] terminated at timestep 400. cumulative reward:  14. avg reward: 11.716\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [216] terminated at timestep 400. cumulative reward:  11. avg reward: 11.713\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [217] terminated at timestep 400. cumulative reward:   3. avg reward: 11.673\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [218] terminated at timestep 400. cumulative reward:  17. avg reward: 11.697\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [219] terminated at timestep 400. cumulative reward:  11. avg reward: 11.694\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [220] terminated at timestep 400. cumulative reward:  14. avg reward: 11.705\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [221] terminated at timestep 400. cumulative reward:   3. avg reward: 11.665\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [222] terminated at timestep 400. cumulative reward:  11. avg reward: 11.662\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [223] terminated at timestep 400. cumulative reward:   3. avg reward: 11.623\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [224] terminated at timestep 400. cumulative reward:  11. avg reward: 11.621\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [225] terminated at timestep 400. cumulative reward:   9. avg reward: 11.609\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [226] terminated at timestep 400. cumulative reward:  19. avg reward: 11.642\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [227] terminated at timestep 400. cumulative reward:   3. avg reward: 11.604\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [228] terminated at timestep 400. cumulative reward:   3. avg reward: 11.566\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [229] terminated at timestep 400. cumulative reward:   9. avg reward: 11.555\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [230] terminated at timestep 400. cumulative reward:  37. avg reward: 11.665\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [231] terminated at timestep 400. cumulative reward:   8. avg reward: 11.649\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [232] terminated at timestep 400. cumulative reward:   3. avg reward: 11.612\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [233] terminated at timestep 400. cumulative reward:   3. avg reward: 11.575\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [234] terminated at timestep 400. cumulative reward:   3. avg reward: 11.538\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [235] terminated at timestep 400. cumulative reward:   3. avg reward: 11.502\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [236] terminated at timestep 400. cumulative reward:  22. avg reward: 11.547\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [237] terminated at timestep 400. cumulative reward:   3. avg reward: 11.511\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [238] terminated at timestep 400. cumulative reward:  14. avg reward: 11.521\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [239] terminated at timestep 400. cumulative reward:   3. avg reward: 11.485\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [240] terminated at timestep 400. cumulative reward:  14. avg reward: 11.496\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [241] terminated at timestep 400. cumulative reward:  14. avg reward: 11.506\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [242] terminated at timestep 400. cumulative reward:   6. avg reward: 11.483\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [243] terminated at timestep 400. cumulative reward:   6. avg reward: 11.461\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [244] terminated at timestep 400. cumulative reward:   9. avg reward: 11.451\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [245] terminated at timestep 400. cumulative reward:  11. avg reward: 11.449\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [246] terminated at timestep 400. cumulative reward:  14. avg reward: 11.459\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [247] terminated at timestep 400. cumulative reward:  17. avg reward: 11.482\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [248] terminated at timestep 400. cumulative reward:  14. avg reward: 11.492\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [249] terminated at timestep 400. cumulative reward:   3. avg reward: 11.458\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [250] terminated at timestep 400. cumulative reward:   3. avg reward: 11.424\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [251] terminated at timestep 400. cumulative reward:  11. avg reward: 11.422\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [252] terminated at timestep 400. cumulative reward:   6. avg reward: 11.401\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [253] terminated at timestep 400. cumulative reward:  14. avg reward: 11.411\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [254] terminated at timestep 400. cumulative reward:  25. avg reward: 11.465\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [255] terminated at timestep 400. cumulative reward:   3. avg reward: 11.431\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [256] terminated at timestep 400. cumulative reward:  11. avg reward: 11.43\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [257] terminated at timestep 400. cumulative reward:   3. avg reward: 11.397\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [258] terminated at timestep 400. cumulative reward:  11. avg reward: 11.395\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [259] terminated at timestep 400. cumulative reward:   3. avg reward: 11.363\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [260] terminated at timestep 400. cumulative reward:  14. avg reward: 11.373\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [261] terminated at timestep 400. cumulative reward:  14. avg reward: 11.383\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [262] terminated at timestep 400. cumulative reward:  11. avg reward: 11.382\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [263] terminated at timestep 400. cumulative reward:   3. avg reward: 11.35\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [264] terminated at timestep 400. cumulative reward:   6. avg reward: 11.33\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [265] terminated at timestep 400. cumulative reward:  14. avg reward: 11.34\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [266] terminated at timestep 400. cumulative reward:  19. avg reward: 11.368\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [267] terminated at timestep 400. cumulative reward:  11. avg reward: 11.367\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [268] terminated at timestep 400. cumulative reward:  17. avg reward: 11.388\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [269] terminated at timestep 400. cumulative reward:  17. avg reward: 11.409\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [270] terminated at timestep 400. cumulative reward:   8. avg reward: 11.396\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [271] terminated at timestep 400. cumulative reward:   3. avg reward: 11.365\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [272] terminated at timestep 400. cumulative reward:   3. avg reward: 11.335\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [273] terminated at timestep 400. cumulative reward:   6. avg reward: 11.315\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [274] terminated at timestep 400. cumulative reward:   6. avg reward: 11.296\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [275] terminated at timestep 400. cumulative reward:  14. avg reward: 11.305\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [276] terminated at timestep 400. cumulative reward:   3. avg reward: 11.275\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [277] terminated at timestep 400. cumulative reward:   3. avg reward: 11.245\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [278] terminated at timestep 400. cumulative reward:  17. avg reward: 11.266\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [279] terminated at timestep 400. cumulative reward:  14. avg reward: 11.276\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [280] terminated at timestep 400. cumulative reward:  11. avg reward: 11.275\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [281] terminated at timestep 400. cumulative reward:  14. avg reward: 11.285\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [282] terminated at timestep 400. cumulative reward:  14. avg reward: 11.294\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [283] terminated at timestep 400. cumulative reward:  14. avg reward: 11.304\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [284] terminated at timestep 400. cumulative reward:  14. avg reward: 11.313\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [285] terminated at timestep 400. cumulative reward:   3. avg reward: 11.284\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [286] terminated at timestep 400. cumulative reward:  17. avg reward: 11.304\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [287] terminated at timestep 400. cumulative reward:   3. avg reward: 11.275\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [288] terminated at timestep 400. cumulative reward:  17. avg reward: 11.295\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [289] terminated at timestep 400. cumulative reward:   3. avg reward: 11.266\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [290] terminated at timestep 400. cumulative reward:   3. avg reward: 11.238\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [291] terminated at timestep 400. cumulative reward:   3. avg reward: 11.21\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [292] terminated at timestep 400. cumulative reward:  11. avg reward: 11.209\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [293] terminated at timestep 400. cumulative reward:  22. avg reward: 11.246\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [294] terminated at timestep 400. cumulative reward:  17. avg reward: 11.265\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [295] terminated at timestep 400. cumulative reward:   8. avg reward: 11.254\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [296] terminated at timestep 400. cumulative reward:   3. avg reward: 11.226\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [297] terminated at timestep 400. cumulative reward:  20. avg reward: 11.256\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [298] terminated at timestep 400. cumulative reward:  14. avg reward: 11.265\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [299] terminated at timestep 400. cumulative reward:  22. avg reward: 11.301\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [300] terminated at timestep 400. cumulative reward:  51. avg reward: 11.433\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [301] terminated at timestep 400. cumulative reward:  17. avg reward: 11.452\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [302] terminated at timestep 400. cumulative reward:  17. avg reward: 11.47\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [303] terminated at timestep 400. cumulative reward:   3. avg reward: 11.442\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [304] terminated at timestep 400. cumulative reward:  14. avg reward: 11.451\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [305] terminated at timestep 400. cumulative reward:  12. avg reward: 11.452\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [306] terminated at timestep 400. cumulative reward:   3. avg reward: 11.425\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [307] terminated at timestep 400. cumulative reward:   9. avg reward: 11.417\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [308] terminated at timestep 400. cumulative reward:  17. avg reward: 11.435\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [309] terminated at timestep 400. cumulative reward:   3. avg reward: 11.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [310] terminated at timestep 400. cumulative reward:   6. avg reward: 11.39\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [311] terminated at timestep 400. cumulative reward:   3. avg reward: 11.363\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [312] terminated at timestep 400. cumulative reward:  14. avg reward: 11.372\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [313] terminated at timestep 400. cumulative reward:   3. avg reward: 11.345\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [314] terminated at timestep 400. cumulative reward:  11. avg reward: 11.344\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [315] terminated at timestep 400. cumulative reward:  11. avg reward: 11.343\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [316] terminated at timestep 400. cumulative reward:   6. avg reward: 11.326\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [317] terminated at timestep 400. cumulative reward:  11. avg reward: 11.325\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [318] terminated at timestep 400. cumulative reward:   3. avg reward: 11.299\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [319] terminated at timestep 400. cumulative reward:   6. avg reward: 11.282\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [320] terminated at timestep 400. cumulative reward:   3. avg reward: 11.256\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [321] terminated at timestep 400. cumulative reward:  14. avg reward: 11.265\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [322] terminated at timestep 400. cumulative reward:   8. avg reward: 11.255\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [323] terminated at timestep 400. cumulative reward:   6. avg reward: 11.238\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [324] terminated at timestep 400. cumulative reward:  14. avg reward: 11.247\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [325] terminated at timestep 400. cumulative reward:  22. avg reward: 11.28\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [326] terminated at timestep 400. cumulative reward:   3. avg reward: 11.255\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [327] terminated at timestep 400. cumulative reward:   3. avg reward: 11.229\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [328] terminated at timestep 400. cumulative reward:   9. avg reward: 11.223\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [329] terminated at timestep 400. cumulative reward:  17. avg reward: 11.24\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [330] terminated at timestep 400. cumulative reward:   6. avg reward: 11.224\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [331] terminated at timestep 400. cumulative reward:   8. avg reward: 11.215\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [332] terminated at timestep 400. cumulative reward:   9. avg reward: 11.208\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [333] terminated at timestep 400. cumulative reward:   6. avg reward: 11.192\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [334] terminated at timestep 400. cumulative reward:  11. avg reward: 11.192\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [335] terminated at timestep 400. cumulative reward:   8. avg reward: 11.182\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [336] terminated at timestep 400. cumulative reward:   6. avg reward: 11.167\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [337] terminated at timestep 400. cumulative reward:   3. avg reward: 11.142\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [338] terminated at timestep 400. cumulative reward:  14. avg reward: 11.151\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [339] terminated at timestep 400. cumulative reward:  14. avg reward: 11.159\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [340] terminated at timestep 400. cumulative reward:  14. avg reward: 11.168\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [341] terminated at timestep 400. cumulative reward:  11. avg reward: 11.167\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [342] terminated at timestep 400. cumulative reward:  25. avg reward: 11.208\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [343] terminated at timestep 400. cumulative reward:  17. avg reward: 11.224\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [344] terminated at timestep 400. cumulative reward:   6. avg reward: 11.209\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [345] terminated at timestep 400. cumulative reward:   6. avg reward: 11.194\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [346] terminated at timestep 400. cumulative reward:   9. avg reward: 11.188\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [347] terminated at timestep 400. cumulative reward:   6. avg reward: 11.173\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [348] terminated at timestep 400. cumulative reward:   6. avg reward: 11.158\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [349] terminated at timestep 400. cumulative reward:   9. avg reward: 11.152\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [350] terminated at timestep 400. cumulative reward:   3. avg reward: 11.129\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [351] terminated at timestep 400. cumulative reward:   6. avg reward: 11.114\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [352] terminated at timestep 400. cumulative reward:   3. avg reward: 11.091\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [353] terminated at timestep 400. cumulative reward:  16. avg reward: 11.105\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [354] terminated at timestep 400. cumulative reward:   6. avg reward: 11.09\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [355] terminated at timestep 400. cumulative reward:   9. avg reward: 11.085\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [356] terminated at timestep 400. cumulative reward:  17. avg reward: 11.101\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [357] terminated at timestep 400. cumulative reward:  11. avg reward: 11.101\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [358] terminated at timestep 400. cumulative reward:  11. avg reward: 11.101\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [359] terminated at timestep 400. cumulative reward:   3. avg reward: 11.078\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [360] terminated at timestep 400. cumulative reward:   3. avg reward: 11.056\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [361] terminated at timestep 400. cumulative reward:   6. avg reward: 11.042\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [362] terminated at timestep 400. cumulative reward:   9. avg reward: 11.036\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [363] terminated at timestep 400. cumulative reward:   6. avg reward: 11.022\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [364] terminated at timestep 400. cumulative reward:   6. avg reward: 11.008\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [365] terminated at timestep 400. cumulative reward:   3. avg reward: 10.986\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [366] terminated at timestep 400. cumulative reward:   3. avg reward: 10.964\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [367] terminated at timestep 400. cumulative reward:   9. avg reward: 10.959\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [368] terminated at timestep 400. cumulative reward:   6. avg reward: 10.946\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [369] terminated at timestep 400. cumulative reward:   8. avg reward: 10.938\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [370] terminated at timestep 400. cumulative reward:   8. avg reward: 10.93\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [371] terminated at timestep 400. cumulative reward:  14. avg reward: 10.938\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [372] terminated at timestep 400. cumulative reward:  14. avg reward: 10.946\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [373] terminated at timestep 400. cumulative reward:   9. avg reward: 10.941\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [374] terminated at timestep 400. cumulative reward:   9. avg reward: 10.936\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [375] terminated at timestep 400. cumulative reward:  14. avg reward: 10.944\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [376] terminated at timestep 400. cumulative reward:   9. avg reward: 10.939\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [377] terminated at timestep 400. cumulative reward:  14. avg reward: 10.947\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [378] terminated at timestep 400. cumulative reward:   6. avg reward: 10.934\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [379] terminated at timestep 400. cumulative reward:   6. avg reward: 10.921\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [380] terminated at timestep 400. cumulative reward:   6. avg reward: 10.908\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Computing the advantages using GAE.\n",
            "Episode [381] terminated at timestep 400. cumulative reward:  14. avg reward: 10.916\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "User interrupted training. Saving weights\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 1000\n",
        "number_of_epochs = 2 # prima era 4\n",
        "batch_size = 20\n",
        "average_reward = 0\n",
        "best_avg = 0\n",
        "previous_action_to_reward = 5\n",
        "gamma = 0.95\n",
        "gae_lambda = 0.95\n",
        "avg_reward_list_GAE = []\n",
        "\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        actions = []\n",
        "        deltas = []\n",
        "        observations = []\n",
        "        advantages = []\n",
        "\n",
        "        t = 0\n",
        "        obs = env.reset()\n",
        "        obs = obs['both_agent_obs'] \n",
        "        \n",
        "        done = False\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        # if (episode) % 50 == 0:\n",
        "        #     shared_critic.save_weights(path_critic + \"shared_critic_exp_6.weights.h5\")\n",
        "        #     shared_actor.save_weights(path_actor + \"shared_actor_exp_6.weights.h5\")\n",
        "\n",
        "        while not done:\n",
        "            action1 = agent_1.action(obs)\n",
        "            action2 = agent_2.action(obs)\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            action = (player_1_action, player_2_action)\n",
        "\n",
        "            actions.append(action)\n",
        "            observations.append(obs)\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            new_obs = new_obs['both_agent_obs']\n",
        "\n",
        "            # if shaped_reward != 0:\n",
        "            #     shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "            #     shaped_reward_factor *= discount_rate\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            if total_reward > 0:\n",
        "                if t > previous_action_to_reward:\n",
        "                    for i in range(t-1, t-previous_action_to_reward-1, -1):\n",
        "                        deltas[i] += total_reward\n",
        "                else:\n",
        "                    for i in range(t-1,-1,-1):\n",
        "                        deltas[i] += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            if done:\n",
        "                delta = total_reward - shared_critic.call(obs)\n",
        "            else:\n",
        "                delta = total_reward + gamma*shared_critic.call(new_obs) - shared_critic.call(obs)\n",
        "\n",
        "            deltas.append(delta)\n",
        "            \n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            # think about training the critic by itself for a while\n",
        "            t += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        avg_reward_list_GAE.append(average_reward)\n",
        "\n",
        "        if average_reward > best_avg and episode > 20:\n",
        "            best_avg = average_reward\n",
        "            shared_critic.save_weights(path_critic + \"shared_critic_exp_9.weights.h5\")\n",
        "            shared_actor.save_weights(path_actor + \"shared_actor_exp_9.weights.h5\")\n",
        "\n",
        "        print(f\"Computing the advantages using GAE.\")\n",
        "        lastgaelambda = 0   \n",
        "        for timestep in reversed(range(len(deltas))):\n",
        "            advantage = deltas[timestep] + gamma*gae_lambda*lastgaelambda\n",
        "            lastgaelambda = advantage\n",
        "            advantages.append(advantage)\n",
        "        advantages.reverse()\n",
        "\n",
        "\n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. avg reward: {round(average_reward, 3)}\")\n",
        "        print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "        for epoch in range(1, number_of_epochs + 1):\n",
        "            num_batches = len(actions) // batch_size\n",
        "            shuffled_indices = tf.random.shuffle(tf.range(len(actions)))\n",
        "            for batch in range(num_batches):\n",
        "                if batch == num_batches: # last batch\n",
        "                    idx = shuffled_indices[batch*batch_size:]\n",
        "                else:\n",
        "                    idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                # deltas_batch = tf.squeeze(tf.gather(deltas, idx), axis=-1)\n",
        "                advantages_batch = tf.squeeze(tf.gather(advantages, idx), axis=-1)\n",
        "                actions_batch = tf.gather(actions, idx)\n",
        "                observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "                shared_critic.train_batch(advantages_batch, observations_batch)\n",
        "                # shared_critic.train_batch(deltas_batch, observations_batch)\n",
        "                shared_actor.train_batch(advantages_batch, observations_batch, actions_batch)\n",
        "                # shared_actor.train_batch(deltas_batch, observations_batch, actions_batch)\n",
        "            print(f\"Epoch {epoch} terminated.\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    shared_critic.save_weights(path_critic + \"shared_critic_exp_9.weights.h5\")\n",
        "    shared_actor.save_weights(path_actor + \"shared_actor_exp_9.weights.h5\")\n",
        "    print(\"User interrupted training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b741dbc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 2.00 (std: 6.00, se: 1.90); avg len: 400.00; : 100%|██████████| 10/10 [00:49<00:00,  4.93s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efcd9be2a8564f029f0d17fca81164c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "# trajs = ae.evaluate_human_model_pair(1)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "087c87dd",
      "metadata": {},
      "source": [
        "# Trial with ordered batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "38e434ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6fe2ee7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha_w = 1e-5\n",
        "alpha_t = 1e-6\n",
        "critic_optimizer = Adam(learning_rate=alpha_w)\n",
        "actor_optimizer = Adam(learning_rate=alpha_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "5365abaf",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=actor_optimizer\n",
        "    )\n",
        "\n",
        "shared_critic = ValueFunctionApproximator(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=critic_optimizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "2adea6ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_1 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        ")\n",
        "agent_2 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    critic=shared_critic,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "6b11bb8e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [  1] terminated at timestep 400. cumulative reward:   9. avg reward: 9.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  2] terminated at timestep 400. cumulative reward:   9. avg reward: 9.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  3] terminated at timestep 400. cumulative reward:   3. avg reward: 7.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  4] terminated at timestep 400. cumulative reward:  11. avg reward: 8.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  5] terminated at timestep 400. cumulative reward:   3. avg reward: 7.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  6] terminated at timestep 400. cumulative reward:  14. avg reward: 8.167\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  7] terminated at timestep 400. cumulative reward:   0. avg reward: 7.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  8] terminated at timestep 400. cumulative reward:  11. avg reward: 7.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [  9] terminated at timestep 400. cumulative reward:  14. avg reward: 8.222\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 10] terminated at timestep 400. cumulative reward:   3. avg reward: 7.7\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 11] terminated at timestep 400. cumulative reward:  17. avg reward: 8.545\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 12] terminated at timestep 400. cumulative reward:   8. avg reward: 8.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 13] terminated at timestep 400. cumulative reward:   3. avg reward: 8.077\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 14] terminated at timestep 400. cumulative reward:   9. avg reward: 8.143\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 15] terminated at timestep 400. cumulative reward:   9. avg reward: 8.2\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 16] terminated at timestep 400. cumulative reward:   8. avg reward: 8.188\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 17] terminated at timestep 400. cumulative reward:   3. avg reward: 7.882\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 18] terminated at timestep 400. cumulative reward:  11. avg reward: 8.056\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 19] terminated at timestep 400. cumulative reward:  11. avg reward: 8.211\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 20] terminated at timestep 400. cumulative reward:   0. avg reward: 7.8\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 21] terminated at timestep 400. cumulative reward:  17. avg reward: 8.238\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 22] terminated at timestep 400. cumulative reward:   8. avg reward: 8.227\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 23] terminated at timestep 400. cumulative reward:  20. avg reward: 8.739\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 24] terminated at timestep 400. cumulative reward:   3. avg reward: 8.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 25] terminated at timestep 400. cumulative reward:   3. avg reward: 8.28\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 26] terminated at timestep 400. cumulative reward:  20. avg reward: 8.731\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 27] terminated at timestep 400. cumulative reward:  11. avg reward: 8.815\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 28] terminated at timestep 400. cumulative reward:  11. avg reward: 8.893\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 29] terminated at timestep 400. cumulative reward:   6. avg reward: 8.793\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 30] terminated at timestep 400. cumulative reward:  12. avg reward: 8.9\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 31] terminated at timestep 400. cumulative reward:  14. avg reward: 9.065\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 32] terminated at timestep 400. cumulative reward:  14. avg reward: 9.219\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 33] terminated at timestep 400. cumulative reward:  16. avg reward: 9.424\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 34] terminated at timestep 400. cumulative reward:  14. avg reward: 9.559\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 35] terminated at timestep 400. cumulative reward:   8. avg reward: 9.514\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 36] terminated at timestep 400. cumulative reward:   3. avg reward: 9.333\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 37] terminated at timestep 400. cumulative reward:  11. avg reward: 9.378\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 38] terminated at timestep 400. cumulative reward:  14. avg reward: 9.5\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 39] terminated at timestep 400. cumulative reward:   8. avg reward: 9.462\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 40] terminated at timestep 400. cumulative reward:   0. avg reward: 9.225\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 41] terminated at timestep 400. cumulative reward:   3. avg reward: 9.073\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 42] terminated at timestep 400. cumulative reward:  17. avg reward: 9.262\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 43] terminated at timestep 400. cumulative reward:  19. avg reward: 9.488\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 44] terminated at timestep 400. cumulative reward:   3. avg reward: 9.341\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 45] terminated at timestep 400. cumulative reward:   3. avg reward: 9.2\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 46] terminated at timestep 400. cumulative reward:  11. avg reward: 9.239\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 47] terminated at timestep 400. cumulative reward:   6. avg reward: 9.17\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 48] terminated at timestep 400. cumulative reward:   3. avg reward: 9.042\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 49] terminated at timestep 400. cumulative reward:   3. avg reward: 8.918\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 50] terminated at timestep 400. cumulative reward:  11. avg reward: 8.96\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 51] terminated at timestep 400. cumulative reward:   3. avg reward: 8.843\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 52] terminated at timestep 400. cumulative reward:   3. avg reward: 8.731\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 53] terminated at timestep 400. cumulative reward:   3. avg reward: 8.623\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 54] terminated at timestep 400. cumulative reward:   6. avg reward: 8.574\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 55] terminated at timestep 400. cumulative reward:  19. avg reward: 8.764\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 56] terminated at timestep 400. cumulative reward:  14. avg reward: 8.857\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 57] terminated at timestep 400. cumulative reward:  14. avg reward: 8.947\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 58] terminated at timestep 400. cumulative reward:   0. avg reward: 8.793\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 59] terminated at timestep 400. cumulative reward:  17. avg reward: 8.932\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 60] terminated at timestep 400. cumulative reward:   8. avg reward: 8.917\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 61] terminated at timestep 400. cumulative reward:  11. avg reward: 8.951\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 62] terminated at timestep 400. cumulative reward:   6. avg reward: 8.903\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 63] terminated at timestep 400. cumulative reward:   3. avg reward: 8.81\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 64] terminated at timestep 400. cumulative reward:  14. avg reward: 8.891\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 65] terminated at timestep 400. cumulative reward:  14. avg reward: 8.969\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 66] terminated at timestep 400. cumulative reward:  17. avg reward: 9.091\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 67] terminated at timestep 400. cumulative reward:   8. avg reward: 9.075\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 68] terminated at timestep 400. cumulative reward:  39. avg reward: 9.515\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 69] terminated at timestep 400. cumulative reward:  11. avg reward: 9.536\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 70] terminated at timestep 400. cumulative reward:  20. avg reward: 9.686\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 71] terminated at timestep 400. cumulative reward:   0. avg reward: 9.549\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 72] terminated at timestep 400. cumulative reward:  27. avg reward: 9.792\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 73] terminated at timestep 400. cumulative reward:  14. avg reward: 9.849\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 74] terminated at timestep 400. cumulative reward:   6. avg reward: 9.797\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 75] terminated at timestep 400. cumulative reward:  11. avg reward: 9.813\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 76] terminated at timestep 400. cumulative reward:  22. avg reward: 9.974\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 77] terminated at timestep 400. cumulative reward:   3. avg reward: 9.883\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 78] terminated at timestep 400. cumulative reward:  14. avg reward: 9.936\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 79] terminated at timestep 400. cumulative reward:   6. avg reward: 9.886\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 80] terminated at timestep 400. cumulative reward:   3. avg reward: 9.8\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 81] terminated at timestep 400. cumulative reward:  11. avg reward: 9.815\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 82] terminated at timestep 400. cumulative reward:  11. avg reward: 9.829\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 83] terminated at timestep 400. cumulative reward:  11. avg reward: 9.843\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 84] terminated at timestep 400. cumulative reward:  11. avg reward: 9.857\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 85] terminated at timestep 400. cumulative reward:   3. avg reward: 9.776\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 86] terminated at timestep 400. cumulative reward:  11. avg reward: 9.791\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 87] terminated at timestep 400. cumulative reward:  11. avg reward: 9.805\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 88] terminated at timestep 400. cumulative reward:  16. avg reward: 9.875\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 89] terminated at timestep 400. cumulative reward:  11. avg reward: 9.888\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 90] terminated at timestep 400. cumulative reward:  19. avg reward: 9.989\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 91] terminated at timestep 400. cumulative reward:  14. avg reward: 10.033\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 92] terminated at timestep 400. cumulative reward:  33. avg reward: 10.283\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 93] terminated at timestep 400. cumulative reward:   8. avg reward: 10.258\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 94] terminated at timestep 400. cumulative reward:  19. avg reward: 10.351\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 95] terminated at timestep 400. cumulative reward:   6. avg reward: 10.305\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 96] terminated at timestep 400. cumulative reward:   3. avg reward: 10.229\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 97] terminated at timestep 400. cumulative reward:   0. avg reward: 10.124\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 98] terminated at timestep 400. cumulative reward:   3. avg reward: 10.051\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [ 99] terminated at timestep 400. cumulative reward:  14. avg reward: 10.091\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [100] terminated at timestep 400. cumulative reward:   3. avg reward: 10.02\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [101] terminated at timestep 400. cumulative reward:  11. avg reward: 10.03\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [102] terminated at timestep 400. cumulative reward:   3. avg reward: 9.961\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [103] terminated at timestep 400. cumulative reward:   3. avg reward: 9.893\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [104] terminated at timestep 400. cumulative reward:   6. avg reward: 9.856\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [105] terminated at timestep 400. cumulative reward:  14. avg reward: 9.895\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [106] terminated at timestep 400. cumulative reward:   6. avg reward: 9.858\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [107] terminated at timestep 400. cumulative reward:  11. avg reward: 9.869\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [108] terminated at timestep 400. cumulative reward:   3. avg reward: 9.806\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [109] terminated at timestep 400. cumulative reward:   8. avg reward: 9.789\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [110] terminated at timestep 400. cumulative reward:  25. avg reward: 9.927\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [111] terminated at timestep 400. cumulative reward:   3. avg reward: 9.865\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [112] terminated at timestep 400. cumulative reward:  11. avg reward: 9.875\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [113] terminated at timestep 400. cumulative reward:   6. avg reward: 9.841\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [114] terminated at timestep 400. cumulative reward:   6. avg reward: 9.807\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [115] terminated at timestep 400. cumulative reward:   8. avg reward: 9.791\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [116] terminated at timestep 400. cumulative reward:  11. avg reward: 9.802\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [117] terminated at timestep 400. cumulative reward:  14. avg reward: 9.838\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [118] terminated at timestep 400. cumulative reward:   3. avg reward: 9.78\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [119] terminated at timestep 400. cumulative reward:   3. avg reward: 9.723\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [120] terminated at timestep 400. cumulative reward:  14. avg reward: 9.758\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [121] terminated at timestep 400. cumulative reward:  14. avg reward: 9.793\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [122] terminated at timestep 400. cumulative reward:  11. avg reward: 9.803\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [123] terminated at timestep 400. cumulative reward:  11. avg reward: 9.813\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [124] terminated at timestep 400. cumulative reward:  17. avg reward: 9.871\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [125] terminated at timestep 400. cumulative reward:   3. avg reward: 9.816\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [126] terminated at timestep 400. cumulative reward:  14. avg reward: 9.849\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [127] terminated at timestep 400. cumulative reward:  11. avg reward: 9.858\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [128] terminated at timestep 400. cumulative reward:  14. avg reward: 9.891\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [129] terminated at timestep 400. cumulative reward:   6. avg reward: 9.86\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [130] terminated at timestep 400. cumulative reward:  11. avg reward: 9.869\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [131] terminated at timestep 400. cumulative reward:   3. avg reward: 9.817\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [132] terminated at timestep 400. cumulative reward:   6. avg reward: 9.788\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [133] terminated at timestep 400. cumulative reward:   3. avg reward: 9.737\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [134] terminated at timestep 400. cumulative reward:  11. avg reward: 9.746\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [135] terminated at timestep 400. cumulative reward:  17. avg reward: 9.8\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [136] terminated at timestep 400. cumulative reward:   3. avg reward: 9.75\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [137] terminated at timestep 400. cumulative reward:   6. avg reward: 9.723\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [138] terminated at timestep 400. cumulative reward:   8. avg reward: 9.71\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [139] terminated at timestep 400. cumulative reward:   3. avg reward: 9.662\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [140] terminated at timestep 400. cumulative reward:   3. avg reward: 9.614\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [141] terminated at timestep 400. cumulative reward:   8. avg reward: 9.603\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [142] terminated at timestep 400. cumulative reward:  11. avg reward: 9.613\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [143] terminated at timestep 400. cumulative reward:   3. avg reward: 9.566\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [144] terminated at timestep 400. cumulative reward:  22. avg reward: 9.653\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [145] terminated at timestep 400. cumulative reward:   0. avg reward: 9.586\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [146] terminated at timestep 400. cumulative reward:  14. avg reward: 9.616\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [147] terminated at timestep 400. cumulative reward:   3. avg reward: 9.571\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [148] terminated at timestep 400. cumulative reward:  34. avg reward: 9.736\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [149] terminated at timestep 400. cumulative reward:   6. avg reward: 9.711\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [150] terminated at timestep 400. cumulative reward:  19. avg reward: 9.773\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [151] terminated at timestep 400. cumulative reward:   3. avg reward: 9.728\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [152] terminated at timestep 400. cumulative reward:  36. avg reward: 9.901\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [153] terminated at timestep 400. cumulative reward:   3. avg reward: 9.856\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [154] terminated at timestep 400. cumulative reward:   6. avg reward: 9.831\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [155] terminated at timestep 400. cumulative reward:   3. avg reward: 9.787\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [156] terminated at timestep 400. cumulative reward:   6. avg reward: 9.763\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [157] terminated at timestep 400. cumulative reward:   8. avg reward: 9.752\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [158] terminated at timestep 400. cumulative reward:  11. avg reward: 9.759\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [159] terminated at timestep 400. cumulative reward:  11. avg reward: 9.767\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [160] terminated at timestep 400. cumulative reward:  22. avg reward: 9.844\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [161] terminated at timestep 400. cumulative reward:  11. avg reward: 9.851\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [162] terminated at timestep 400. cumulative reward:  14. avg reward: 9.877\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [163] terminated at timestep 400. cumulative reward:   6. avg reward: 9.853\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [164] terminated at timestep 400. cumulative reward:   3. avg reward: 9.811\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [165] terminated at timestep 400. cumulative reward:  14. avg reward: 9.836\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [166] terminated at timestep 400. cumulative reward:   3. avg reward: 9.795\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [167] terminated at timestep 400. cumulative reward:  11. avg reward: 9.802\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [168] terminated at timestep 400. cumulative reward:   3. avg reward: 9.762\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [169] terminated at timestep 400. cumulative reward:  11. avg reward: 9.769\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [170] terminated at timestep 400. cumulative reward:  11. avg reward: 9.776\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [171] terminated at timestep 400. cumulative reward:   3. avg reward: 9.737\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [172] terminated at timestep 400. cumulative reward:  14. avg reward: 9.762\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [173] terminated at timestep 400. cumulative reward:   3. avg reward: 9.723\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [174] terminated at timestep 400. cumulative reward:  19. avg reward: 9.776\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [175] terminated at timestep 400. cumulative reward:  19. avg reward: 9.829\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [176] terminated at timestep 400. cumulative reward:   6. avg reward: 9.807\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [177] terminated at timestep 400. cumulative reward:  14. avg reward: 9.831\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [178] terminated at timestep 400. cumulative reward:   6. avg reward: 9.809\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [179] terminated at timestep 400. cumulative reward:  11. avg reward: 9.816\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [180] terminated at timestep 400. cumulative reward:  14. avg reward: 9.839\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [181] terminated at timestep 400. cumulative reward:   3. avg reward: 9.801\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [182] terminated at timestep 400. cumulative reward:   3. avg reward: 9.764\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [183] terminated at timestep 400. cumulative reward:  14. avg reward: 9.787\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [184] terminated at timestep 400. cumulative reward:  17. avg reward: 9.826\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [185] terminated at timestep 400. cumulative reward:  14. avg reward: 9.849\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [186] terminated at timestep 400. cumulative reward:   8. avg reward: 9.839\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [187] terminated at timestep 400. cumulative reward:   3. avg reward: 9.802\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [188] terminated at timestep 400. cumulative reward:   8. avg reward: 9.793\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [189] terminated at timestep 400. cumulative reward:  17. avg reward: 9.831\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [190] terminated at timestep 400. cumulative reward:   3. avg reward: 9.795\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [191] terminated at timestep 400. cumulative reward:  11. avg reward: 9.801\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [192] terminated at timestep 400. cumulative reward:   3. avg reward: 9.766\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [193] terminated at timestep 400. cumulative reward:  14. avg reward: 9.788\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [194] terminated at timestep 400. cumulative reward:  14. avg reward: 9.809\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [195] terminated at timestep 400. cumulative reward:  14. avg reward: 9.831\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [196] terminated at timestep 400. cumulative reward:  11. avg reward: 9.837\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [197] terminated at timestep 400. cumulative reward:   3. avg reward: 9.802\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [198] terminated at timestep 400. cumulative reward:  19. avg reward: 9.848\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [199] terminated at timestep 400. cumulative reward:  11. avg reward: 9.854\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [200] terminated at timestep 400. cumulative reward:   8. avg reward: 9.845\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [201] terminated at timestep 400. cumulative reward:  11. avg reward: 9.851\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [202] terminated at timestep 400. cumulative reward:   3. avg reward: 9.817\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [203] terminated at timestep 400. cumulative reward:   6. avg reward: 9.798\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [204] terminated at timestep 400. cumulative reward:  17. avg reward: 9.833\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [205] terminated at timestep 400. cumulative reward:  22. avg reward: 9.893\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [206] terminated at timestep 400. cumulative reward:  11. avg reward: 9.898\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [207] terminated at timestep 400. cumulative reward:  14. avg reward: 9.918\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [208] terminated at timestep 400. cumulative reward:   6. avg reward: 9.899\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [209] terminated at timestep 400. cumulative reward:  19. avg reward: 9.943\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [210] terminated at timestep 400. cumulative reward:  16. avg reward: 9.971\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [211] terminated at timestep 400. cumulative reward:   6. avg reward: 9.953\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [212] terminated at timestep 400. cumulative reward:   6. avg reward: 9.934\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [213] terminated at timestep 400. cumulative reward:   6. avg reward: 9.915\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [214] terminated at timestep 400. cumulative reward:   3. avg reward: 9.883\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [215] terminated at timestep 400. cumulative reward:   3. avg reward: 9.851\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [216] terminated at timestep 400. cumulative reward:  11. avg reward: 9.856\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [217] terminated at timestep 400. cumulative reward:  22. avg reward: 9.912\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [218] terminated at timestep 400. cumulative reward:   6. avg reward: 9.894\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [219] terminated at timestep 400. cumulative reward:  14. avg reward: 9.913\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [220] terminated at timestep 400. cumulative reward:   6. avg reward: 9.895\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [221] terminated at timestep 400. cumulative reward:   3. avg reward: 9.864\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [222] terminated at timestep 400. cumulative reward:   3. avg reward: 9.833\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [223] terminated at timestep 400. cumulative reward:   6. avg reward: 9.816\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [224] terminated at timestep 400. cumulative reward:   3. avg reward: 9.786\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [225] terminated at timestep 400. cumulative reward:   3. avg reward: 9.756\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [226] terminated at timestep 400. cumulative reward:   3. avg reward: 9.726\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [227] terminated at timestep 400. cumulative reward:  14. avg reward: 9.744\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [228] terminated at timestep 400. cumulative reward:   6. avg reward: 9.728\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [229] terminated at timestep 400. cumulative reward:   8. avg reward: 9.721\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [230] terminated at timestep 400. cumulative reward:  11. avg reward: 9.726\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [231] terminated at timestep 400. cumulative reward:   8. avg reward: 9.719\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [232] terminated at timestep 400. cumulative reward:   3. avg reward: 9.69\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [233] terminated at timestep 400. cumulative reward:  11. avg reward: 9.695\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [234] terminated at timestep 400. cumulative reward:  11. avg reward: 9.701\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [235] terminated at timestep 400. cumulative reward:   6. avg reward: 9.685\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [236] terminated at timestep 400. cumulative reward:   8. avg reward: 9.678\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [237] terminated at timestep 400. cumulative reward:   3. avg reward: 9.65\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [238] terminated at timestep 400. cumulative reward:   3. avg reward: 9.622\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [239] terminated at timestep 400. cumulative reward:  11. avg reward: 9.628\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [240] terminated at timestep 400. cumulative reward:   8. avg reward: 9.621\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [241] terminated at timestep 400. cumulative reward:   3. avg reward: 9.593\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [242] terminated at timestep 400. cumulative reward:   8. avg reward: 9.587\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [243] terminated at timestep 400. cumulative reward:   3. avg reward: 9.56\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [244] terminated at timestep 400. cumulative reward:   3. avg reward: 9.533\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [245] terminated at timestep 400. cumulative reward:   3. avg reward: 9.506\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [246] terminated at timestep 400. cumulative reward:  16. avg reward: 9.533\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [247] terminated at timestep 400. cumulative reward:   3. avg reward: 9.506\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [248] terminated at timestep 400. cumulative reward:   3. avg reward: 9.48\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [249] terminated at timestep 400. cumulative reward:  11. avg reward: 9.486\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [250] terminated at timestep 400. cumulative reward:  11. avg reward: 9.492\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [251] terminated at timestep 400. cumulative reward:  11. avg reward: 9.498\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [252] terminated at timestep 400. cumulative reward:  14. avg reward: 9.516\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [253] terminated at timestep 400. cumulative reward:   0. avg reward: 9.478\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [254] terminated at timestep 400. cumulative reward:   3. avg reward: 9.453\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [255] terminated at timestep 400. cumulative reward:   6. avg reward: 9.439\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [256] terminated at timestep 400. cumulative reward:   3. avg reward: 9.414\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [257] terminated at timestep 400. cumulative reward:   3. avg reward: 9.389\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [258] terminated at timestep 400. cumulative reward:  11. avg reward: 9.395\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [259] terminated at timestep 400. cumulative reward:   3. avg reward: 9.371\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [260] terminated at timestep 400. cumulative reward:   3. avg reward: 9.346\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [261] terminated at timestep 400. cumulative reward:   6. avg reward: 9.333\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [262] terminated at timestep 400. cumulative reward:   3. avg reward: 9.309\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [263] terminated at timestep 400. cumulative reward:   6. avg reward: 9.297\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [264] terminated at timestep 400. cumulative reward:   6. avg reward: 9.284\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [265] terminated at timestep 400. cumulative reward:   3. avg reward: 9.26\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [266] terminated at timestep 400. cumulative reward:  16. avg reward: 9.286\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [267] terminated at timestep 400. cumulative reward:   3. avg reward: 9.262\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [268] terminated at timestep 400. cumulative reward:   0. avg reward: 9.228\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [269] terminated at timestep 400. cumulative reward:   8. avg reward: 9.223\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [270] terminated at timestep 400. cumulative reward:   8. avg reward: 9.219\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [271] terminated at timestep 400. cumulative reward:   6. avg reward: 9.207\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [272] terminated at timestep 400. cumulative reward:  16. avg reward: 9.232\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [273] terminated at timestep 400. cumulative reward:   6. avg reward: 9.22\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [274] terminated at timestep 400. cumulative reward:   6. avg reward: 9.208\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [275] terminated at timestep 400. cumulative reward:   3. avg reward: 9.185\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [276] terminated at timestep 400. cumulative reward:   3. avg reward: 9.163\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [277] terminated at timestep 400. cumulative reward:   3. avg reward: 9.141\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [278] terminated at timestep 400. cumulative reward:   3. avg reward: 9.119\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [279] terminated at timestep 400. cumulative reward:   3. avg reward: 9.097\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [280] terminated at timestep 400. cumulative reward:   3. avg reward: 9.075\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [281] terminated at timestep 400. cumulative reward:   3. avg reward: 9.053\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [282] terminated at timestep 400. cumulative reward:   3. avg reward: 9.032\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [283] terminated at timestep 400. cumulative reward:   0. avg reward: 9.0\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [284] terminated at timestep 400. cumulative reward:  11. avg reward: 9.007\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [285] terminated at timestep 400. cumulative reward:   3. avg reward: 8.986\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [286] terminated at timestep 400. cumulative reward:   3. avg reward: 8.965\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [287] terminated at timestep 400. cumulative reward:   3. avg reward: 8.944\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [288] terminated at timestep 400. cumulative reward:   3. avg reward: 8.924\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [289] terminated at timestep 400. cumulative reward:   3. avg reward: 8.903\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [290] terminated at timestep 400. cumulative reward:   6. avg reward: 8.893\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [291] terminated at timestep 400. cumulative reward:   3. avg reward: 8.873\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [292] terminated at timestep 400. cumulative reward:   6. avg reward: 8.863\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [293] terminated at timestep 400. cumulative reward:   3. avg reward: 8.843\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [294] terminated at timestep 400. cumulative reward:   3. avg reward: 8.823\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [295] terminated at timestep 400. cumulative reward:  11. avg reward: 8.831\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [296] terminated at timestep 400. cumulative reward:   3. avg reward: 8.811\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [297] terminated at timestep 400. cumulative reward:   3. avg reward: 8.791\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [298] terminated at timestep 400. cumulative reward:  11. avg reward: 8.799\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [299] terminated at timestep 400. cumulative reward:   0. avg reward: 8.769\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n",
            "Episode [300] terminated at timestep 400. cumulative reward:   3. avg reward: 8.75\n",
            "Performing stocastic gradient descent with 4 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Epoch 3 terminated.\n",
            "Epoch 4 terminated.\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 300\n",
        "number_of_epochs = 4\n",
        "batch_size = 20\n",
        "average_reward = 0\n",
        "gamma = 0.95\n",
        "\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        actions = []\n",
        "        deltas = []\n",
        "        observations = []\n",
        "\n",
        "        t = 0\n",
        "        obs = env.reset()\n",
        "        \n",
        "        done = False\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        if (episode) % 50 == 0:\n",
        "            shared_critic.save_weights(path_critic + \"shared_critic_exp_4.weights.h5\")\n",
        "            shared_actor.save_weights(path_actor + \"shared_actor_exp_4.weights.h5\")\n",
        "\n",
        "        while not done:\n",
        "            action1 = agent_1.action(obs['both_agent_obs'])\n",
        "            action2 = agent_2.action(obs['both_agent_obs'])\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "\n",
        "            if obs['other_agent_env_idx'] == 0:\n",
        "                my_obs = (obs['both_agent_obs'][1],obs['both_agent_obs'][0])\n",
        "                obs['both_agent_obs'] = my_obs # BRO I WAS TOO LAZY TO OVERRIDE OBS. DON'T FORGET IT\n",
        "                action = (player_2_action, player_1_action)\n",
        "            else:\n",
        "                action = (player_1_action, player_2_action)\n",
        "\n",
        "            actions.append(action)\n",
        "            observations.append(obs['both_agent_obs'])\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            if shaped_reward != 0:\n",
        "                shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "                shaped_reward_factor *= discount_rate\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            if done:\n",
        "                delta = total_reward - shared_critic.call(obs['both_agent_obs'])\n",
        "            else:\n",
        "                delta = total_reward + gamma*shared_critic.call(new_obs['both_agent_obs']) - shared_critic.call(obs['both_agent_obs'])\n",
        "\n",
        "            deltas.append(delta)\n",
        "            \n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            # think about training the critic by itself for a while\n",
        "            t += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. avg reward: {round(average_reward, 3)}\")\n",
        "        print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "        for epoch in range(1, number_of_epochs + 1):\n",
        "            num_batches = len(actions) // batch_size\n",
        "            shuffled_indices = tf.random.shuffle(tf.range(len(actions)))\n",
        "            for batch in range(num_batches):\n",
        "                if batch == num_batches: # last batch\n",
        "                    idx = shuffled_indices[batch*batch_size:]\n",
        "                else:\n",
        "                    idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                deltas_batch = tf.squeeze(tf.gather(deltas, idx), axis=-1)\n",
        "                actions_batch = tf.gather(actions, idx)\n",
        "                observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "                shared_critic.train_batch(deltas_batch, observations_batch)\n",
        "                shared_actor.train_batch(deltas_batch, observations_batch, actions_batch)\n",
        "            print(f\"Epoch {epoch} terminated.\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    shared_critic.save_weights(path_critic + \"shared_critic_exp_4.weights.h5\")\n",
        "    shared_actor.save_weights(path_actor + \"shared_actor_exp_4.weights.h5\")\n",
        "    print(\"User interrupted training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0043e144",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "# trajs = ae.evaluate_human_model_pair(1)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ffa52cf",
      "metadata": {},
      "source": [
        "# Trial with PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "476fee77",
      "metadata": {},
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "ea8436fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "alpha_w = 1e-5\n",
        "alpha_t = 1e-6\n",
        "critic_optimizer = Adam(learning_rate=alpha_w)\n",
        "actor_optimizer = Adam(learning_rate=alpha_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "34ee2a09",
      "metadata": {},
      "outputs": [],
      "source": [
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=actor_optimizer\n",
        "    )\n",
        "\n",
        "shared_old_policy = Policy(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=None\n",
        "    )\n",
        "\n",
        "shared_critic = ValueFunctionApproximator(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=critic_optimizer\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "2f8b3c83",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_1 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    old_policy=shared_old_policy,\n",
        "    critic=shared_critic,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        ")\n",
        "agent_2 = MyAgent(\n",
        "    actor=shared_actor,\n",
        "    old_policy=shared_old_policy,\n",
        "    critic=shared_critic,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "ffec9eae",
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_critic.load_weights(path_critic + \"shared_critic_exp_8.weights.h5\")\n",
        "shared_actor.load_weights(path_actor + \"shared_actor_exp_8.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "936877d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_1.update_old_policy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "4ee57f02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [  1] terminated at timestep 400. cumulative reward:  14. avg reward: 14.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  2] terminated at timestep 400. cumulative reward:  30. avg reward: 22.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  3] terminated at timestep 400. cumulative reward:  39. avg reward: 27.667\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  4] terminated at timestep 400. cumulative reward:   9. avg reward: 23.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  5] terminated at timestep 400. cumulative reward:  62. avg reward: 30.8\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  6] terminated at timestep 400. cumulative reward:  25. avg reward: 29.833\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  7] terminated at timestep 400. cumulative reward:  40. avg reward: 31.286\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  8] terminated at timestep 400. cumulative reward:  12. avg reward: 28.875\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [  9] terminated at timestep 400. cumulative reward:  33. avg reward: 29.333\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 10] terminated at timestep 400. cumulative reward:  30. avg reward: 29.4\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 11] terminated at timestep 400. cumulative reward:  22. avg reward: 28.727\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 12] terminated at timestep 400. cumulative reward:  45. avg reward: 30.083\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 13] terminated at timestep 400. cumulative reward:   9. avg reward: 28.462\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 14] terminated at timestep 400. cumulative reward:  22. avg reward: 28.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 15] terminated at timestep 400. cumulative reward:  22. avg reward: 27.6\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 16] terminated at timestep 400. cumulative reward:  42. avg reward: 28.5\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 17] terminated at timestep 400. cumulative reward:   9. avg reward: 27.353\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 18] terminated at timestep 400. cumulative reward:  20. avg reward: 26.944\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 19] terminated at timestep 400. cumulative reward:  12. avg reward: 26.158\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 20] terminated at timestep 400. cumulative reward:   9. avg reward: 25.3\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 21] terminated at timestep 400. cumulative reward:  51. avg reward: 26.524\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 22] terminated at timestep 400. cumulative reward:   9. avg reward: 25.727\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 23] terminated at timestep 400. cumulative reward:  12. avg reward: 25.13\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 24] terminated at timestep 400. cumulative reward:  11. avg reward: 24.542\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 25] terminated at timestep 400. cumulative reward:  39. avg reward: 25.12\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 26] terminated at timestep 400. cumulative reward:  12. avg reward: 24.615\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 27] terminated at timestep 400. cumulative reward:  20. avg reward: 24.444\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 28] terminated at timestep 400. cumulative reward:  51. avg reward: 25.393\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 29] terminated at timestep 400. cumulative reward:  28. avg reward: 25.483\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 30] terminated at timestep 400. cumulative reward:   9. avg reward: 24.933\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 31] terminated at timestep 400. cumulative reward:  28. avg reward: 25.032\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 32] terminated at timestep 400. cumulative reward:  36. avg reward: 25.375\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 33] terminated at timestep 400. cumulative reward:  45. avg reward: 25.97\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 34] terminated at timestep 400. cumulative reward:  17. avg reward: 25.706\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 35] terminated at timestep 400. cumulative reward:  12. avg reward: 25.314\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 36] terminated at timestep 400. cumulative reward:   9. avg reward: 24.861\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 37] terminated at timestep 400. cumulative reward:   9. avg reward: 24.432\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 38] terminated at timestep 400. cumulative reward:  17. avg reward: 24.237\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 39] terminated at timestep 400. cumulative reward:  56. avg reward: 25.051\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 40] terminated at timestep 400. cumulative reward:   9. avg reward: 24.65\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 41] terminated at timestep 400. cumulative reward:  25. avg reward: 24.659\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 42] terminated at timestep 400. cumulative reward:   9. avg reward: 24.286\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 43] terminated at timestep 400. cumulative reward:  20. avg reward: 24.186\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 44] terminated at timestep 400. cumulative reward:  11. avg reward: 23.886\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 45] terminated at timestep 400. cumulative reward:  12. avg reward: 23.622\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 46] terminated at timestep 400. cumulative reward:  17. avg reward: 23.478\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 47] terminated at timestep 400. cumulative reward:  12. avg reward: 23.234\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 48] terminated at timestep 400. cumulative reward:  23. avg reward: 23.229\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 49] terminated at timestep 400. cumulative reward:  22. avg reward: 23.204\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 50] terminated at timestep 400. cumulative reward:  31. avg reward: 23.36\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 51] terminated at timestep 400. cumulative reward:   9. avg reward: 23.078\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 52] terminated at timestep 400. cumulative reward:  28. avg reward: 23.173\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 53] terminated at timestep 400. cumulative reward:  27. avg reward: 23.245\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 54] terminated at timestep 400. cumulative reward:   9. avg reward: 22.981\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 55] terminated at timestep 400. cumulative reward:  23. avg reward: 22.982\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 56] terminated at timestep 400. cumulative reward:  42. avg reward: 23.321\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 57] terminated at timestep 400. cumulative reward:  19. avg reward: 23.246\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 58] terminated at timestep 400. cumulative reward:   9. avg reward: 23.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 59] terminated at timestep 400. cumulative reward:  28. avg reward: 23.085\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 60] terminated at timestep 400. cumulative reward:  36. avg reward: 23.3\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 61] terminated at timestep 400. cumulative reward:  28. avg reward: 23.377\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 62] terminated at timestep 400. cumulative reward:  12. avg reward: 23.194\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 63] terminated at timestep 400. cumulative reward:  22. avg reward: 23.175\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 64] terminated at timestep 400. cumulative reward:  30. avg reward: 23.281\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 65] terminated at timestep 400. cumulative reward:  17. avg reward: 23.185\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 66] terminated at timestep 400. cumulative reward:  14. avg reward: 23.045\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 67] terminated at timestep 400. cumulative reward:  26. avg reward: 23.09\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 68] terminated at timestep 400. cumulative reward:  30. avg reward: 23.191\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 69] terminated at timestep 400. cumulative reward:  28. avg reward: 23.261\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 70] terminated at timestep 400. cumulative reward:  39. avg reward: 23.486\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 71] terminated at timestep 400. cumulative reward:  25. avg reward: 23.507\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 72] terminated at timestep 400. cumulative reward:  36. avg reward: 23.681\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 73] terminated at timestep 400. cumulative reward:  11. avg reward: 23.507\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 74] terminated at timestep 400. cumulative reward:  27. avg reward: 23.554\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 75] terminated at timestep 400. cumulative reward:  17. avg reward: 23.467\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 76] terminated at timestep 400. cumulative reward:  30. avg reward: 23.553\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 77] terminated at timestep 400. cumulative reward:  33. avg reward: 23.675\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 78] terminated at timestep 400. cumulative reward:  46. avg reward: 23.962\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 79] terminated at timestep 400. cumulative reward:  22. avg reward: 23.937\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 80] terminated at timestep 400. cumulative reward:  25. avg reward: 23.95\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 81] terminated at timestep 400. cumulative reward:  28. avg reward: 24.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 82] terminated at timestep 400. cumulative reward:  23. avg reward: 23.988\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 83] terminated at timestep 400. cumulative reward:  34. avg reward: 24.108\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 84] terminated at timestep 400. cumulative reward:  36. avg reward: 24.25\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 85] terminated at timestep 400. cumulative reward:  11. avg reward: 24.094\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 86] terminated at timestep 400. cumulative reward:  22. avg reward: 24.07\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 87] terminated at timestep 400. cumulative reward:  20. avg reward: 24.023\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 88] terminated at timestep 400. cumulative reward:   9. avg reward: 23.852\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 89] terminated at timestep 400. cumulative reward:  37. avg reward: 24.0\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 90] terminated at timestep 400. cumulative reward:  25. avg reward: 24.011\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 91] terminated at timestep 400. cumulative reward:  28. avg reward: 24.055\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 92] terminated at timestep 400. cumulative reward:  11. avg reward: 23.913\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 93] terminated at timestep 400. cumulative reward:  31. avg reward: 23.989\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 94] terminated at timestep 400. cumulative reward:  17. avg reward: 23.915\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 95] terminated at timestep 400. cumulative reward:  37. avg reward: 24.053\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 96] terminated at timestep 400. cumulative reward:  25. avg reward: 24.062\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 97] terminated at timestep 400. cumulative reward:  17. avg reward: 23.99\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 98] terminated at timestep 400. cumulative reward:  46. avg reward: 24.214\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [ 99] terminated at timestep 400. cumulative reward:  12. avg reward: 24.091\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [100] terminated at timestep 400. cumulative reward:  34. avg reward: 24.19\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [101] terminated at timestep 400. cumulative reward:  48. avg reward: 24.426\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [102] terminated at timestep 400. cumulative reward:  39. avg reward: 24.569\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [103] terminated at timestep 400. cumulative reward:  39. avg reward: 24.709\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [104] terminated at timestep 400. cumulative reward:  25. avg reward: 24.712\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [105] terminated at timestep 400. cumulative reward:  16. avg reward: 24.629\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [106] terminated at timestep 400. cumulative reward:   9. avg reward: 24.481\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [107] terminated at timestep 400. cumulative reward:  59. avg reward: 24.804\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [108] terminated at timestep 400. cumulative reward:  28. avg reward: 24.833\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [109] terminated at timestep 400. cumulative reward:  35. avg reward: 24.927\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [110] terminated at timestep 400. cumulative reward:   9. avg reward: 24.782\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [111] terminated at timestep 400. cumulative reward:  51. avg reward: 25.018\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [112] terminated at timestep 400. cumulative reward:  20. avg reward: 24.973\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [113] terminated at timestep 400. cumulative reward:  12. avg reward: 24.858\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [114] terminated at timestep 400. cumulative reward:  34. avg reward: 24.939\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [115] terminated at timestep 400. cumulative reward:  14. avg reward: 24.843\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [116] terminated at timestep 400. cumulative reward:  25. avg reward: 24.845\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [117] terminated at timestep 400. cumulative reward:  40. avg reward: 24.974\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [118] terminated at timestep 400. cumulative reward:  48. avg reward: 25.169\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [119] terminated at timestep 400. cumulative reward:  77. avg reward: 25.605\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [120] terminated at timestep 400. cumulative reward:  44. avg reward: 25.758\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [121] terminated at timestep 400. cumulative reward:  22. avg reward: 25.727\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [122] terminated at timestep 400. cumulative reward:  42. avg reward: 25.861\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [123] terminated at timestep 400. cumulative reward:  25. avg reward: 25.854\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [124] terminated at timestep 400. cumulative reward:  28. avg reward: 25.871\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [125] terminated at timestep 400. cumulative reward:  36. avg reward: 25.952\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [126] terminated at timestep 400. cumulative reward:  11. avg reward: 25.833\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [127] terminated at timestep 400. cumulative reward:  39. avg reward: 25.937\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [128] terminated at timestep 400. cumulative reward:  23. avg reward: 25.914\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [129] terminated at timestep 400. cumulative reward:  20. avg reward: 25.868\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [130] terminated at timestep 400. cumulative reward:  36. avg reward: 25.946\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [131] terminated at timestep 400. cumulative reward:  14. avg reward: 25.855\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [132] terminated at timestep 400. cumulative reward:  20. avg reward: 25.811\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [133] terminated at timestep 400. cumulative reward:  46. avg reward: 25.962\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [134] terminated at timestep 400. cumulative reward:  12. avg reward: 25.858\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [135] terminated at timestep 400. cumulative reward:  42. avg reward: 25.978\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [136] terminated at timestep 400. cumulative reward:  48. avg reward: 26.14\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [137] terminated at timestep 400. cumulative reward:  31. avg reward: 26.175\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [138] terminated at timestep 400. cumulative reward:   9. avg reward: 26.051\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [139] terminated at timestep 400. cumulative reward:  43. avg reward: 26.173\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [140] terminated at timestep 400. cumulative reward:  34. avg reward: 26.229\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [141] terminated at timestep 400. cumulative reward:   9. avg reward: 26.106\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [142] terminated at timestep 400. cumulative reward:  50. avg reward: 26.275\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [143] terminated at timestep 400. cumulative reward:  20. avg reward: 26.231\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [144] terminated at timestep 400. cumulative reward:  33. avg reward: 26.278\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [145] terminated at timestep 400. cumulative reward:  20. avg reward: 26.234\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [146] terminated at timestep 400. cumulative reward:  11. avg reward: 26.13\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [147] terminated at timestep 400. cumulative reward:  44. avg reward: 26.252\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [148] terminated at timestep 400. cumulative reward:  20. avg reward: 26.209\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [149] terminated at timestep 400. cumulative reward:  19. avg reward: 26.161\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [150] terminated at timestep 400. cumulative reward:  12. avg reward: 26.067\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [151] terminated at timestep 400. cumulative reward:  19. avg reward: 26.02\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [152] terminated at timestep 400. cumulative reward:   9. avg reward: 25.908\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [153] terminated at timestep 400. cumulative reward:   9. avg reward: 25.797\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [154] terminated at timestep 400. cumulative reward:  37. avg reward: 25.87\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [155] terminated at timestep 400. cumulative reward:   9. avg reward: 25.761\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [156] terminated at timestep 400. cumulative reward:  36. avg reward: 25.827\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [157] terminated at timestep 400. cumulative reward:  12. avg reward: 25.739\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [158] terminated at timestep 400. cumulative reward:  28. avg reward: 25.753\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [159] terminated at timestep 400. cumulative reward:  20. avg reward: 25.717\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [160] terminated at timestep 400. cumulative reward:  54. avg reward: 25.894\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [161] terminated at timestep 400. cumulative reward:  48. avg reward: 26.031\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [162] terminated at timestep 400. cumulative reward:  33. avg reward: 26.074\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [163] terminated at timestep 400. cumulative reward:  20. avg reward: 26.037\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [164] terminated at timestep 400. cumulative reward:  46. avg reward: 26.159\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [165] terminated at timestep 400. cumulative reward:  28. avg reward: 26.17\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [166] terminated at timestep 400. cumulative reward:  62. avg reward: 26.386\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [167] terminated at timestep 400. cumulative reward:  30. avg reward: 26.407\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [168] terminated at timestep 400. cumulative reward:  22. avg reward: 26.381\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [169] terminated at timestep 400. cumulative reward:  34. avg reward: 26.426\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [170] terminated at timestep 400. cumulative reward:  12. avg reward: 26.341\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [171] terminated at timestep 400. cumulative reward:  20. avg reward: 26.304\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [172] terminated at timestep 400. cumulative reward:  56. avg reward: 26.477\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [173] terminated at timestep 400. cumulative reward:  43. avg reward: 26.572\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [174] terminated at timestep 400. cumulative reward:  25. avg reward: 26.563\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [175] terminated at timestep 400. cumulative reward:  22. avg reward: 26.537\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [176] terminated at timestep 400. cumulative reward:  34. avg reward: 26.58\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [177] terminated at timestep 400. cumulative reward:  25. avg reward: 26.571\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [178] terminated at timestep 400. cumulative reward:  28. avg reward: 26.579\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [179] terminated at timestep 400. cumulative reward:  20. avg reward: 26.542\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [180] terminated at timestep 400. cumulative reward:   6. avg reward: 26.428\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [181] terminated at timestep 400. cumulative reward:  33. avg reward: 26.464\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [182] terminated at timestep 400. cumulative reward:  19. avg reward: 26.423\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [183] terminated at timestep 400. cumulative reward:  33. avg reward: 26.459\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [184] terminated at timestep 400. cumulative reward:  71. avg reward: 26.701\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [185] terminated at timestep 400. cumulative reward:   9. avg reward: 26.605\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [186] terminated at timestep 400. cumulative reward:  28. avg reward: 26.613\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [187] terminated at timestep 400. cumulative reward:  22. avg reward: 26.588\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [188] terminated at timestep 400. cumulative reward:  19. avg reward: 26.548\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [189] terminated at timestep 400. cumulative reward:  48. avg reward: 26.661\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [190] terminated at timestep 400. cumulative reward:  17. avg reward: 26.611\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [191] terminated at timestep 400. cumulative reward:  31. avg reward: 26.634\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [192] terminated at timestep 400. cumulative reward:  53. avg reward: 26.771\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [193] terminated at timestep 400. cumulative reward:  17. avg reward: 26.72\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [194] terminated at timestep 400. cumulative reward:  40. avg reward: 26.789\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [195] terminated at timestep 400. cumulative reward:  28. avg reward: 26.795\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [196] terminated at timestep 400. cumulative reward:  48. avg reward: 26.903\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [197] terminated at timestep 400. cumulative reward:  28. avg reward: 26.909\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [198] terminated at timestep 400. cumulative reward:  31. avg reward: 26.929\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [199] terminated at timestep 400. cumulative reward:  27. avg reward: 26.93\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [200] terminated at timestep 400. cumulative reward:  40. avg reward: 26.995\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [201] terminated at timestep 400. cumulative reward:  36. avg reward: 27.04\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [202] terminated at timestep 400. cumulative reward:  25. avg reward: 27.03\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [203] terminated at timestep 400. cumulative reward:   9. avg reward: 26.941\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [204] terminated at timestep 400. cumulative reward:  46. avg reward: 27.034\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [205] terminated at timestep 400. cumulative reward:  25. avg reward: 27.024\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [206] terminated at timestep 400. cumulative reward:  25. avg reward: 27.015\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [207] terminated at timestep 400. cumulative reward:  23. avg reward: 26.995\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [208] terminated at timestep 400. cumulative reward:  56. avg reward: 27.135\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [209] terminated at timestep 400. cumulative reward:   9. avg reward: 27.048\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [210] terminated at timestep 400. cumulative reward:  36. avg reward: 27.09\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [211] terminated at timestep 400. cumulative reward:   9. avg reward: 27.005\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [212] terminated at timestep 400. cumulative reward:  56. avg reward: 27.142\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [213] terminated at timestep 400. cumulative reward:  43. avg reward: 27.216\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [214] terminated at timestep 400. cumulative reward:   9. avg reward: 27.131\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [215] terminated at timestep 400. cumulative reward:  20. avg reward: 27.098\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [216] terminated at timestep 400. cumulative reward:  17. avg reward: 27.051\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [217] terminated at timestep 400. cumulative reward:  20. avg reward: 27.018\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [218] terminated at timestep 400. cumulative reward:  12. avg reward: 26.95\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [219] terminated at timestep 400. cumulative reward:   9. avg reward: 26.868\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [220] terminated at timestep 400. cumulative reward:   9. avg reward: 26.786\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [221] terminated at timestep 400. cumulative reward:  48. avg reward: 26.882\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [222] terminated at timestep 400. cumulative reward:   9. avg reward: 26.802\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [223] terminated at timestep 400. cumulative reward:  43. avg reward: 26.874\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [224] terminated at timestep 400. cumulative reward:  36. avg reward: 26.915\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [225] terminated at timestep 400. cumulative reward:  48. avg reward: 27.009\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [226] terminated at timestep 400. cumulative reward:  57. avg reward: 27.142\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [227] terminated at timestep 400. cumulative reward:  23. avg reward: 27.123\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [228] terminated at timestep 400. cumulative reward:  11. avg reward: 27.053\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [229] terminated at timestep 400. cumulative reward:  76. avg reward: 27.266\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [230] terminated at timestep 400. cumulative reward:   9. avg reward: 27.187\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [231] terminated at timestep 400. cumulative reward:  36. avg reward: 27.225\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [232] terminated at timestep 400. cumulative reward:  37. avg reward: 27.267\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [233] terminated at timestep 400. cumulative reward:  20. avg reward: 27.236\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [234] terminated at timestep 400. cumulative reward:   9. avg reward: 27.158\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [235] terminated at timestep 400. cumulative reward:  45. avg reward: 27.234\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [236] terminated at timestep 400. cumulative reward:  36. avg reward: 27.271\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [237] terminated at timestep 400. cumulative reward:  12. avg reward: 27.207\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [238] terminated at timestep 400. cumulative reward:  25. avg reward: 27.197\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [239] terminated at timestep 400. cumulative reward:  22. avg reward: 27.176\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [240] terminated at timestep 400. cumulative reward:  19. avg reward: 27.142\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [241] terminated at timestep 400. cumulative reward:   9. avg reward: 27.066\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [242] terminated at timestep 400. cumulative reward:  17. avg reward: 27.025\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [243] terminated at timestep 400. cumulative reward:  57. avg reward: 27.148\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [244] terminated at timestep 400. cumulative reward:  20. avg reward: 27.119\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [245] terminated at timestep 400. cumulative reward:  28. avg reward: 27.122\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [246] terminated at timestep 400. cumulative reward:  23. avg reward: 27.106\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [247] terminated at timestep 400. cumulative reward:  43. avg reward: 27.17\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [248] terminated at timestep 400. cumulative reward:  28. avg reward: 27.173\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [249] terminated at timestep 400. cumulative reward:  11. avg reward: 27.108\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [250] terminated at timestep 400. cumulative reward:  43. avg reward: 27.172\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [251] terminated at timestep 400. cumulative reward:  48. avg reward: 27.255\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [252] terminated at timestep 400. cumulative reward:  20. avg reward: 27.226\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [253] terminated at timestep 400. cumulative reward:   9. avg reward: 27.154\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [254] terminated at timestep 400. cumulative reward:  42. avg reward: 27.213\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [255] terminated at timestep 400. cumulative reward:  12. avg reward: 27.153\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [256] terminated at timestep 400. cumulative reward:  34. avg reward: 27.18\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [257] terminated at timestep 400. cumulative reward:  14. avg reward: 27.128\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [258] terminated at timestep 400. cumulative reward:  37. avg reward: 27.167\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [259] terminated at timestep 400. cumulative reward:  12. avg reward: 27.108\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [260] terminated at timestep 400. cumulative reward: 105. avg reward: 27.408\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [261] terminated at timestep 400. cumulative reward:  36. avg reward: 27.441\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [262] terminated at timestep 400. cumulative reward:  17. avg reward: 27.401\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [263] terminated at timestep 400. cumulative reward:  31. avg reward: 27.414\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [264] terminated at timestep 400. cumulative reward:  22. avg reward: 27.394\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [265] terminated at timestep 400. cumulative reward:   9. avg reward: 27.325\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [266] terminated at timestep 400. cumulative reward:  42. avg reward: 27.38\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [267] terminated at timestep 400. cumulative reward:  33. avg reward: 27.401\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [268] terminated at timestep 400. cumulative reward:  77. avg reward: 27.586\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [269] terminated at timestep 400. cumulative reward:  46. avg reward: 27.654\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [270] terminated at timestep 400. cumulative reward:  31. avg reward: 27.667\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [271] terminated at timestep 400. cumulative reward:  54. avg reward: 27.764\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [272] terminated at timestep 400. cumulative reward:  48. avg reward: 27.838\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [273] terminated at timestep 400. cumulative reward:   9. avg reward: 27.769\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [274] terminated at timestep 400. cumulative reward:  34. avg reward: 27.792\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [275] terminated at timestep 400. cumulative reward:   6. avg reward: 27.713\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [276] terminated at timestep 400. cumulative reward:  20. avg reward: 27.685\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [277] terminated at timestep 400. cumulative reward:  12. avg reward: 27.628\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [278] terminated at timestep 400. cumulative reward:  31. avg reward: 27.64\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [279] terminated at timestep 400. cumulative reward:  25. avg reward: 27.631\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [280] terminated at timestep 400. cumulative reward:  23. avg reward: 27.614\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [281] terminated at timestep 400. cumulative reward:  33. avg reward: 27.633\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [282] terminated at timestep 400. cumulative reward:  56. avg reward: 27.734\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [283] terminated at timestep 400. cumulative reward:  17. avg reward: 27.696\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [284] terminated at timestep 400. cumulative reward:   9. avg reward: 27.63\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [285] terminated at timestep 400. cumulative reward:  67. avg reward: 27.768\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [286] terminated at timestep 400. cumulative reward:  23. avg reward: 27.752\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [287] terminated at timestep 400. cumulative reward:  25. avg reward: 27.742\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [288] terminated at timestep 400. cumulative reward:   9. avg reward: 27.677\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [289] terminated at timestep 400. cumulative reward:  12. avg reward: 27.623\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [290] terminated at timestep 400. cumulative reward:   9. avg reward: 27.559\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [291] terminated at timestep 400. cumulative reward:   9. avg reward: 27.495\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [292] terminated at timestep 400. cumulative reward:  45. avg reward: 27.555\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [293] terminated at timestep 400. cumulative reward:  34. avg reward: 27.577\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [294] terminated at timestep 400. cumulative reward:  28. avg reward: 27.578\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [295] terminated at timestep 400. cumulative reward:  12. avg reward: 27.525\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [296] terminated at timestep 400. cumulative reward:  12. avg reward: 27.473\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [297] terminated at timestep 400. cumulative reward:  22. avg reward: 27.455\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [298] terminated at timestep 400. cumulative reward:   9. avg reward: 27.393\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [299] terminated at timestep 400. cumulative reward:  12. avg reward: 27.341\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [300] terminated at timestep 400. cumulative reward:  48. avg reward: 27.41\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [301] terminated at timestep 400. cumulative reward:  17. avg reward: 27.375\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [302] terminated at timestep 400. cumulative reward:  14. avg reward: 27.331\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [303] terminated at timestep 400. cumulative reward:  25. avg reward: 27.323\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [304] terminated at timestep 400. cumulative reward:  54. avg reward: 27.411\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [305] terminated at timestep 400. cumulative reward:  31. avg reward: 27.423\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [306] terminated at timestep 400. cumulative reward:  12. avg reward: 27.373\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [307] terminated at timestep 400. cumulative reward:  20. avg reward: 27.349\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [308] terminated at timestep 400. cumulative reward:  17. avg reward: 27.315\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [309] terminated at timestep 400. cumulative reward:  14. avg reward: 27.272\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [310] terminated at timestep 400. cumulative reward:  45. avg reward: 27.329\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [311] terminated at timestep 400. cumulative reward:  65. avg reward: 27.45\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [312] terminated at timestep 400. cumulative reward:  17. avg reward: 27.417\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [313] terminated at timestep 400. cumulative reward:  50. avg reward: 27.489\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [314] terminated at timestep 400. cumulative reward:  51. avg reward: 27.564\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [315] terminated at timestep 400. cumulative reward:  31. avg reward: 27.575\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [316] terminated at timestep 400. cumulative reward:  26. avg reward: 27.57\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [317] terminated at timestep 400. cumulative reward:   9. avg reward: 27.511\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [318] terminated at timestep 400. cumulative reward:   9. avg reward: 27.453\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [319] terminated at timestep 400. cumulative reward:  31. avg reward: 27.464\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [320] terminated at timestep 400. cumulative reward:  40. avg reward: 27.503\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [321] terminated at timestep 400. cumulative reward:  20. avg reward: 27.48\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [322] terminated at timestep 400. cumulative reward:  25. avg reward: 27.472\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [323] terminated at timestep 400. cumulative reward:  43. avg reward: 27.52\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [324] terminated at timestep 400. cumulative reward:  51. avg reward: 27.593\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [325] terminated at timestep 400. cumulative reward:  38. avg reward: 27.625\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [326] terminated at timestep 400. cumulative reward:  33. avg reward: 27.641\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [327] terminated at timestep 400. cumulative reward:  31. avg reward: 27.651\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [328] terminated at timestep 400. cumulative reward:   9. avg reward: 27.595\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [329] terminated at timestep 400. cumulative reward:   9. avg reward: 27.538\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [330] terminated at timestep 400. cumulative reward:  42. avg reward: 27.582\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [331] terminated at timestep 400. cumulative reward:  39. avg reward: 27.616\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [332] terminated at timestep 400. cumulative reward:  28. avg reward: 27.617\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [333] terminated at timestep 400. cumulative reward:   9. avg reward: 27.562\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [334] terminated at timestep 400. cumulative reward:  46. avg reward: 27.617\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [335] terminated at timestep 400. cumulative reward:  23. avg reward: 27.603\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [336] terminated at timestep 400. cumulative reward:  30. avg reward: 27.61\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [337] terminated at timestep 400. cumulative reward:  43. avg reward: 27.656\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [338] terminated at timestep 400. cumulative reward:  57. avg reward: 27.743\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [339] terminated at timestep 400. cumulative reward:   9. avg reward: 27.687\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [340] terminated at timestep 400. cumulative reward:  43. avg reward: 27.732\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [341] terminated at timestep 400. cumulative reward:  20. avg reward: 27.71\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [342] terminated at timestep 400. cumulative reward:  51. avg reward: 27.778\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [343] terminated at timestep 400. cumulative reward:  42. avg reward: 27.819\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [344] terminated at timestep 400. cumulative reward:  38. avg reward: 27.849\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [345] terminated at timestep 400. cumulative reward:  19. avg reward: 27.823\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [346] terminated at timestep 400. cumulative reward:  53. avg reward: 27.896\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [347] terminated at timestep 400. cumulative reward:  54. avg reward: 27.971\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [348] terminated at timestep 400. cumulative reward:  28. avg reward: 27.971\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [349] terminated at timestep 400. cumulative reward:   9. avg reward: 27.917\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [350] terminated at timestep 400. cumulative reward:   6. avg reward: 27.854\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [351] terminated at timestep 400. cumulative reward:  37. avg reward: 27.88\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [352] terminated at timestep 400. cumulative reward:  12. avg reward: 27.835\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [353] terminated at timestep 400. cumulative reward:   9. avg reward: 27.782\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [354] terminated at timestep 400. cumulative reward:  23. avg reward: 27.768\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [355] terminated at timestep 400. cumulative reward:  17. avg reward: 27.738\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [356] terminated at timestep 400. cumulative reward:  40. avg reward: 27.772\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [357] terminated at timestep 400. cumulative reward:  12. avg reward: 27.728\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [358] terminated at timestep 400. cumulative reward:  12. avg reward: 27.684\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [359] terminated at timestep 400. cumulative reward:   0. avg reward: 27.607\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [360] terminated at timestep 400. cumulative reward:   9. avg reward: 27.556\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [361] terminated at timestep 400. cumulative reward:  45. avg reward: 27.604\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [362] terminated at timestep 400. cumulative reward:  25. avg reward: 27.597\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [363] terminated at timestep 400. cumulative reward:  38. avg reward: 27.625\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [364] terminated at timestep 400. cumulative reward:  12. avg reward: 27.582\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [365] terminated at timestep 400. cumulative reward:  12. avg reward: 27.54\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [366] terminated at timestep 400. cumulative reward:   9. avg reward: 27.489\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [367] terminated at timestep 400. cumulative reward:  17. avg reward: 27.46\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [368] terminated at timestep 400. cumulative reward:  23. avg reward: 27.448\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [369] terminated at timestep 400. cumulative reward:  12. avg reward: 27.407\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [370] terminated at timestep 400. cumulative reward:  54. avg reward: 27.478\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [371] terminated at timestep 400. cumulative reward:  31. avg reward: 27.488\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [372] terminated at timestep 400. cumulative reward:  17. avg reward: 27.46\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [373] terminated at timestep 400. cumulative reward:  12. avg reward: 27.418\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [374] terminated at timestep 400. cumulative reward:  17. avg reward: 27.39\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [375] terminated at timestep 400. cumulative reward:  12. avg reward: 27.349\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [376] terminated at timestep 400. cumulative reward:  12. avg reward: 27.309\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [377] terminated at timestep 400. cumulative reward:  28. avg reward: 27.31\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [378] terminated at timestep 400. cumulative reward:  46. avg reward: 27.36\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [379] terminated at timestep 400. cumulative reward:  46. avg reward: 27.409\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [380] terminated at timestep 400. cumulative reward:  48. avg reward: 27.463\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [381] terminated at timestep 400. cumulative reward:  12. avg reward: 27.423\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [382] terminated at timestep 400. cumulative reward:  45. avg reward: 27.469\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [383] terminated at timestep 400. cumulative reward:  23. avg reward: 27.457\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [384] terminated at timestep 400. cumulative reward:  37. avg reward: 27.482\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [385] terminated at timestep 400. cumulative reward:  37. avg reward: 27.506\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [386] terminated at timestep 400. cumulative reward:  39. avg reward: 27.536\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [387] terminated at timestep 400. cumulative reward:  31. avg reward: 27.545\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [388] terminated at timestep 400. cumulative reward:  17. avg reward: 27.518\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [389] terminated at timestep 400. cumulative reward:  12. avg reward: 27.478\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [390] terminated at timestep 400. cumulative reward:  23. avg reward: 27.467\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [391] terminated at timestep 400. cumulative reward:  42. avg reward: 27.504\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [392] terminated at timestep 400. cumulative reward:  12. avg reward: 27.464\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [393] terminated at timestep 400. cumulative reward:  50. avg reward: 27.522\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [394] terminated at timestep 400. cumulative reward:  12. avg reward: 27.482\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [395] terminated at timestep 400. cumulative reward:  25. avg reward: 27.476\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [396] terminated at timestep 400. cumulative reward:  53. avg reward: 27.54\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [397] terminated at timestep 400. cumulative reward:  22. avg reward: 27.526\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "User interrupted training. Saving weights\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 1000\n",
        "number_of_epochs = 2\n",
        "batch_size = 20\n",
        "average_reward = 0\n",
        "best_avg = 0\n",
        "previous_action_to_reward = 5\n",
        "gamma = 0.95\n",
        "avg_reward_list_PPO = []\n",
        "\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        actions = []\n",
        "        deltas = []\n",
        "        observations = []\n",
        "\n",
        "        t = 0\n",
        "        obs = env.reset()\n",
        "        obs = obs['both_agent_obs'] \n",
        "        \n",
        "        done = False\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            action1 = agent_1.action(obs)\n",
        "            action2 = agent_2.action(obs)\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            action = (player_1_action, player_2_action)\n",
        "\n",
        "            actions.append(action)\n",
        "            observations.append(obs)\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            new_obs = new_obs['both_agent_obs']\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            if total_reward > 0:\n",
        "                if t > previous_action_to_reward:\n",
        "                    for i in range(t-1, t-previous_action_to_reward-1, -1):\n",
        "                        deltas[i] += total_reward\n",
        "                else:\n",
        "                    for i in range(t-1,-1,-1):\n",
        "                        deltas[i] += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            if done:\n",
        "                delta = total_reward - shared_critic.call(obs)\n",
        "            else:\n",
        "                delta = total_reward + gamma*shared_critic.call(new_obs) - shared_critic.call(obs)\n",
        "\n",
        "            deltas.append(delta)\n",
        "            \n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            # think about training the critic by itself for a while\n",
        "            t += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        avg_reward_list_PPO.append(average_reward)\n",
        "\n",
        "        if average_reward > best_avg and episode > 20:\n",
        "            best_avg = average_reward\n",
        "            shared_critic.save_weights(path_critic + \"shared_critic_exp_10.weights.h5\")\n",
        "            shared_actor.save_weights(path_actor + \"shared_actor_exp_10.weights.h5\")\n",
        "        \n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {t}. cumulative reward: {cumulative_reward:>3d}. avg reward: {round(average_reward, 3)}\")\n",
        "        print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "        for epoch in range(1, number_of_epochs + 1):\n",
        "            num_batches = len(actions) // batch_size\n",
        "            shuffled_indices = tf.random.shuffle(tf.range(len(actions)))\n",
        "            for batch in range(num_batches):\n",
        "                if batch == num_batches: # last batch\n",
        "                    idx = shuffled_indices[batch*batch_size:]\n",
        "                else:\n",
        "                    idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                deltas_batch = tf.squeeze(tf.gather(deltas, idx), axis=-1)\n",
        "                actions_batch = tf.gather(actions, idx)\n",
        "                observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "                shared_critic.train_batch(deltas_batch, observations_batch)\n",
        "                shared_actor.train_batch_PPO(deltas_batch, observations_batch, actions_batch, agent_1.old_policy)\n",
        "            print(f\"Epoch {epoch} terminated.\")\n",
        "        agent_1.update_old_policy()\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    shared_critic.save_weights(path_critic + \"shared_critic_exp_10.weights.h5\")\n",
        "    shared_actor.save_weights(path_actor + \"shared_actor_exp_10.weights.h5\")\n",
        "    print(\"User interrupted training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "251c3851",
      "metadata": {},
      "outputs": [],
      "source": [
        "shared_critic.load_weights(path_critic + \"shared_critic_exp_10.weights.h5\")\n",
        "shared_actor.load_weights(path_actor + \"shared_actor_exp_10.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "6652e161",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|██████████| 10/10 [02:22<00:00, 14.29s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e54496d7764e7088ba3f3328d1cc3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "# trajs = ae.evaluate_human_model_pair(1)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c6aa54f",
      "metadata": {
        "id": "1c6aa54f"
      },
      "source": [
        "# Using trajectories\n",
        " When evaluating trajectory of my agents, the agents are fed with the overcooked state.  \n",
        " Since my agent use the \"both_agent_obs\", i can convert the overcooked state in \"both_agent_obs\" through base_env.featurize_state_mdp(state).  \n",
        " The problem here is that i need to pay attention to the index since this method returns always in the POV of agent 0.  \n",
        " What i can do is to retrieve the index with env.agent_idx and i will have the following equality:  \n",
        " base_env.featurize_state_mdp(state)[0] == obs['both_agent_obs'][env.agent_idx]  \n",
        " I need to find a way to include the environment on my agent class and be able to call the agent_idx in order to preprocess the state and use the right order.\n",
        " During testing this should not be a huge problem since our network should be able to generalize the position... let's do without it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "03f39dab",
      "metadata": {
        "id": "03f39dab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obs = env.reset()\n",
        "state = obs['overcooked_state']\n",
        "transformed_obs = base_env.featurize_state_mdp(state)\n",
        "print(env.agent_idx)\n",
        "transformed_obs[env.agent_idx] == obs['both_agent_obs'][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "938fee1f",
      "metadata": {
        "id": "938fee1f"
      },
      "source": [
        "# Let's try implementing training with batches\n",
        "The idea is to compute some steps in the episode (let's say the whole episode), then you perform stochastic gradient descent with batches. the batch is the whole episode, and you train on minibatches of the episode, performing multiple epochs (let's say 10.)  \n",
        "`Note:` THIS IS STILL ACTOR CRITIC KINDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "43d7deec",
      "metadata": {
        "id": "43d7deec"
      },
      "outputs": [],
      "source": [
        "class PolicyBatch(Model):\n",
        "    def __init__(self, input_shape, num_actions, optimizer):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.optimizer = optimizer\n",
        "        self.input_a = Input(shape=(self.input_shape))\n",
        "        self.input_b = Input(shape=(self.input_shape))\n",
        "        self.dense_1 = layers.Dense(128, activation='tanh')\n",
        "        self.dense_2 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_3 = layers.Dense(128, activation='tanh')\n",
        "        self.policy_a = layers.Dense(self.num_actions, activation='softmax', name=\"policy_a\")\n",
        "        self.policy_b = layers.Dense(self.num_actions, activation='softmax', name=\"policy_b\")\n",
        "        self.build_model()\n",
        "\n",
        "    def preprocess(self, obs_batch):\n",
        "        if isinstance(obs_batch, Tuple):\n",
        "            obs_batch = [obs_batch] # to handle the case where obs_batch is a single observation\n",
        "\n",
        "        obs_1, obs_2 = zip(*obs_batch)\n",
        "        obs_batch = tf.concat([tf.stack(obs_1), tf.stack(obs_2)], axis=-1)\n",
        "        return obs_batch\n",
        "\n",
        "\n",
        "    def call(self, obs_batch, training=False):\n",
        "        x = self.preprocess(obs_batch)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.dense_3(x)\n",
        "        policy_a = self.policy_a(x)\n",
        "        policy_b = self.policy_b(x)\n",
        "        return (policy_a, policy_b) # self.call(obs_batch)[0][N]: n-th policy of agent 1\n",
        "\n",
        "    def build_model(self):\n",
        "        # computing a forward pass in order to automatically build the model\n",
        "        dummy_input = (\n",
        "            tf.zeros((1, 96)),\n",
        "            tf.zeros((1, 96))\n",
        "        )\n",
        "        _ = self(dummy_input)\n",
        "\n",
        "    def train_step(self, deltas_batch: tf.Tensor, obs_batch, actions_batch):\n",
        "        # update t with t + alpha_t*delta*grad_pi^(A|S) where A is the action taken before reaching St+1\n",
        "        with tf.GradientTape() as tape:\n",
        "            pi = self.call(obs_batch, training=True)\n",
        "            log_pi = tf.math.log(pi)\n",
        "            # processed_log_pi = -deltas_batch * log_pi\n",
        "            # pi_a = 0\n",
        "            # for i in range(len(actions_batch)):\n",
        "            #     pi_a += processed_log_pi[0][i][actions_batch[i][0]] + processed_log_pi[1][i][actions_batch[i][1]]\n",
        "            pi_a1 = tf.gather(log_pi[0], actions_batch[:, 0], axis=1, batch_dims=1)\n",
        "            pi_a2 = tf.gather(log_pi[1], actions_batch[:, 1], axis=1, batch_dims=1)\n",
        "\n",
        "            # Now compute the weighted sum over the batch\n",
        "            pi_a = -tf.reduce_sum(tf.squeeze(deltas_batch) * (pi_a1 + pi_a2))\n",
        "\n",
        "\n",
        "        grad_pi_a = tape.gradient(pi_a, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_pi_a, self.trainable_weights))\n",
        "\n",
        "        # # Assuming shape of log_pi: (2, batch_size, num_actions)\n",
        "        # # actions_batch: (batch_size, 2), each row is [a1, a2]\n",
        "        # pi_a1 = tf.gather(log_pi[0], actions_batch[:, 0], axis=1, batch_dims=1)\n",
        "        # pi_a2 = tf.gather(log_pi[1], actions_batch[:, 1], axis=1, batch_dims=1)\n",
        "\n",
        "        # # Now compute the weighted sum over the batch\n",
        "        # loss = -tf.reduce_sum(tf.squeeze(deltas_batch) * (pi_a1 + pi_a2))\n",
        "\n",
        "\n",
        "\n",
        "class ValueFunctionApproximatorBatch(Model):\n",
        "    def __init__(self, input_shape, optimizer):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.optimizer = optimizer\n",
        "        self.input_a = Input(shape=(self.input_shape))\n",
        "        self.input_b = Input(shape=(self.input_shape))\n",
        "        self.dense_1 = layers.Dense(128, activation='tanh')\n",
        "        self.dense_2 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_3 = layers.Dense(128, activation='tanh')\n",
        "        # self.value_function = layers.Dense(1, activation='relu', name=\"value_function\")\n",
        "        self.value_function = layers.Dense(1, name=\"value_function\")\n",
        "        self.build_model()\n",
        "\n",
        "    def preprocess(self, obs_batch):\n",
        "        if isinstance(obs_batch, Tuple):\n",
        "            obs_batch = [obs_batch] # to handle the case where obs_batch is a single observation\n",
        "\n",
        "        obs_1, obs_2 = zip(*obs_batch)\n",
        "        obs_batch = tf.concat([tf.stack(obs_1), tf.stack(obs_2)], axis=-1)\n",
        "        return obs_batch\n",
        "\n",
        "\n",
        "    def call(self, obs_batch, training=False):\n",
        "        x = self.preprocess(obs_batch)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.dense_3(x)\n",
        "        value_function = self.value_function(x)\n",
        "        return value_function\n",
        "\n",
        "    def build_model(self):\n",
        "        # computing a forward pass in order to automatically build the model\n",
        "        dummy_input =  (\n",
        "            tf.zeros((1, 96)),\n",
        "            tf.zeros((1, 96))\n",
        "        )\n",
        "        _ = self(dummy_input)\n",
        "\n",
        "    def train_step(self, deltas_batch: tf.Tensor, obs_batch): # deltas is a tf.Tensor of shape (batch_size,1)\n",
        "        # update w with w + alpha_w*grad_v^(St)*delta\n",
        "        with tf.GradientTape() as tape:\n",
        "            state_value = self.call(obs_batch, training=True)\n",
        "            loss = tf.reduce_mean(tf.square(deltas_batch)) # adding a term that minimizes the distance between the true and the estimated value\n",
        "            processed_state_value = -deltas_batch * state_value + loss\n",
        "\n",
        "        grad_state_value = tape.gradient(processed_state_value, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_state_value, self.trainable_weights))\n",
        "\n",
        "class MyAgentBatch(Agent):\n",
        "    \"\"\"\n",
        "    This class is more a couple of actors since we use shared networks and the output are 2!!!\n",
        "    For now let's treat it like a single player identified by self.index\n",
        "    \"\"\"\n",
        "    def __init__(self, actor, critic, idx, base_env: OvercookedEnv):\n",
        "        super().__init__()\n",
        "        self.actor = actor\n",
        "        self.critic = critic\n",
        "        self.idx = idx\n",
        "        if not self.idx in [0,1]:\n",
        "            raise AssertionError(\"The index of the agent must be either 0 or 1!\")\n",
        "        self.base_env = base_env\n",
        "\n",
        "    def action(self, obs):\n",
        "        \"\"\"\n",
        "        obs: preprocessed observation (or overcookedstate)\n",
        "        We want to output the action given the state. can use a NN!\n",
        "        should return a tuple (Action, Dict)\n",
        "        Dict should contain info about the action ('action_probs': numpy array)\n",
        "        \"\"\"\n",
        "        if isinstance(obs, OvercookedState):\n",
        "            # this is useful for translating the OvercookedState\n",
        "            # into observation that can be fed into the NN.\n",
        "            obs_from_state = self.base_env.featurize_state_mdp(obs)\n",
        "            obs = (obs_from_state[0],obs_from_state[1])\n",
        "\n",
        "\n",
        "        action_probs = self.actor.call(obs)[self.idx].numpy()\n",
        "        # if np.random.random() > self.epsilon:\n",
        "        #     action = Action.argmax(action_probs) # greedy selection\n",
        "        # else:\n",
        "        #     action_idx = np.random.choice(range(0,6), size=1)[0]\n",
        "        #     action = Action.INDEX_TO_ACTION[action_idx] # random exploration\n",
        "        sample = tf.random.categorical(tf.math.log(action_probs), num_samples = 1)\n",
        "        action_idx = tf.squeeze(sample, axis=-1)[0].numpy()\n",
        "        action = Action.INDEX_TO_ACTION[action_idx]\n",
        "        return (action, {'action_probs': action_probs})\n",
        "\n",
        "    def actions(self, obss):\n",
        "        \"\"\"\n",
        "        Look at the documentation of the Agent class\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def update(self, obs, reward):\n",
        "        \"\"\"\n",
        "        What do we need to update?\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    # def decay_epsilon(self, decay):\n",
        "    #     if self.epsilon - decay <= 0.5:\n",
        "    #         self.epsilon = 0.5\n",
        "    #     else:\n",
        "    #         self.epsilon -= decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b81d70c8",
      "metadata": {
        "id": "b81d70c8"
      },
      "outputs": [],
      "source": [
        "number_of_frames = 400\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)\n",
        "\n",
        "alpha_t = 1e-6\n",
        "alpha_w = 1e-5\n",
        "\n",
        "optimizer_actor = Adam(learning_rate=alpha_t)\n",
        "optimizer_critic = Adam(learning_rate=alpha_w)\n",
        "\n",
        "input_shape = env.observation_space._shape\n",
        "\n",
        "shared_actor_batch = PolicyBatch(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=optimizer_actor\n",
        ")\n",
        "\n",
        "shared_critic_batch = ValueFunctionApproximatorBatch(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=optimizer_critic\n",
        "    )\n",
        "\n",
        "agent_1 = MyAgentBatch(\n",
        "    actor=shared_actor_batch,\n",
        "    critic=shared_critic_batch,\n",
        "    idx=0,\n",
        "    base_env=base_env\n",
        ")\n",
        "agent_2 = MyAgentBatch(\n",
        "    actor=shared_actor_batch,\n",
        "    critic=shared_critic_batch,\n",
        "    idx=1,\n",
        "    base_env=base_env\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "c9350f67",
      "metadata": {
        "id": "c9350f67"
      },
      "outputs": [],
      "source": [
        "path_critic = \"networks/critic/\"\n",
        "path_actor = \"networks/actor/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "61f56709",
      "metadata": {
        "id": "61f56709",
        "outputId": "221c5d18-d592-474a-85ed-ae66babd72b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [  1] terminated at timestep 400. cumulative reward:   3. avg reward: 3.0.\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 1\n",
        "batch_size = 30\n",
        "number_of_epochs = 2\n",
        "average_reward = 0\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        timestep = 0\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "\n",
        "        # shaped_reward_factor = 1 # multiplicative factor for discounting shaped reward.\n",
        "        # discount_rate = 1 # will decrease the shaped reward every time\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        if (episode) % 75 == 0:\n",
        "            shared_critic_batch.save_weights(path_critic + \"shared_critic_batch.weights.h5\")\n",
        "            shared_actor_batch.save_weights(path_actor + \"shared_actor_batch.weights.h5\")\n",
        "\n",
        "        actions = []\n",
        "        deltas = []\n",
        "        observations = []\n",
        "        rewards = []\n",
        "\n",
        "        while not done:\n",
        "            # reordering the actions based on the POV of the environment\n",
        "            if obs['other_agent_env_idx'] == 0:\n",
        "                my_obs = (obs['both_agent_obs'][1],obs['both_agent_obs'][0])\n",
        "                obs['both_agent_obs'] = my_obs\n",
        "\n",
        "            action1 = agent_1.action(obs['both_agent_obs'])\n",
        "            action2 = agent_2.action(obs['both_agent_obs'])\n",
        "            player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            \n",
        "            if obs['other_agent_env_idx'] == 1:\n",
        "                action = (player_1_action, player_2_action)\n",
        "                # action = (agent_1_actions[timestep], agent_2_actions[timestep])\n",
        "            else:\n",
        "                action = (player_2_action,player_1_action)\n",
        "                # action = (agent_2_actions[timestep], agent_1_actions[timestep])\n",
        "\n",
        "            actions.append(action)\n",
        "            observations.append(obs['both_agent_obs'])\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "\n",
        "            # if shaped_reward != 0:\n",
        "            #     shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "            #     shaped_reward_factor *= discount_rate\n",
        "\n",
        "\n",
        "            total_reward = reward + shaped_reward\n",
        "            rewards.append(total_reward)\n",
        "            cumulative_reward += total_reward\n",
        "\n",
        "            # compute delta = R + v^(St+1) - v^(St) where v^(St+1) = 0 if done\n",
        "            # if done:\n",
        "            #     delta = total_reward - shared_critic_batch.call(obs['both_agent_obs'])\n",
        "            # else:\n",
        "            #     delta = total_reward + shared_critic_batch.call(new_obs['both_agent_obs']) - shared_critic_batch.call(obs['both_agent_obs'])\n",
        "\n",
        "            # deltas.append(delta)\n",
        "\n",
        "            # update state (obs = new_obs)\n",
        "            obs = new_obs\n",
        "\n",
        "            timestep += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        print(f\"Episode [{episode:>3d}] terminated at timestep {timestep}. cumulative reward: {cumulative_reward:>3d}. avg reward: {round(average_reward, 3)}.\")\n",
        "\n",
        "        print(f\"Computing the deltas (MONTE-CARLO)\")\n",
        "        for t in range(len(actions)):\n",
        "            G_t = np.sum(rewards[t:])\n",
        "            delta = G_t - shared_critic_batch.call(observations[t])\n",
        "            deltas.append(delta)\n",
        "\n",
        "        print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "        for epoch in range(1, number_of_epochs + 1):\n",
        "            num_batches = len(actions) // batch_size\n",
        "            shuffled_indices = tf.random.shuffle(tf.range(len(actions)))\n",
        "            for batch in range(num_batches):\n",
        "                if batch == num_batches: # last batch\n",
        "                    idx = shuffled_indices[batch*batch_size:]\n",
        "                else:\n",
        "                    idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                deltas_batch = tf.squeeze(tf.gather(deltas, idx), axis=-1)\n",
        "                actions_batch = tf.gather(actions, idx)\n",
        "                observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "                shared_critic_batch.train_step(deltas_batch, observations_batch)\n",
        "                shared_actor_batch.train_step(deltas_batch, observations_batch, actions_batch)\n",
        "            print(f\"Epoch {epoch} terminated.\")\n",
        "\n",
        "\n",
        "\n",
        "        # shared_critic.save_weights(path_critic + \"shared_critic.weights.h5\")\n",
        "        # shared_actor.save_weights(path_actor + \"shared_actor.weights.h5\")\n",
        "except:\n",
        "    shared_critic_batch.save_weights(path_critic + \"shared_critic_batch.weights.h5\")\n",
        "    shared_actor_batch.save_weights(path_actor + \"shared_actor_batch.weights.h5\")\n",
        "    print(\"Unexpected interruption of training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "da08f7f0",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ce70979766b04bbca1d9b0e93edd4cd0"
          ]
        },
        "id": "da08f7f0",
        "outputId": "d63a1016-365e-4238-e7d2-1e473d677cc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|██████████| 10/10 [00:47<00:00,  4.73s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4df25a3ee1a74a879f1dd349eb91e83c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "de853212",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
              " array([[0.22263195, 0.1434645 , 0.07354847, 0.18801843, 0.34869647,\n",
              "         0.02364018]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
              " array([[0.15698901, 0.10884099, 0.09701831, 0.19173887, 0.3188748 ,\n",
              "         0.12653792]], dtype=float32)>)"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shared_actor_batch(observations[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "8e780e9d",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "26901325e6a1432b8e04604eb27f9c78"
          ]
        },
        "id": "8e780e9d",
        "outputId": "8bef7ba8-da62-4533-fbae-08ece6b4260d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|██████████| 10/10 [00:00<00:00, 12.70it/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55834c28fe38415fba9b24c1688d1975",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "ap = AgentPair(RandomAgent(all_actions=True), RandomAgent(all_actions=True))\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3f60cb1",
      "metadata": {
        "id": "c3f60cb1"
      },
      "source": [
        "# TRIALS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1225413e",
      "metadata": {},
      "source": [
        "actor batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4f0b2be",
      "metadata": {
        "id": "e4f0b2be"
      },
      "source": [
        "# Let's use different NNs for the agents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a52ab9e",
      "metadata": {
        "id": "9a52ab9e"
      },
      "outputs": [],
      "source": [
        "class SinglePolicyBatch(Model):\n",
        "    def __init__(self, input_shape, num_actions, optimizer):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.optimizer = optimizer\n",
        "        self.input_a = Input(shape=(self.input_shape))\n",
        "        self.input_b = Input(shape=(self.input_shape))\n",
        "        self.dense_1 = layers.Dense(128, activation='tanh')\n",
        "        self.dense_2 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_3 = layers.Dense(128, activation='tanh')\n",
        "        self.policy = layers.Dense(self.num_actions, activation='softmax', name=\"policy\")\n",
        "        self.build_model()\n",
        "\n",
        "    def preprocess(self, obs_batch):\n",
        "        if isinstance(obs_batch, Tuple):\n",
        "            obs_batch = [obs_batch] # to handle the case where obs_batch is a single observation\n",
        "\n",
        "        obs_1, obs_2 = zip(*obs_batch)\n",
        "        obs_batch = tf.concat([tf.stack(obs_1), tf.stack(obs_2)], axis=-1)\n",
        "        return obs_batch\n",
        "\n",
        "\n",
        "    def call(self, obs_batch, training=False):\n",
        "        x = self.preprocess(obs_batch)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.dense_3(x)\n",
        "        policy = self.policy(x)\n",
        "        return policy\n",
        "\n",
        "    def build_model(self):\n",
        "        # computing a forward pass in order to automatically build the model\n",
        "        dummy_input = (\n",
        "            tf.zeros((1, 96)),\n",
        "            tf.zeros((1, 96))\n",
        "        )\n",
        "        _ = self(dummy_input)\n",
        "\n",
        "    def train_step(self, deltas_batch: tf.Tensor, obs_batch, actions_batch):\n",
        "        # update t with t + alpha_t*delta*grad_pi^(A|S) where A is the action taken before reaching St+1\n",
        "        with tf.GradientTape() as tape:\n",
        "            pi = self.call(obs_batch, training=True)\n",
        "            log_pi = tf.math.log(pi)\n",
        "            processed_log_pi = -deltas_batch * log_pi\n",
        "            pi_a = 0\n",
        "            for i in range(len(actions_batch)):\n",
        "                # THIS NEED TO BE MODIFIED\n",
        "                pi_a += processed_log_pi[i][actions_batch[i]]\n",
        "            # pi_a = tf.gather(log_pi, actions_batch[:], axis=1, batch_dims=1)\n",
        "            # pi_a = -tf.reduce_sum(tf.squeeze(deltas_batch) * pi_a)\n",
        "\n",
        "        grad_pi_a = tape.gradient(pi_a, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_pi_a, self.trainable_weights))\n",
        "\n",
        "\n",
        "class SingleValueFunctionApproximatorBatch(Model):\n",
        "    def __init__(self, input_shape, optimizer):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.optimizer = optimizer\n",
        "        self.input_a = Input(shape=(self.input_shape))\n",
        "        self.input_b = Input(shape=(self.input_shape))\n",
        "        self.dense_1 = layers.Dense(128, activation='tanh')\n",
        "        self.dense_2 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_3 = layers.Dense(128, activation='tanh')\n",
        "        # self.value_function = layers.Dense(1, activation='relu', name=\"value_function\")\n",
        "        self.value_function = layers.Dense(1, name=\"value_function\")\n",
        "        self.build_model()\n",
        "\n",
        "    def preprocess(self, obs_batch):\n",
        "        if isinstance(obs_batch, Tuple):\n",
        "            obs_batch = [obs_batch] # to handle the case where obs_batch is a single observation\n",
        "\n",
        "        obs_1, obs_2 = zip(*obs_batch)\n",
        "        obs_batch = tf.concat([tf.stack(obs_1), tf.stack(obs_2)], axis=-1)\n",
        "        return obs_batch\n",
        "\n",
        "\n",
        "    def call(self, obs_batch, training=False):\n",
        "        x = self.preprocess(obs_batch)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.dense_3(x)\n",
        "        value_function = self.value_function(x)\n",
        "        return value_function\n",
        "\n",
        "    def build_model(self):\n",
        "        # computing a forward pass in order to automatically build the model\n",
        "        dummy_input =  (\n",
        "            tf.zeros((1, 96)),\n",
        "            tf.zeros((1, 96))\n",
        "        )\n",
        "        _ = self(dummy_input)\n",
        "\n",
        "    def train_step(self, deltas_batch: tf.Tensor, obs_batch): # deltas is a tf.Tensor of shape (batch_size,1)\n",
        "        # update w with w + alpha_w*grad_v^(St)*delta\n",
        "        with tf.GradientTape() as tape:\n",
        "            state_value = self.call(obs_batch, training=True)\n",
        "            loss = tf.reduce_mean(tf.square(deltas_batch)) # adding a term that minimizes the distance between the true and the estimated value\n",
        "            processed_state_value = -deltas_batch * state_value + loss\n",
        "\n",
        "        grad_state_value = tape.gradient(processed_state_value, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_state_value, self.trainable_weights))\n",
        "\n",
        "class SingleMyAgentBatch(Agent):\n",
        "    \"\"\"\n",
        "    This class implements a single Agent\n",
        "    For now let's treat it like a single player identified by self.index\n",
        "    \"\"\"\n",
        "    def __init__(self, actor, critic, idx, base_env: OvercookedEnv, epsilon = 0.1):\n",
        "        super().__init__()\n",
        "        self.actor = actor\n",
        "        self.critic = critic\n",
        "        self.idx = idx\n",
        "        if not self.idx in [0,1]:\n",
        "            raise AssertionError(\"The index of the agent must be either 0 or 1!\")\n",
        "        self.base_env = base_env\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def action(self, obs):\n",
        "        \"\"\"\n",
        "        obs: preprocessed observation (or overcookedstate)\n",
        "        We want to output the action given the state. can use a NN!\n",
        "        should return a tuple (Action, Dict)\n",
        "        Dict should contain info about the action ('action_probs': numpy array)\n",
        "        \"\"\"\n",
        "        if isinstance(obs, OvercookedState):\n",
        "            # this is useful for translating the OvercookedState\n",
        "            # into observation that can be fed into the NN.\n",
        "            obs_from_state = self.base_env.featurize_state_mdp(obs)\n",
        "            obs = (obs_from_state[0],obs_from_state[1])\n",
        "\n",
        "\n",
        "        action_probs = self.actor.call(obs).numpy()\n",
        "        if np.random.random() > self.epsilon:\n",
        "            action = Action.argmax(action_probs) # greedy selection\n",
        "        else:\n",
        "            action_idx = np.random.choice(range(0,6), size=1)[0]\n",
        "            action = Action.INDEX_TO_ACTION[action_idx] # random exploration\n",
        "        return (action, {'action_probs': action_probs})\n",
        "\n",
        "    def actions(self, obss):\n",
        "        \"\"\"\n",
        "        Look at the documentation of the Agent class\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def update(self, obs, reward):\n",
        "        \"\"\"\n",
        "        What do we need to update?\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def decay_epsilon(self, decay):\n",
        "        if self.epsilon - decay <= 0.5:\n",
        "            self.epsilon = 0.5\n",
        "        else:\n",
        "            self.epsilon -= decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6964557",
      "metadata": {
        "id": "f6964557"
      },
      "outputs": [],
      "source": [
        "number_of_frames = 9\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)\n",
        "\n",
        "alpha_t = 1e-5\n",
        "alpha_w = 1e-5\n",
        "\n",
        "optimizer_actor_1 = Adam(learning_rate=alpha_t)\n",
        "optimizer_actor_2 = Adam(learning_rate=alpha_t)\n",
        "optimizer_critic_1 = Adam(learning_rate=alpha_w)\n",
        "optimizer_critic_2 = Adam(learning_rate=alpha_w)\n",
        "\n",
        "input_shape = env.observation_space._shape\n",
        "\n",
        "single_actor_batch_1 = SinglePolicyBatch(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=optimizer_actor_1\n",
        ")\n",
        "single_actor_batch_2 = SinglePolicyBatch(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=optimizer_actor_2\n",
        ")\n",
        "\n",
        "single_critic_batch_1 = SingleValueFunctionApproximatorBatch(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=optimizer_critic_1\n",
        "    )\n",
        "\n",
        "single_critic_batch_2 = SingleValueFunctionApproximatorBatch(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=optimizer_critic_2\n",
        "    )\n",
        "\n",
        "agent_1 = SingleMyAgentBatch(\n",
        "    actor=single_actor_batch_1,\n",
        "    critic=single_critic_batch_1,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        "    epsilon=0.9\n",
        ")\n",
        "agent_2 = SingleMyAgentBatch(\n",
        "    actor=single_actor_batch_2,\n",
        "    critic=single_critic_batch_2,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        "    epsilon=0.9\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55bd79c3",
      "metadata": {
        "id": "55bd79c3"
      },
      "outputs": [],
      "source": [
        "path_critic = \"networks/critic/\"\n",
        "path_actor = \"networks/actor/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1ec03cc",
      "metadata": {
        "id": "b1ec03cc",
        "outputId": "aef52577-3711-4dc1-9ccd-0e512834057e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [1] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [2] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [3] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [4] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [5] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [6] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [7] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [8] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [9] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [10] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [11] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [12] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [13] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [14] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [15] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [16] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [17] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [18] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [19] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [20] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [21] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [22] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [23] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [24] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [25] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [26] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [27] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [28] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [29] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [30] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [31] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [32] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [33] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [34] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [35] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [36] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [37] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [38] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [39] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [40] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [41] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [42] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [43] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [44] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [45] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [46] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [47] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [48] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [49] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Episode [50] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 50\n",
        "batch_size = 30\n",
        "number_of_epochs = 2\n",
        "average_reward = 0\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        timestep = 0\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "\n",
        "        shaped_reward_factor = 1 # multiplicative factor for discounting shaped reward.\n",
        "        discount_rate = 1 # will decrease the shaped reward every time\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        # if (episode) % 100 == 0:\n",
        "        #     agent_1.decay_epsilon(decay=0.1)\n",
        "        #     agent_2.decay_epsilon(decay=0.1)\n",
        "        #     single_critic_batch_1.save_weights(path_critic + \"single_critic_batch_1_\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "        #     single_critic_batch_2.save_weights(path_critic + \"single_critic_batch_2_\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "        #     single_actor_batch_1.save_weights(path_actor + \"single_actor_batch_1\"+str(agent_2.epsilon)[2]+\".weights.h5\")\n",
        "        #     single_actor_batch_2.save_weights(path_actor + \"single_actor_batch_2\"+str(agent_2.epsilon)[2]+\".weights.h5\")\n",
        "\n",
        "        agent_1_actions = [0,3,5,4,4,2,0,5,3]\n",
        "        agent_2_actions = [2,5,3,0,5,2,4,4,4]\n",
        "        agent_1_deltas = []\n",
        "        agent_2_deltas = []\n",
        "        agent_1_rewards = []\n",
        "        agent_2_rewards = []\n",
        "        observations = []\n",
        "\n",
        "        while not done:\n",
        "            # reordering the actions based on the POV of the environment\n",
        "            if obs['other_agent_env_idx'] == 0:\n",
        "                my_obs = (obs['both_agent_obs'][1],obs['both_agent_obs'][0])\n",
        "                obs['both_agent_obs'] = my_obs\n",
        "\n",
        "            # action1 = agent_1.action(obs['both_agent_obs'])\n",
        "            # action2 = agent_2.action(obs['both_agent_obs'])\n",
        "            # player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            # player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "            if obs['other_agent_env_idx'] == 1:\n",
        "                # action = (player_1_action,player_2_action)\n",
        "                action = (agent_1_actions[timestep], agent_2_actions[timestep])\n",
        "            else:\n",
        "                # action = (player_2_action,player_1_action)\n",
        "                action = (agent_2_actions[timestep], agent_1_actions[timestep])\n",
        "\n",
        "            # agent_1_actions.append(player_1_action)\n",
        "            # agent_2_actions.append(player_2_action)\n",
        "            observations.append(obs['both_agent_obs'])\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            # shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "            agent_1_shaped_reward = env_info['shaped_r_by_agent'][0]\n",
        "            agent_2_shaped_reward = env_info['shaped_r_by_agent'][1]\n",
        "\n",
        "            # if shaped_reward != 0:\n",
        "            #     shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "            #     shaped_reward_factor *= discount_rate\n",
        "\n",
        "\n",
        "            agent_1_total_reward = reward + agent_1_shaped_reward\n",
        "            agent_2_total_reward = reward + agent_2_shaped_reward\n",
        "            agent_1_rewards.append(agent_1_total_reward)\n",
        "            agent_2_rewards.append(agent_2_total_reward)\n",
        "            cumulative_reward += (agent_1_total_reward + agent_2_total_reward - reward) # since it's in both the total rewards\n",
        "\n",
        "            obs = new_obs\n",
        "\n",
        "            timestep += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        print(f\"Episode [{episode}] terminated at timestep {timestep}. cumulative reward: {cumulative_reward}.\")\n",
        "\n",
        "        print(f\"cumulative sparse reward: {env_info['episode']['ep_game_stats']['cumulative_sparse_rewards_by_agent']}\")\n",
        "        print(f\"cumulative shaped reward: {env_info['episode']['ep_game_stats']['cumulative_shaped_rewards_by_agent']}\")\n",
        "\n",
        "        print(f\"Computing the deltas (MONTE-CARLO)\")\n",
        "        for t in range(len(observations)):\n",
        "            G_t_agent_1 = np.sum(agent_1_rewards[t:])\n",
        "            G_t_agent_2 = np.sum(agent_2_rewards[t:])\n",
        "            agent_1_delta = G_t_agent_1 - single_critic_batch_1.call(observations[t])\n",
        "            agent_2_delta = G_t_agent_2 - single_critic_batch_2.call(observations[t])\n",
        "            agent_1_deltas.append(agent_1_delta)\n",
        "            agent_2_deltas.append(agent_2_delta)\n",
        "\n",
        "        print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "        for epoch in range(number_of_epochs):\n",
        "            num_batches = len(observations) // batch_size\n",
        "            shuffled_indices = tf.random.shuffle(tf.range(len(observations)))\n",
        "            for batch in range(num_batches):\n",
        "                if batch == num_batches: # last batch\n",
        "                    idx = shuffled_indices[batch*batch_size:]\n",
        "                else:\n",
        "                    idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                agent_1_deltas_batch = tf.squeeze(tf.gather(agent_1_deltas, idx), axis=-1)\n",
        "                agent_2_deltas_batch = tf.squeeze(tf.gather(agent_2_deltas, idx), axis=-1)\n",
        "                agent_1_actions_batch = tf.gather(agent_1_actions, idx)\n",
        "                agent_2_actions_batch = tf.gather(agent_2_actions, idx)\n",
        "                observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "                single_critic_batch_1.train_step(agent_1_deltas_batch, observations_batch)\n",
        "                single_critic_batch_2.train_step(agent_2_deltas_batch, observations_batch)\n",
        "                single_actor_batch_1.train_step(agent_1_deltas_batch, observations_batch, agent_1_actions_batch)\n",
        "                single_actor_batch_2.train_step(agent_2_deltas_batch, observations_batch, agent_2_actions_batch)\n",
        "            print(f\"Epoch {epoch+1} terminated.\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    # single_critic_batch_1.save_weights(path_critic + \"single_critic_batch_1_\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "    # single_critic_batch_2.save_weights(path_critic + \"single_critic_batch_2_\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "    # single_actor_batch_1.save_weights(path_actor + \"single_actor_batch_1\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "    # single_actor_batch_2.save_weights(path_actor + \"single_actor_batch_2\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "    print(\"Unexpected interruption of training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6fd289",
      "metadata": {
        "id": "2f6fd289",
        "outputId": "976f3c50-73eb-444e-9815-0f0ad0c18516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9, 6), dtype=float32, numpy=\n",
              "array([[0.54414874, 0.05493079, 0.1023247 , 0.02552165, 0.04326788,\n",
              "        0.22980621],\n",
              "       [0.5266621 , 0.03774102, 0.11036786, 0.02473315, 0.0646782 ,\n",
              "        0.23581766],\n",
              "       [0.5498627 , 0.04551601, 0.10392934, 0.03518714, 0.06702498,\n",
              "        0.19847982],\n",
              "       [0.41870925, 0.04036696, 0.12767266, 0.06343313, 0.1267527 ,\n",
              "        0.22306532],\n",
              "       [0.4566209 , 0.03419267, 0.11589438, 0.04616598, 0.11127401,\n",
              "        0.23585202],\n",
              "       [0.39955464, 0.06012763, 0.22791953, 0.03555314, 0.07913763,\n",
              "        0.19770738],\n",
              "       [0.60577947, 0.06245914, 0.09557437, 0.00751843, 0.05389806,\n",
              "        0.17477058],\n",
              "       [0.5739549 , 0.0505186 , 0.09698042, 0.00787342, 0.05436873,\n",
              "        0.21630393],\n",
              "       [0.6620109 , 0.04429185, 0.09476521, 0.00352296, 0.03521813,\n",
              "        0.16019094]], dtype=float32)>"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_1.actor(observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed7b0ff7",
      "metadata": {
        "id": "ed7b0ff7"
      },
      "outputs": [],
      "source": [
        "single_critic_batch_1.load_weights(path_critic + \"single_critic_batch_1_6.weights.h5\")\n",
        "single_critic_batch_2.load_weights(path_critic + \"single_critic_batch_2_6.weights.h5\")\n",
        "single_actor_batch_1.load_weights(path_actor + \"single_actor_batch_16.weights.h5\")\n",
        "single_actor_batch_2.load_weights(path_actor + \"single_actor_batch_26.weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d34ce220",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "cab7d876fa7740abaebea4c71d8c8c97"
          ]
        },
        "id": "d34ce220",
        "outputId": "d1c9fb67-4a8c-4602-ab5c-92cba58ed3fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|██████████| 10/10 [00:44<00:00,  4.47s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cab7d876fa7740abaebea4c71d8c8c97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "agent_1.epsilon = 0.1\n",
        "agent_2.epsilon = 0.1\n",
        "ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed905ae3",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9e3588454c424947a9f5f7de17fe01ae"
          ]
        },
        "id": "ed905ae3",
        "outputId": "6f3416b7-b455-43e7-9344-5b812c60c8ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Avg rew: 0.00 (std: 0.00, se: 0.00); avg len: 400.00; : 100%|██████████| 10/10 [00:46<00:00,  4.63s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e3588454c424947a9f5f7de17fe01ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='timestep', max=399), Output()), _dom_classes=('widget-in…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Here we create an evaluator for the cramped_room layout\n",
        "layout = \"cramped_room\"\n",
        "ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "                                     env_params={\"horizon\": 400})\n",
        "\n",
        "agent_1.epsilon = 0.1\n",
        "agent_2.epsilon = 0.1\n",
        "ap = AgentPair(agent_2, agent_1)\n",
        "\n",
        "trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "\n",
        "StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42934b23",
      "metadata": {
        "id": "42934b23"
      },
      "source": [
        "# PPO Implementation with different NNs for the agents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8f606dd",
      "metadata": {
        "id": "c8f606dd"
      },
      "outputs": [],
      "source": [
        "class SinglePPOPolicyBatch(Model):\n",
        "    def __init__(self, input_shape, num_actions, optimizer, epsilon = 0.05):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.num_actions = num_actions\n",
        "        self.optimizer = optimizer\n",
        "        self.epsilon = epsilon\n",
        "        self.input_a = Input(shape=(self.input_shape))\n",
        "        self.input_b = Input(shape=(self.input_shape))\n",
        "        self.dense_1 = layers.Dense(128, activation='tanh')\n",
        "        self.dense_2 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_3 = layers.Dense(128, activation='tanh')\n",
        "        self.policy = layers.Dense(self.num_actions, activation='softmax', name=\"policy\")\n",
        "        self.build_model()\n",
        "\n",
        "    def preprocess(self, obs_batch):\n",
        "        if isinstance(obs_batch, Tuple):\n",
        "            obs_batch = [obs_batch] # to handle the case where obs_batch is a single observation\n",
        "\n",
        "        obs_1, obs_2 = zip(*obs_batch)\n",
        "        obs_batch = tf.concat([tf.stack(obs_1), tf.stack(obs_2)], axis=-1)\n",
        "        return obs_batch\n",
        "\n",
        "\n",
        "    def call(self, obs_batch, training=False):\n",
        "        x = self.preprocess(obs_batch)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.dense_3(x)\n",
        "        policy = self.policy(x)\n",
        "        return policy\n",
        "\n",
        "    def build_model(self):\n",
        "        # computing a forward pass in order to automatically build the model\n",
        "        dummy_input = (\n",
        "            tf.zeros((1, 96)),\n",
        "            tf.zeros((1, 96))\n",
        "        )\n",
        "        _ = self(dummy_input)\n",
        "\n",
        "    def train_step(self, deltas_batch: tf.Tensor, obs_batch, actions_batch, old_policy):\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            pi = self.call(obs_batch, training=True)\n",
        "            old_pi = old_policy.call(obs_batch)\n",
        "            pi_ratio = pi / old_pi + 1e-8 # to avoid numerical instability\n",
        "            pi_clipped_ratio = tf.clip_by_value(pi_ratio, 1 - self.epsilon, 1 + self.epsilon)\n",
        "            pi_ratio_advantage = pi_ratio*deltas_batch\n",
        "            pi_clipped_ratio_advantage = pi_clipped_ratio*deltas_batch\n",
        "            L = 0\n",
        "            for i in range(len(actions_batch)):\n",
        "                L += min(pi_ratio_advantage[i][actions_batch[i]], pi_clipped_ratio_advantage[i][actions_batch[i]])\n",
        "            loss = -L\n",
        "\n",
        "        grad_loss = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_loss, self.trainable_weights))\n",
        "\n",
        "\n",
        "class SinglePPOValueFunctionApproximatorBatch(Model):\n",
        "    def __init__(self, input_shape, optimizer):\n",
        "        super().__init__()\n",
        "        self.input_shape = input_shape\n",
        "        self.optimizer = optimizer\n",
        "        self.input_a = Input(shape=(self.input_shape))\n",
        "        self.input_b = Input(shape=(self.input_shape))\n",
        "        self.dense_1 = layers.Dense(128, activation='tanh')\n",
        "        self.dense_2 = layers.Dense(256, activation='tanh')\n",
        "        self.dense_3 = layers.Dense(128, activation='tanh')\n",
        "        # self.value_function = layers.Dense(1, activation='relu', name=\"value_function\")\n",
        "        self.value_function = layers.Dense(1, name=\"value_function\")\n",
        "        self.build_model()\n",
        "\n",
        "    def preprocess(self, obs_batch):\n",
        "        if isinstance(obs_batch, Tuple):\n",
        "            obs_batch = [obs_batch] # to handle the case where obs_batch is a single observation\n",
        "\n",
        "        obs_1, obs_2 = zip(*obs_batch)\n",
        "        obs_batch = tf.concat([tf.stack(obs_1), tf.stack(obs_2)], axis=-1)\n",
        "        return obs_batch\n",
        "\n",
        "\n",
        "    def call(self, obs_batch, training=False):\n",
        "        x = self.preprocess(obs_batch)\n",
        "        x = self.dense_1(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.dense_3(x)\n",
        "        value_function = self.value_function(x)\n",
        "        return value_function\n",
        "\n",
        "    def build_model(self):\n",
        "        # computing a forward pass in order to automatically build the model\n",
        "        dummy_input =  (\n",
        "            tf.zeros((1, 96)),\n",
        "            tf.zeros((1, 96))\n",
        "        )\n",
        "        _ = self(dummy_input)\n",
        "\n",
        "    def train_step(self, deltas_batch: tf.Tensor, obs_batch): # deltas is a tf.Tensor of shape (batch_size,1)\n",
        "        # update w with w + alpha_w*grad_v^(St)*delta\n",
        "        with tf.GradientTape() as tape:\n",
        "            state_value = self.call(obs_batch, training=True)\n",
        "            loss = tf.reduce_mean(tf.square(deltas_batch)) # adding a term that minimizes the distance between the true and the estimated value\n",
        "            processed_state_value = -deltas_batch * state_value + loss\n",
        "\n",
        "        grad_state_value = tape.gradient(processed_state_value, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad_state_value, self.trainable_weights))\n",
        "\n",
        "class SinglePPOMyAgentBatch(Agent):\n",
        "    \"\"\"\n",
        "    This class implements a single Agent\n",
        "    For now let's treat it like a single player identified by self.index\n",
        "    \"\"\"\n",
        "    def __init__(self, actor, old_policy, critic, idx, base_env: OvercookedEnv, epsilon = 0.1):\n",
        "        super().__init__()\n",
        "        self.actor = actor\n",
        "        self.old_policy = old_policy\n",
        "        self.critic = critic\n",
        "        self.idx = idx\n",
        "        if not self.idx in [0,1]:\n",
        "            raise AssertionError(\"The index of the agent must be either 0 or 1!\")\n",
        "        self.base_env = base_env\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def action(self, obs):\n",
        "        \"\"\"\n",
        "        obs: preprocessed observation (or overcookedstate)\n",
        "        We want to output the action given the state. can use a NN!\n",
        "        should return a tuple (Action, Dict)\n",
        "        Dict should contain info about the action ('action_probs': numpy array)\n",
        "        \"\"\"\n",
        "        if isinstance(obs, OvercookedState):\n",
        "            # this is useful for translating the OvercookedState\n",
        "            # into observation that can be fed into the NN.\n",
        "            obs_from_state = self.base_env.featurize_state_mdp(obs)\n",
        "            obs = (obs_from_state[0],obs_from_state[1])\n",
        "\n",
        "\n",
        "        action_probs = self.actor.call(obs).numpy()\n",
        "        if np.random.random() > self.epsilon:\n",
        "            action = Action.argmax(action_probs) # greedy selection\n",
        "        else:\n",
        "            action_idx = np.random.choice(range(0,6), size=1)[0]\n",
        "            action = Action.INDEX_TO_ACTION[action_idx] # random exploration\n",
        "        return (action, {'action_probs': action_probs})\n",
        "\n",
        "    def actions(self, obss):\n",
        "        \"\"\"\n",
        "        Look at the documentation of the Agent class\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def update_old_policy(self):\n",
        "        self.old_policy.set_weights(self.actor.get_weights())\n",
        "\n",
        "\n",
        "    def decay_epsilon(self, decay):\n",
        "        if self.epsilon - decay <= 0.5:\n",
        "            self.epsilon = 0.5\n",
        "        else:\n",
        "            self.epsilon -= decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12eba244",
      "metadata": {
        "id": "12eba244"
      },
      "outputs": [],
      "source": [
        "number_of_frames = 9\n",
        "layout_name = \"cramped_room\"\n",
        "base_mdp = OvercookedGridworld.from_layout_name(layout_name=layout_name) #or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=number_of_frames)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)\n",
        "\n",
        "alpha_t = 1e-6\n",
        "alpha_w = 1e-3\n",
        "\n",
        "optimizer_actor_1 = Adam(learning_rate=alpha_t)\n",
        "optimizer_actor_2 = Adam(learning_rate=alpha_t)\n",
        "optimizer_critic_1 = Adam(learning_rate=alpha_w)\n",
        "optimizer_critic_2 = Adam(learning_rate=alpha_w)\n",
        "\n",
        "input_shape = env.observation_space._shape\n",
        "\n",
        "single_actor_batch_1 = SinglePPOPolicyBatch(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=optimizer_actor_1\n",
        ")\n",
        "single_actor_batch_2 = SinglePPOPolicyBatch(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=optimizer_actor_2\n",
        ")\n",
        "old_policy_1 = SinglePPOPolicyBatch(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=None\n",
        ")\n",
        "old_policy_2 = SinglePPOPolicyBatch(\n",
        "    input_shape=input_shape,\n",
        "    num_actions=Action.NUM_ACTIONS,\n",
        "    optimizer=None\n",
        ")\n",
        "\n",
        "single_critic_batch_1 = SinglePPOValueFunctionApproximatorBatch(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=optimizer_critic_1\n",
        "    )\n",
        "\n",
        "single_critic_batch_2 = SinglePPOValueFunctionApproximatorBatch(\n",
        "    input_shape=input_shape,\n",
        "    optimizer=optimizer_critic_2\n",
        "    )\n",
        "\n",
        "agent_1 = SinglePPOMyAgentBatch(\n",
        "    actor=single_actor_batch_1,\n",
        "    old_policy=old_policy_1,\n",
        "    critic=single_critic_batch_1,\n",
        "    idx=0,\n",
        "    base_env=base_env,\n",
        "    epsilon=0.9\n",
        ")\n",
        "agent_2 = SinglePPOMyAgentBatch(\n",
        "    actor=single_actor_batch_2,\n",
        "    old_policy=old_policy_2,\n",
        "    critic=single_critic_batch_2,\n",
        "    idx=1,\n",
        "    base_env=base_env,\n",
        "    epsilon=0.9\n",
        ")\n",
        "\n",
        "agent_1.update_old_policy()\n",
        "agent_2.update_old_policy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13732512",
      "metadata": {
        "id": "13732512"
      },
      "outputs": [],
      "source": [
        "path_critic = \"networks/critic/\"\n",
        "path_actor = \"networks/actor/\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9dfc84a",
      "metadata": {
        "id": "f9dfc84a"
      },
      "source": [
        "- try to learn only the valuefunction first.\n",
        "- try to build more complex neural networks\n",
        "- you need to sample to have the action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05486c34",
      "metadata": {
        "id": "05486c34",
        "outputId": "57446625-3017-45c0-a1c9-961b50eab430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode [1] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [2] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [3] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [4] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [5] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [6] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [7] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [8] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [9] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [10] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [11] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [12] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [13] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [14] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [15] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [16] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [17] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [18] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [19] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [20] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [21] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [22] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [23] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [24] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [25] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [26] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [27] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [28] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [29] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [30] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [31] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [32] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [33] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [34] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [35] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [36] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [37] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [38] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [39] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [40] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [41] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [42] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [43] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [44] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [45] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [46] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [47] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [48] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [49] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [50] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [51] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [52] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [53] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [54] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [55] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [56] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [57] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [58] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [59] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [60] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [61] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [62] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [63] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [64] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [65] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [66] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [67] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [68] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [69] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [70] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [71] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [72] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [73] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [74] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [75] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [76] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [77] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [78] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [79] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [80] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [81] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [82] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [83] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [84] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [85] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [86] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [87] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [88] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [89] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [90] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [91] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [92] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [93] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [94] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [95] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [96] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [97] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [98] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [99] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n",
            "Episode [100] terminated at timestep 9. cumulative reward: 6.\n",
            "cumulative sparse reward: [0 0]\n",
            "cumulative shaped reward: [3 3]\n",
            "Computing the deltas (MONTE-CARLO)\n",
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n"
          ]
        }
      ],
      "source": [
        "number_of_episodes = 100\n",
        "batch_size = 9\n",
        "number_of_epochs = 2\n",
        "average_reward = 0\n",
        "try:\n",
        "    for episode in range(1, number_of_episodes + 1):\n",
        "        timestep = 0\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "\n",
        "        shaped_reward_factor = 1 # multiplicative factor for discounting shaped reward.\n",
        "        discount_rate = 1 # will decrease the shaped reward every time\n",
        "        cumulative_reward = 0\n",
        "\n",
        "        # if (episode) % 100 == 0:\n",
        "        #     agent_1.decay_epsilon(decay=0.1)\n",
        "        #     agent_2.decay_epsilon(decay=0.1)\n",
        "        #     single_critic_batch_1.save_weights(path_critic + \"PPO_single_critic_batch_1_\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "        #     single_critic_batch_2.save_weights(path_critic + \"PPO_single_critic_batch_2_\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "        #     single_actor_batch_1.save_weights(path_actor + \"PPO_single_actor_batch_1\"+str(agent_2.epsilon)[2]+\".weights.h5\")\n",
        "        #     single_actor_batch_2.save_weights(path_actor + \"PPO_single_actor_batch_2\"+str(agent_2.epsilon)[2]+\".weights.h5\")\n",
        "\n",
        "        agent_1_actions = [0,3,5,4,4,2,0,5,3]\n",
        "        agent_2_actions = [2,5,3,0,5,2,4,4,4]\n",
        "        agent_1_deltas = []\n",
        "        agent_2_deltas = []\n",
        "        # agent_1_deltas = [0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]\n",
        "        # agent_2_deltas = [0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]\n",
        "        agent_1_rewards = []\n",
        "        agent_2_rewards = []\n",
        "        observations = []\n",
        "\n",
        "        while not done:\n",
        "            # render = env.render() / 255.0\n",
        "            # plt.imshow(render)\n",
        "            # plt.show()\n",
        "\n",
        "            # reordering the actions based on the POV of the environment\n",
        "            if obs['other_agent_env_idx'] == 0:\n",
        "                my_obs = (obs['both_agent_obs'][1],obs['both_agent_obs'][0])\n",
        "                obs['both_agent_obs'] = my_obs\n",
        "\n",
        "            # action1 = agent_1.action(obs['both_agent_obs'])\n",
        "            # action2 = agent_2.action(obs['both_agent_obs'])\n",
        "            # player_1_action = Action.ACTION_TO_INDEX[action1[0]]\n",
        "            # player_2_action = Action.ACTION_TO_INDEX[action2[0]]\n",
        "\n",
        "            if obs['other_agent_env_idx'] == 1:\n",
        "                # action = (player_1_action,player_2_action)\n",
        "                action = (agent_1_actions[timestep], agent_2_actions[timestep])\n",
        "            else:\n",
        "                # action = (player_2_action,player_1_action)\n",
        "                action = (agent_2_actions[timestep], agent_1_actions[timestep])\n",
        "\n",
        "            # agent_1_actions.append(player_1_action)\n",
        "            # agent_2_actions.append(player_2_action)\n",
        "            observations.append(obs['both_agent_obs'])\n",
        "\n",
        "            new_obs, reward, done, env_info = env.step(action)\n",
        "            # shaped_reward = sum(env_info['shaped_r_by_agent']) # let's use shaped reward for learning how to play first.\n",
        "            agent_1_shaped_reward = env_info['shaped_r_by_agent'][0]\n",
        "            agent_2_shaped_reward = env_info['shaped_r_by_agent'][1]\n",
        "\n",
        "            # if shaped_reward != 0:\n",
        "            #     shaped_reward = shaped_reward * shaped_reward_factor # discounting the shaped reward\n",
        "            #     shaped_reward_factor *= discount_rate\n",
        "\n",
        "\n",
        "            agent_1_total_reward = reward + agent_1_shaped_reward\n",
        "            agent_2_total_reward = reward + agent_2_shaped_reward\n",
        "            agent_1_rewards.append(agent_1_total_reward)\n",
        "            agent_2_rewards.append(agent_2_total_reward)\n",
        "            cumulative_reward += (agent_1_total_reward + agent_2_total_reward - reward) # since it's in both the total rewards\n",
        "\n",
        "            obs = new_obs\n",
        "\n",
        "            timestep += 1\n",
        "\n",
        "        average_reward = 1/(episode)*( cumulative_reward + (episode-1)*average_reward)\n",
        "        print(f\"Episode [{episode}] terminated at timestep {timestep}. cumulative reward: {cumulative_reward}.\")\n",
        "\n",
        "        print(f\"cumulative sparse reward: {env_info['episode']['ep_game_stats']['cumulative_sparse_rewards_by_agent']}\")\n",
        "        print(f\"cumulative shaped reward: {env_info['episode']['ep_game_stats']['cumulative_shaped_rewards_by_agent']}\")\n",
        "\n",
        "        print(f\"Computing the deltas (MONTE-CARLO)\")\n",
        "        for t in range(len(observations)):\n",
        "            G_t_agent_1 = np.sum(agent_1_rewards[t:])\n",
        "            G_t_agent_2 = np.sum(agent_2_rewards[t:])\n",
        "            agent_1_delta = G_t_agent_1 - single_critic_batch_1.call(observations[t])\n",
        "            agent_2_delta = G_t_agent_2 - single_critic_batch_2.call(observations[t])\n",
        "            agent_1_deltas.append(agent_1_delta)\n",
        "            agent_2_deltas.append(agent_2_delta)\n",
        "\n",
        "        print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "        for epoch in range(number_of_epochs):\n",
        "            num_batches = len(observations) // batch_size\n",
        "            shuffled_indices = tf.random.shuffle(tf.range(len(observations)))\n",
        "            for batch in range(num_batches):\n",
        "                if batch == num_batches: # last batch\n",
        "                    idx = shuffled_indices[batch*batch_size:]\n",
        "                else:\n",
        "                    idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "                agent_1_deltas_batch = tf.squeeze(tf.gather(agent_1_deltas, idx), axis=-1)\n",
        "                agent_2_deltas_batch = tf.squeeze(tf.gather(agent_2_deltas, idx), axis=-1)\n",
        "                agent_1_actions_batch = tf.gather(agent_1_actions, idx)\n",
        "                agent_2_actions_batch = tf.gather(agent_2_actions, idx)\n",
        "                observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "                single_critic_batch_1.train_step(agent_1_deltas_batch, observations_batch)\n",
        "                single_critic_batch_2.train_step(agent_2_deltas_batch, observations_batch)\n",
        "                single_actor_batch_1.train_step(agent_1_deltas_batch, observations_batch, agent_1_actions_batch, agent_1.old_policy)\n",
        "                single_actor_batch_2.train_step(agent_2_deltas_batch, observations_batch, agent_2_actions_batch, agent_2.old_policy)\n",
        "\n",
        "            print(f\"Epoch {epoch+1} terminated.\")\n",
        "        agent_1.update_old_policy()\n",
        "        agent_2.update_old_policy()\n",
        "        print(\"Old policy updated.\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    # single_critic_batch_1.save_weights(path_critic + \"PPO_single_critic_batch_1_\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "    # single_critic_batch_2.save_weights(path_critic + \"PPO_single_critic_batch_2_\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "    # single_actor_batch_1.save_weights(path_actor + \"PPO_single_actor_batch_1\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "    # single_actor_batch_2.save_weights(path_actor + \"PPO_single_actor_batch_2\"+str(agent_1.epsilon)[2]+\".weights.h5\")\n",
        "    print(\"Unexpected interruption of training. Saving weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18d3b09a",
      "metadata": {
        "id": "18d3b09a",
        "outputId": "5de7f584-83e2-4c02-851b-b61e54f3274d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deltas: [<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.08810043]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.57649255]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.74333763]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.4717548]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.48167014]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.4180901]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.20407844]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.14600158]], dtype=float32)>, <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-2.7087955]], dtype=float32)>]\n",
            "actions: [0, 3, 5, 4, 4, 2, 0, 5, 3]\n"
          ]
        }
      ],
      "source": [
        "print(f\"deltas: {agent_1_deltas}\")\n",
        "print(f\"actions: {agent_1_actions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa8ab71c",
      "metadata": {
        "id": "fa8ab71c",
        "outputId": "b66440a8-e7e7-4acf-e41f-1f57f79bbef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9, 1), dtype=float32, numpy=\n",
              "array([[3.0029888],\n",
              "       [3.476031 ],\n",
              "       [3.6558423],\n",
              "       [3.420232 ],\n",
              "       [3.426095 ],\n",
              "       [3.357685 ],\n",
              "       [3.0948834],\n",
              "       [3.0314775],\n",
              "       [2.5496166]], dtype=float32)>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_1.critic(observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdcd6555",
      "metadata": {
        "id": "bdcd6555",
        "outputId": "6d7d839c-7e10-4e75-d699-4d56a5f9fc82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 3, 5, 4, 4, 2, 0, 5, 3]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9, 6), dtype=float32, numpy=\n",
              "array([[0.42995033, 0.15540141, 0.07245072, 0.09965793, 0.08214606,\n",
              "        0.16039355],\n",
              "       [0.3812262 , 0.11570279, 0.05563588, 0.09430336, 0.1404916 ,\n",
              "        0.2126403 ],\n",
              "       [0.39994976, 0.14705846, 0.05766393, 0.07857709, 0.10975736,\n",
              "        0.2069934 ],\n",
              "       [0.38749117, 0.17783736, 0.10564444, 0.07958111, 0.07753027,\n",
              "        0.17191567],\n",
              "       [0.4107398 , 0.1536756 , 0.10426272, 0.08185078, 0.08316261,\n",
              "        0.16630848],\n",
              "       [0.37289113, 0.15720315, 0.08807483, 0.06117241, 0.08681408,\n",
              "        0.2338444 ],\n",
              "       [0.2669122 , 0.13264365, 0.07348461, 0.10169731, 0.24469541,\n",
              "        0.18056683],\n",
              "       [0.25690734, 0.12257473, 0.06750435, 0.08076221, 0.28243768,\n",
              "        0.18981364],\n",
              "       [0.28856304, 0.09113441, 0.06223999, 0.08719691, 0.28227845,\n",
              "        0.18858723]], dtype=float32)>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(agent_1_actions)\n",
        "agent_1.actor(observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7abfbf4",
      "metadata": {
        "id": "d7abfbf4",
        "outputId": "6659cc85-01ba-4e0a-a31a-6715bd54a490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performing stocastic gradient descent with 2 epochs.\n",
            "Epoch 1 terminated.\n",
            "Epoch 2 terminated.\n",
            "Old policy updated.\n"
          ]
        }
      ],
      "source": [
        "number_of_epochs = 2\n",
        "print(f\"Performing stocastic gradient descent with {number_of_epochs} epochs.\")\n",
        "for epoch in range(number_of_epochs):\n",
        "    num_batches = len(observations) // batch_size\n",
        "    shuffled_indices = tf.random.shuffle(tf.range(len(observations)))\n",
        "    for batch in range(num_batches):\n",
        "        if batch == num_batches: # last batch\n",
        "            idx = shuffled_indices[batch*batch_size:]\n",
        "        else:\n",
        "            idx = shuffled_indices[batch*batch_size:(batch+1)*batch_size]\n",
        "\n",
        "        agent_1_deltas_batch = tf.squeeze(tf.gather(agent_1_deltas, idx), axis=-1)\n",
        "        agent_2_deltas_batch = tf.squeeze(tf.gather(agent_2_deltas, idx), axis=-1)\n",
        "        agent_1_actions_batch = tf.gather(agent_1_actions, idx)\n",
        "        agent_2_actions_batch = tf.gather(agent_2_actions, idx)\n",
        "        observations_batch = tf.gather(observations, idx)\n",
        "\n",
        "        single_critic_batch_1.train_step(agent_1_deltas_batch, observations_batch)\n",
        "        single_critic_batch_2.train_step(agent_2_deltas_batch, observations_batch)\n",
        "        single_actor_batch_1.train_step(agent_1_deltas_batch, observations_batch, agent_1_actions_batch, agent_1.old_policy)\n",
        "        single_actor_batch_2.train_step(agent_2_deltas_batch, observations_batch, agent_2_actions_batch, agent_2.old_policy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} terminated.\")\n",
        "agent_1.update_old_policy()\n",
        "agent_2.update_old_policy()\n",
        "print(\"Old policy updated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e27eecfa",
      "metadata": {
        "id": "e27eecfa",
        "outputId": "25177205-f9a1-4be1-dc3c-737f043cf6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "actions: [0, 3, 5, 4, 4, 2, 0, 5, 3]\n",
            "tf.Tensor(\n",
            "[[0.15358098 0.12851276 0.19724137 0.26844463 0.09837393 0.15384635]\n",
            " [0.1419473  0.12488297 0.20040582 0.24967888 0.08087178 0.20221326]\n",
            " [0.1426429  0.14456539 0.22539036 0.1953097  0.10137178 0.1907199 ]\n",
            " [0.09734543 0.14189063 0.35803217 0.14960736 0.11195736 0.14116707]\n",
            " [0.1094325  0.14722984 0.33201593 0.16180198 0.09866285 0.150857  ]\n",
            " [0.10592322 0.14850427 0.34247446 0.19748576 0.08631345 0.11929888]\n",
            " [0.10938568 0.17282152 0.19826694 0.28383833 0.07338683 0.16230066]\n",
            " [0.11258917 0.18495543 0.16243964 0.33746386 0.04965557 0.15289621]\n",
            " [0.13929448 0.15747339 0.15320216 0.31434095 0.05044907 0.18524003]], shape=(9, 6), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(f\"actions: {agent_1_actions}\")\n",
        "print(agent_1.actor(observations))\n",
        "# [0.09367532, 0.17965837, 0.3680178 , 0.12918349, 0.12197147, 0.10749362] 0\n",
        "# [0.10268684, 0.14741758, 0.35757372, 0.16343038, 0.13853838,0.09035313] 3\n",
        "# [0.11685525, 0.14133197, 0.28310293, 0.20308046, 0.17950246,0.07612696],5,\n",
        "# [0.11804521, 0.17394674, 0.19776204, 0.17337577, 0.26236528,0.07450493],4,\n",
        "# [0.12199399, 0.16056925, 0.19554548, 0.16675068, 0.27091032,0.08423036],4,\n",
        "# [0.14682746, 0.20350426, 0.17738527, 0.1450429 , 0.26738393,0.05985614], 2,\n",
        "# [0.13215278, 0.18081923, 0.24620707, 0.16264597, 0.17406137,0.10411353], 0,\n",
        "# [0.13127315, 0.18660071, 0.24234423, 0.14297846, 0.17740306,0.11940035],5,\n",
        "# [0.13906823, 0.16432595, 0.35385984, 0.13538487, 0.11182725,0.09553384] 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5976b1a2",
      "metadata": {
        "id": "5976b1a2"
      },
      "outputs": [],
      "source": [
        "# # Here we create an evaluator for the cramped_room layout\n",
        "# layout = \"cramped_room\"\n",
        "# ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "#                                      env_params={\"horizon\": 400})\n",
        "\n",
        "# agent_1.epsilon = 0.5\n",
        "# agent_2.epsilon = 0.5\n",
        "# ap = AgentPair(agent_1, agent_2)\n",
        "\n",
        "# trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "\n",
        "# StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2546c88",
      "metadata": {
        "id": "a2546c88"
      },
      "outputs": [],
      "source": [
        "# # Here we create an evaluator for the cramped_room layout\n",
        "# layout = \"cramped_room\"\n",
        "# ae = AgentEvaluator.from_layout_name(mdp_params={\"layout_name\": layout, \"old_dynamics\": True},\n",
        "#                                      env_params={\"horizon\": 400})\n",
        "\n",
        "# ap = AgentPair(RandomAgent(all_actions=True), RandomAgent(all_actions=True))\n",
        "\n",
        "# trajs = ae.evaluate_agent_pair(ap, 10)\n",
        "\n",
        "# StateVisualizer().display_rendered_trajectory(trajs, ipython_display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4abaac",
      "metadata": {
        "id": "7b4abaac",
        "outputId": "f6e2ee94-79fd-4de1-d07a-f4c940a572e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "delta: [[-0.08628636]\n",
            " [-0.08628636]\n",
            " [-0.08628636]\n",
            " [ 0.25002515]\n",
            " [-0.05459686]]\n",
            "action: [5, 4, 5, 2, 4]\n"
          ]
        }
      ],
      "source": [
        "agent_1_deltas_batch = tf.squeeze(agent_1_deltas[:5], axis=-1)\n",
        "agent_2_deltas_batch = tf.squeeze(agent_2_deltas[:5], axis=-1)\n",
        "agent_1_actions_batch = agent_1_actions[:5]\n",
        "agent_2_actions_batch = agent_2_actions[:5]\n",
        "observations_batch = observations[:5]\n",
        "print(f\"delta: {agent_1_deltas_batch}\")\n",
        "print(f\"action: {agent_1_actions_batch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60fc67f6",
      "metadata": {
        "id": "60fc67f6",
        "outputId": "79d6f369-a76b-490e-ac15-2039babb3103"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 6), dtype=float32, numpy=\n",
              "array([[0.1851859 , 0.31293392, 0.12289874, 0.09092614, 0.19850704,\n",
              "        0.08954828],\n",
              "       [0.24177429, 0.29987434, 0.08277841, 0.11627084, 0.19729319,\n",
              "        0.06200891],\n",
              "       [0.2519065 , 0.32475212, 0.10912957, 0.11884841, 0.1412006 ,\n",
              "        0.05416276],\n",
              "       [0.16171499, 0.3840429 , 0.12999965, 0.12385841, 0.14538556,\n",
              "        0.05499851],\n",
              "       [0.20342645, 0.36186278, 0.13344555, 0.12230352, 0.13379931,\n",
              "        0.04516245]], dtype=float32)>"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_1.actor(observations[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6452d54",
      "metadata": {
        "id": "b6452d54"
      },
      "outputs": [],
      "source": [
        "single_critic_batch_1.train_step(agent_1_deltas_batch, observations_batch)\n",
        "single_critic_batch_2.train_step(agent_2_deltas_batch, observations_batch)\n",
        "single_actor_batch_1.train_step(agent_1_deltas_batch, observations_batch, agent_1_actions_batch, agent_1.old_policy)\n",
        "single_actor_batch_2.train_step(agent_2_deltas_batch, observations_batch, agent_2_actions_batch, agent_2.old_policy)\n",
        "# agent_1.update_old_policy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01018123",
      "metadata": {
        "id": "01018123",
        "outputId": "70408054-0034-4515-de69-37bd8a74319c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 6), dtype=float32, numpy=\n",
              "array([[0.17644215, 0.22335747, 0.24774687, 0.05928389, 0.19960198,\n",
              "        0.09356767],\n",
              "       [0.17644215, 0.22335747, 0.24774687, 0.05928389, 0.19960198,\n",
              "        0.09356767],\n",
              "       [0.17644215, 0.22335747, 0.24774687, 0.05928389, 0.19960198,\n",
              "        0.09356767],\n",
              "       [0.19349185, 0.26201612, 0.21033107, 0.06349459, 0.17717108,\n",
              "        0.09349547],\n",
              "       [0.12860686, 0.2923308 , 0.27677163, 0.05776837, 0.13853319,\n",
              "        0.10598914]], dtype=float32)>"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_1.actor(observations[:5])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
